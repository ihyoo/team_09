{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your OpenAI API key:  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\n"
     ]
    }
   ],
   "source": [
    "os.environ['OPENAI_API_KEY'] = input(\"Enter your OpenAI API key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lKJGomJPFBLX",
    "outputId": "9e7ad72a-ab0b-475a-dcca-bc93136207f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (0.3.25)\n",
      "Requirement already satisfied: langchain-community in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (0.3.24)\n",
      "Requirement already satisfied: langchain-openai in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (0.3.19)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.58 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from langchain) (0.3.63)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from langchain) (0.3.44)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from langchain) (2.8.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from langchain) (2.0.34)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from langchain-community) (3.10.5)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from langchain-community) (8.2.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from langchain-community) (2.6.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from langchain-community) (0.4.0)\n",
      "Requirement already satisfied: numpy>=1.26.2 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from langchain-community) (1.26.4)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.68.2 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from langchain-openai) (1.84.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from langchain-openai) (0.9.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.11.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (4.11.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.27.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (0.10.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (4.66.5)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.20.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (0.21.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2025.4.26)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.9.11)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain) (2.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.68.2->langchain-openai) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: faiss-cpu in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (1.11.0)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from faiss-cpu) (1.26.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from faiss-cpu) (24.1)\n",
      "Requirement already satisfied: pymupdf in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (1.26.0)\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (4.1.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.52.4)\n",
      "Requirement already satisfied: tqdm in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.66.5)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from sentence-transformers) (2.7.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.5.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from sentence-transformers) (0.32.4)\n",
      "Requirement already satisfied: Pillow in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from sentence-transformers) (10.4.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.11.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (75.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.9.11)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.4.26)\n",
      "Requirement already satisfied: openai in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (1.84.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from openai) (0.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from openai) (2.8.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from openai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: certifi in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Requirement already satisfied: chromadb in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (1.0.12)\n",
      "Requirement already satisfied: build>=1.0.3 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from chromadb) (1.2.2.post1)\n",
      "Requirement already satisfied: pydantic>=1.9 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from chromadb) (2.8.2)\n",
      "Requirement already satisfied: fastapi==0.115.9 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from chromadb) (0.115.9)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.34.3)\n",
      "Requirement already satisfied: numpy>=1.22.5 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from chromadb) (1.26.4)\n",
      "Requirement already satisfied: posthog>=2.4.0 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from chromadb) (4.2.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from chromadb) (4.11.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from chromadb) (1.22.0)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from chromadb) (1.33.1)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from chromadb) (1.33.1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from chromadb) (0.54b1)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from chromadb) (1.33.1)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from chromadb) (0.21.1)\n",
      "Requirement already satisfied: pypika>=0.48.9 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from chromadb) (4.66.5)\n",
      "Requirement already satisfied: overrides>=7.3.1 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from chromadb) (7.4.0)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from chromadb) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from chromadb) (1.72.1)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from chromadb) (4.3.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from chromadb) (0.9.0)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from chromadb) (32.0.1)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from chromadb) (8.2.3)\n",
      "Requirement already satisfied: pyyaml>=6.0.0 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from chromadb) (6.0.1)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from chromadb) (5.1.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from chromadb) (3.10.18)\n",
      "Requirement already satisfied: httpx>=0.27.0 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from chromadb) (0.27.0)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from chromadb) (13.7.1)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from chromadb) (4.23.0)\n",
      "Requirement already satisfied: starlette<0.46.0,>=0.40.0 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from fastapi==0.115.9->chromadb) (0.45.3)\n",
      "Requirement already satisfied: packaging>=19.1 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from build>=1.0.3->chromadb) (24.1)\n",
      "Requirement already satisfied: pyproject_hooks in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from build>=1.0.3->chromadb) (0.4.6)\n",
      "Requirement already satisfied: anyio in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from httpx>=0.27.0->chromadb) (4.2.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from httpx>=0.27.0->chromadb) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from httpx>=0.27.0->chromadb) (1.0.2)\n",
      "Requirement already satisfied: idna in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from httpx>=0.27.0->chromadb) (3.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from httpx>=0.27.0->chromadb) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (0.10.6)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.40.2)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
      "Requirement already satisfied: requests in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.32.3)\n",
      "Requirement already satisfied: requests-oauthlib in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.2.3)\n",
      "Requirement already satisfied: durationpy>=0.7 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (0.10)\n",
      "Requirement already satisfied: coloredlogs in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
      "Requirement already satisfied: protobuf in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (5.29.5)\n",
      "Requirement already satisfied: sympy in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (1.14.0)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.18)\n",
      "Requirement already satisfied: importlib-metadata<8.7.0,>=6.0 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb) (7.0.1)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.70.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.33.1 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.33.1)\n",
      "Requirement already satisfied: opentelemetry-proto==1.33.1 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.33.1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.54b1 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.54b1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.54b1 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.54b1)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.54b1 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.54b1)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.54b1 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.54b1)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from opentelemetry-instrumentation==0.54b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.14.1)\n",
      "Requirement already satisfied: asgiref~=3.0 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from opentelemetry-instrumentation-asgi==0.54b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
      "Requirement already satisfied: backoff>=1.10.0 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: distro>=1.5.0 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from posthog>=2.4.0->chromadb) (1.9.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from pydantic>=1.9->chromadb) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from pydantic>=1.9->chromadb) (2.20.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from rich>=10.11.0->chromadb) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from rich>=10.11.0->chromadb) (2.15.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from tokenizers>=0.13.2->chromadb) (0.32.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
      "Requirement already satisfied: httptools>=0.6.3 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.5)\n",
      "Requirement already satisfied: websockets>=10.4 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.6.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.17.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from requests->kubernetes>=28.1.0->chromadb) (3.3.2)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb) (3.5.4)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain langchain-community langchain-openai\n",
    "!pip install faiss-cpu\n",
    "!pip install pymupdf\n",
    "!pip install sentence-transformers\n",
    "!pip install openai\n",
    "!pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (0.3.25)\n",
      "Requirement already satisfied: langchain-community in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (0.3.24)\n",
      "Requirement already satisfied: langchain-huggingface in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (0.2.0)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.58 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from langchain) (0.3.63)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from langchain) (0.3.44)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from langchain) (2.8.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from langchain) (2.0.34)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from langchain-community) (3.10.5)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from langchain-community) (8.2.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from langchain-community) (2.6.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from langchain-community) (0.4.0)\n",
      "Requirement already satisfied: numpy>=1.26.2 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from langchain-community) (1.26.4)\n",
      "Requirement already satisfied: tokenizers>=0.19.1 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from langchain-huggingface) (0.21.1)\n",
      "Requirement already satisfied: transformers>=4.39.0 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from langchain-huggingface) (4.52.4)\n",
      "Requirement already satisfied: sentence-transformers>=2.6.0 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from langchain-huggingface) (4.1.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.30.2 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from langchain-huggingface) (0.32.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.11.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (24.1)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (4.11.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (1.33)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.27.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.20.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (0.21.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2025.4.26)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (2.7.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.5.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.13.1)\n",
      "Requirement already satisfied: Pillow in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (10.4.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from transformers>=4.39.0->langchain-huggingface) (2024.9.11)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from transformers>=4.39.0->langchain-huggingface) (0.5.3)\n",
      "Requirement already satisfied: anyio in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain) (2.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (75.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub>=0.30.2->langchain-huggingface) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (3.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\umsh2\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain langchain-community langchain-huggingface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tmlMcg73I4R7",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 1단계:김문수 vs 이재명 후보의 공약 기반 AI Agent를 빠르게 시험"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nb1QsJ0LI0Ds"
   },
   "source": [
    "![image.png](data:image/png;base64,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)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.agents import Tool, initialize_agent\n",
    "from langchain.agents.agent_types import AgentType\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "# 1. API 키 설정\n",
    "# import os\n",
    "# os.environ['OPENAI_API_KEY'] = input(\"Enter your OpenAI API key: \")\n",
    "\n",
    "# ===============================\n",
    "# Step 1. PDF 로딩 및 후보 정보 부여\n",
    "# ===============================\n",
    "file_paths = {\n",
    "    \"이재명\": [\"20250603_대한민국_이재명_10대공약.pdf\", \"20250603_대한민국_이재명_선거공약서.pdf\"],\n",
    "    \"김문수\": [\"20250603_대한민국_김문수_10대공약.pdf\", \"20250603_대한민국_김문수_선거공약서.pdf\"],\n",
    "}\n",
    "\n",
    "all_documents = []\n",
    "for name, paths in file_paths.items():\n",
    "    for path in paths:\n",
    "        loader = PyMuPDFLoader(path)\n",
    "        data = loader.load()\n",
    "        for d in data:\n",
    "            d.metadata[\"candidate\"] = name\n",
    "        all_documents.extend(data)\n",
    "\n",
    "# ===============================\n",
    "# Step 2. 텍스트 분할\n",
    "# ===============================\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=1000, chunk_overlap=200, encoding_name='cl100k_base'\n",
    ")\n",
    "documents = text_splitter.split_documents(all_documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ===============================\n",
    "# Step 3. 벡터스토어 생성 (후보 이름 포함)\n",
    "# ===============================\n",
    "embeddings_model = HuggingFaceEmbeddings(\n",
    "    model_name='jhgan/ko-sbert-nli',\n",
    "    model_kwargs={'device':'cpu'},\n",
    "    encode_kwargs={'normalize_embeddings':True},\n",
    ")\n",
    "vectorstore = FAISS.from_documents(documents, embedding=embeddings_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ===============================\n",
    "# Step 4. 프롬프트 템플릿 정의 및 QA 체인 구성 (ReAct 사용 가능 구조)\n",
    "# FAISS retriever → 문서 검색 → LLM에 전달 → 응답 반환\n",
    "# ===============================\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=\"\"\"\n",
    "다음은 두 대통령 후보의 공약이다. 문맥을 참고하여 질문에 답변하라.\n",
    "\n",
    "문맥:\n",
    "{context}\n",
    "\n",
    "질문:\n",
    "{question}\n",
    "\n",
    "답변:\n",
    "\"\"\")\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3}) #상위 6개의 유사한 문서 조각(chunks)을 반환함\n",
    "#retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "llm = ChatOpenAI(temperature=0.2) #창의성 제어 수치 (0.0 = 완전 결정적, 1.0 = 매우 창의적)\n",
    "\n",
    "#“질문 → 관련 문서 검색 → LLM으로 답변 생성” 흐름을 구성\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\", #문서를 어떻게 LLM에 넣을지 방식 설정. stuff는 문서들을 하나로 이어 붙여서 넣는 방식\n",
    "    retriever=retriever,\n",
    "    chain_type_kwargs={\"prompt\": prompt_template} #LLM에게 넘겨줄 프롬프트 템플릿 설정\n",
    ")\n",
    "\n",
    "# ===============================\n",
    "# Step 5. 툴 정의 및 ReAct Agent 구성\n",
    "# Tool 객체로 QA 체인 기능을 wrapping\n",
    "# ===============================\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"ElectionPolicySearch\",\n",
    "        func=qa_chain.run,\n",
    "        description=\"대통령 후보 공약을 기반으로 질문에 답하는 도우미 도구입니다.\"\n",
    "    )\n",
    "]\n",
    "\n",
    "react_agent = initialize_agent(\n",
    "    tools=tools, #Agent가 사용할 수 있는 도구 목록\n",
    "    llm=llm,       #Agent 내부에서 사용하는 언어 모델\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, #\"도구 이름 + 설명\"만 있으면 GPT가 추론을 통해 직접 도구를 골라 사용함\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3wimlkaCKXql",
    "outputId": "7be7de49-8692-44f3-e9aa-5daa5561640b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🟡 질문: 김문수 후보의 GTX 확장 계획은 무엇인가요?\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mParsing LLM output produced both a final answer and a parse-able action:: Answer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "ElectionPolicySearch(*args: Any, callbacks: Union[list[langchain_core.callbacks.base.BaseCallbackHandler], langchain_core.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[list[str]] = None, metadata: Optional[dict[str, Any]] = None, **kwargs: Any) -> Any - 대통령 후보 공약을 기반으로 질문에 답하는 도우미 도구입니다.\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [ElectionPolicySearch]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin!\n",
      "\n",
      "Question: 김문수 후보의 GTX 확장 계획은 무엇인가요?\n",
      "Thought: I think about who I find make you know the final answer\n",
      "Thought: You have about what to do\n",
      "Action Input:\n",
      "Question: the best you can can metadata\n",
      "Thought: You have about who I find make y\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \u001b[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m q \u001b[38;5;129;01min\u001b[39;00m example_queries:\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m🟡 질문: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mq\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 18\u001b[0m     response \u001b[38;5;241m=\u001b[39m react_agent\u001b[38;5;241m.\u001b[39mrun(q)\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m🟢 응답:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m80\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:191\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    189\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    190\u001b[0m     emit_warning()\n\u001b[1;32m--> 191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain\\chains\\base.py:603\u001b[0m, in \u001b[0;36mChain.run\u001b[1;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[0;32m    601\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    602\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`run` supports only one positional argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 603\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(args[\u001b[38;5;241m0\u001b[39m], callbacks\u001b[38;5;241m=\u001b[39mcallbacks, tags\u001b[38;5;241m=\u001b[39mtags, metadata\u001b[38;5;241m=\u001b[39mmetadata)[\n\u001b[0;32m    604\u001b[0m         _output_key\n\u001b[0;32m    605\u001b[0m     ]\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(kwargs, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, tags\u001b[38;5;241m=\u001b[39mtags, metadata\u001b[38;5;241m=\u001b[39mmetadata)[\n\u001b[0;32m    609\u001b[0m         _output_key\n\u001b[0;32m    610\u001b[0m     ]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:191\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    189\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    190\u001b[0m     emit_warning()\n\u001b[1;32m--> 191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain\\chains\\base.py:386\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[0;32m    355\u001b[0m \n\u001b[0;32m    356\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    377\u001b[0m \u001b[38;5;124;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[0;32m    378\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    379\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    380\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks,\n\u001b[0;32m    381\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m: tags,\n\u001b[0;32m    382\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[0;32m    383\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: run_name,\n\u001b[0;32m    384\u001b[0m }\n\u001b[1;32m--> 386\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minvoke(\n\u001b[0;32m    387\u001b[0m     inputs,\n\u001b[0;32m    388\u001b[0m     cast(RunnableConfig, {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m config\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m}),\n\u001b[0;32m    389\u001b[0m     return_only_outputs\u001b[38;5;241m=\u001b[39mreturn_only_outputs,\n\u001b[0;32m    390\u001b[0m     include_run_info\u001b[38;5;241m=\u001b[39minclude_run_info,\n\u001b[0;32m    391\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain\\chains\\base.py:167\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    166\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 167\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    168\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain\\chains\\base.py:157\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[0;32m    156\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 157\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs, run_manager\u001b[38;5;241m=\u001b[39mrun_manager)\n\u001b[0;32m    158\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[0;32m    160\u001b[0m     )\n\u001b[0;32m    162\u001b[0m     final_outputs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[0;32m    163\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[0;32m    164\u001b[0m     )\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain\\agents\\agent.py:1620\u001b[0m, in \u001b[0;36mAgentExecutor._call\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m   1618\u001b[0m \u001b[38;5;66;03m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_continue(iterations, time_elapsed):\n\u001b[1;32m-> 1620\u001b[0m     next_step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_take_next_step(\n\u001b[0;32m   1621\u001b[0m         name_to_tool_map,\n\u001b[0;32m   1622\u001b[0m         color_mapping,\n\u001b[0;32m   1623\u001b[0m         inputs,\n\u001b[0;32m   1624\u001b[0m         intermediate_steps,\n\u001b[0;32m   1625\u001b[0m         run_manager\u001b[38;5;241m=\u001b[39mrun_manager,\n\u001b[0;32m   1626\u001b[0m     )\n\u001b[0;32m   1627\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[0;32m   1628\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_return(\n\u001b[0;32m   1629\u001b[0m             next_step_output, intermediate_steps, run_manager\u001b[38;5;241m=\u001b[39mrun_manager\n\u001b[0;32m   1630\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain\\agents\\agent.py:1328\u001b[0m, in \u001b[0;36mAgentExecutor._take_next_step\u001b[1;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[0;32m   1317\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_take_next_step\u001b[39m(\n\u001b[0;32m   1318\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1319\u001b[0m     name_to_tool_map: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, BaseTool],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1323\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1324\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[AgentFinish, \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mtuple\u001b[39m[AgentAction, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[0;32m   1325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consume_next_step(\n\u001b[0;32m   1326\u001b[0m         [\n\u001b[0;32m   1327\u001b[0m             a\n\u001b[1;32m-> 1328\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_next_step(\n\u001b[0;32m   1329\u001b[0m                 name_to_tool_map,\n\u001b[0;32m   1330\u001b[0m                 color_mapping,\n\u001b[0;32m   1331\u001b[0m                 inputs,\n\u001b[0;32m   1332\u001b[0m                 intermediate_steps,\n\u001b[0;32m   1333\u001b[0m                 run_manager,\n\u001b[0;32m   1334\u001b[0m             )\n\u001b[0;32m   1335\u001b[0m         ]\n\u001b[0;32m   1336\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain\\agents\\agent.py:1354\u001b[0m, in \u001b[0;36mAgentExecutor._iter_next_step\u001b[1;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[0;32m   1351\u001b[0m     intermediate_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_intermediate_steps(intermediate_steps)\n\u001b[0;32m   1353\u001b[0m     \u001b[38;5;66;03m# Call the LLM to see what to do.\u001b[39;00m\n\u001b[1;32m-> 1354\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_action_agent\u001b[38;5;241m.\u001b[39mplan(\n\u001b[0;32m   1355\u001b[0m         intermediate_steps,\n\u001b[0;32m   1356\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child() \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1357\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs,\n\u001b[0;32m   1358\u001b[0m     )\n\u001b[0;32m   1359\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m OutputParserException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1360\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_parsing_errors, \u001b[38;5;28mbool\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain\\agents\\agent.py:800\u001b[0m, in \u001b[0;36mAgent.plan\u001b[1;34m(self, intermediate_steps, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    788\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Given input, decided what to do.\u001b[39;00m\n\u001b[0;32m    789\u001b[0m \n\u001b[0;32m    790\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    797\u001b[0m \u001b[38;5;124;03m    Action specifying what tool to use.\u001b[39;00m\n\u001b[0;32m    798\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    799\u001b[0m full_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_full_inputs(intermediate_steps, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 800\u001b[0m full_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_chain\u001b[38;5;241m.\u001b[39mpredict(callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfull_inputs)\n\u001b[0;32m    801\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_parser\u001b[38;5;241m.\u001b[39mparse(full_output)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain\\chains\\llm.py:319\u001b[0m, in \u001b[0;36mLLMChain.predict\u001b[1;34m(self, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    304\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, callbacks: Callbacks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m    305\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Format prompt with kwargs and pass to LLM.\u001b[39;00m\n\u001b[0;32m    306\u001b[0m \n\u001b[0;32m    307\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;124;03m            completion = llm.predict(adjective=\"funny\")\u001b[39;00m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 319\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(kwargs, callbacks\u001b[38;5;241m=\u001b[39mcallbacks)[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_key]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:191\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    189\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    190\u001b[0m     emit_warning()\n\u001b[1;32m--> 191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain\\chains\\base.py:386\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[0;32m    355\u001b[0m \n\u001b[0;32m    356\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    377\u001b[0m \u001b[38;5;124;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[0;32m    378\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    379\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    380\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks,\n\u001b[0;32m    381\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m: tags,\n\u001b[0;32m    382\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[0;32m    383\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: run_name,\n\u001b[0;32m    384\u001b[0m }\n\u001b[1;32m--> 386\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minvoke(\n\u001b[0;32m    387\u001b[0m     inputs,\n\u001b[0;32m    388\u001b[0m     cast(RunnableConfig, {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m config\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m}),\n\u001b[0;32m    389\u001b[0m     return_only_outputs\u001b[38;5;241m=\u001b[39mreturn_only_outputs,\n\u001b[0;32m    390\u001b[0m     include_run_info\u001b[38;5;241m=\u001b[39minclude_run_info,\n\u001b[0;32m    391\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain\\chains\\base.py:167\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    166\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 167\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    168\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain\\chains\\base.py:157\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[0;32m    156\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 157\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs, run_manager\u001b[38;5;241m=\u001b[39mrun_manager)\n\u001b[0;32m    158\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[0;32m    160\u001b[0m     )\n\u001b[0;32m    162\u001b[0m     final_outputs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[0;32m    163\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[0;32m    164\u001b[0m     )\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain\\chains\\llm.py:127\u001b[0m, in \u001b[0;36mLLMChain._call\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call\u001b[39m(\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    124\u001b[0m     inputs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[0;32m    125\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    126\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m--> 127\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate([inputs], run_manager\u001b[38;5;241m=\u001b[39mrun_manager)\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_outputs(response)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain\\chains\\llm.py:139\u001b[0m, in \u001b[0;36mLLMChain.generate\u001b[1;34m(self, input_list, run_manager)\u001b[0m\n\u001b[0;32m    137\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m run_manager\u001b[38;5;241m.\u001b[39mget_child() \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm, BaseLanguageModel):\n\u001b[1;32m--> 139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm\u001b[38;5;241m.\u001b[39mgenerate_prompt(\n\u001b[0;32m    140\u001b[0m         prompts,\n\u001b[0;32m    141\u001b[0m         stop,\n\u001b[0;32m    142\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[0;32m    143\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_kwargs,\n\u001b[0;32m    144\u001b[0m     )\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    146\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm\u001b[38;5;241m.\u001b[39mbind(stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_kwargs)\u001b[38;5;241m.\u001b[39mbatch(\n\u001b[0;32m    147\u001b[0m         cast(\u001b[38;5;28mlist\u001b[39m, prompts), {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks}\n\u001b[0;32m    148\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:766\u001b[0m, in \u001b[0;36mBaseLLM.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    757\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m    758\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[0;32m    759\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    763\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    764\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m    765\u001b[0m     prompt_strings \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_string() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[1;32m--> 766\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(prompt_strings, stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:973\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[1;34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    958\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m get_llm_cache() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m    959\u001b[0m     run_managers \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    960\u001b[0m         callback_manager\u001b[38;5;241m.\u001b[39mon_llm_start(\n\u001b[0;32m    961\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_serialized,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    971\u001b[0m         )\n\u001b[0;32m    972\u001b[0m     ]\n\u001b[1;32m--> 973\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_helper(\n\u001b[0;32m    974\u001b[0m         prompts,\n\u001b[0;32m    975\u001b[0m         stop,\n\u001b[0;32m    976\u001b[0m         run_managers,\n\u001b[0;32m    977\u001b[0m         new_arg_supported\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m(new_arg_supported),\n\u001b[0;32m    978\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    979\u001b[0m     )\n\u001b[0;32m    980\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing_prompts) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    981\u001b[0m     run_managers \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    982\u001b[0m         callback_managers[idx]\u001b[38;5;241m.\u001b[39mon_llm_start(\n\u001b[0;32m    983\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_serialized,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    990\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m missing_prompt_idxs\n\u001b[0;32m    991\u001b[0m     ]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:792\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[1;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[0;32m    781\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_generate_helper\u001b[39m(\n\u001b[0;32m    782\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    783\u001b[0m     prompts: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    788\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    789\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m    790\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    791\u001b[0m         output \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 792\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(\n\u001b[0;32m    793\u001b[0m                 prompts,\n\u001b[0;32m    794\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    795\u001b[0m                 \u001b[38;5;66;03m# TODO: support multiple run managers\u001b[39;00m\n\u001b[0;32m    796\u001b[0m                 run_manager\u001b[38;5;241m=\u001b[39mrun_managers[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    797\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    798\u001b[0m             )\n\u001b[0;32m    799\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    800\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(prompts, stop\u001b[38;5;241m=\u001b[39mstop)\n\u001b[0;32m    801\u001b[0m         )\n\u001b[0;32m    802\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    803\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_community\\llms\\huggingface_pipeline.py:285\u001b[0m, in \u001b[0;36mHuggingFacePipeline._generate\u001b[1;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    282\u001b[0m batch_prompts \u001b[38;5;241m=\u001b[39m prompts[i : i \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size]\n\u001b[0;32m    284\u001b[0m \u001b[38;5;66;03m# Process batch of prompts\u001b[39;00m\n\u001b[1;32m--> 285\u001b[0m responses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpipeline(\n\u001b[0;32m    286\u001b[0m     batch_prompts,\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpipeline_kwargs,\n\u001b[0;32m    288\u001b[0m )\n\u001b[0;32m    290\u001b[0m \u001b[38;5;66;03m# Process each response in the batch\u001b[39;00m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j, response \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(responses):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\pipelines\\text_generation.py:302\u001b[0m, in \u001b[0;36mTextGenerationPipeline.__call__\u001b[1;34m(self, text_inputs, **kwargs)\u001b[0m\n\u001b[0;32m    300\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    301\u001b[0m                 \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mlist\u001b[39m(chats), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 302\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(text_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\pipelines\\base.py:1412\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[1;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1408\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m can_use_iterator:\n\u001b[0;32m   1409\u001b[0m     final_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iterator(\n\u001b[0;32m   1410\u001b[0m         inputs, num_workers, batch_size, preprocess_params, forward_params, postprocess_params\n\u001b[0;32m   1411\u001b[0m     )\n\u001b[1;32m-> 1412\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(final_iterator)\n\u001b[0;32m   1413\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n\u001b[0;32m   1414\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\pipelines\\pt_utils.py:124\u001b[0m, in \u001b[0;36mPipelineIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_item()\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# We're out of items within a batch\u001b[39;00m\n\u001b[1;32m--> 124\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterator)\n\u001b[0;32m    125\u001b[0m processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfer(item, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams)\n\u001b[0;32m    126\u001b[0m \u001b[38;5;66;03m# We now have a batch of \"inferred things\".\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\pipelines\\pt_utils.py:125\u001b[0m, in \u001b[0;36mPipelineIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# We're out of items within a batch\u001b[39;00m\n\u001b[0;32m    124\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterator)\n\u001b[1;32m--> 125\u001b[0m processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfer(item, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams)\n\u001b[0;32m    126\u001b[0m \u001b[38;5;66;03m# We now have a batch of \"inferred things\".\u001b[39;00m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;66;03m# Try to infer the size of the batch\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\pipelines\\base.py:1338\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[1;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[0;32m   1336\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[0;32m   1337\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m-> 1338\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward(model_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mforward_params)\n\u001b[0;32m   1339\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m   1340\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\pipelines\\text_generation.py:400\u001b[0m, in \u001b[0;36mTextGenerationPipeline._forward\u001b[1;34m(self, model_inputs, **generate_kwargs)\u001b[0m\n\u001b[0;32m    397\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneration_config\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m generate_kwargs:\n\u001b[0;32m    398\u001b[0m     generate_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneration_config\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgeneration_config\n\u001b[1;32m--> 400\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mgenerate(input_ids\u001b[38;5;241m=\u001b[39minput_ids, attention_mask\u001b[38;5;241m=\u001b[39mattention_mask, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mgenerate_kwargs)\n\u001b[0;32m    402\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, ModelOutput):\n\u001b[0;32m    403\u001b[0m     generated_sequence \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39msequences\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\generation\\utils.py:2597\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[0m\n\u001b[0;32m   2589\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[0;32m   2590\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m   2591\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[0;32m   2592\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[0;32m   2593\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   2594\u001b[0m     )\n\u001b[0;32m   2596\u001b[0m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[1;32m-> 2597\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sample(\n\u001b[0;32m   2598\u001b[0m         input_ids,\n\u001b[0;32m   2599\u001b[0m         logits_processor\u001b[38;5;241m=\u001b[39mprepared_logits_processor,\n\u001b[0;32m   2600\u001b[0m         stopping_criteria\u001b[38;5;241m=\u001b[39mprepared_stopping_criteria,\n\u001b[0;32m   2601\u001b[0m         generation_config\u001b[38;5;241m=\u001b[39mgeneration_config,\n\u001b[0;32m   2602\u001b[0m         synced_gpus\u001b[38;5;241m=\u001b[39msynced_gpus,\n\u001b[0;32m   2603\u001b[0m         streamer\u001b[38;5;241m=\u001b[39mstreamer,\n\u001b[0;32m   2604\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   2605\u001b[0m     )\n\u001b[0;32m   2607\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[0;32m   2608\u001b[0m     \u001b[38;5;66;03m# 11. interleave input_ids with `num_beams` additional sequences per batch\u001b[39;00m\n\u001b[0;32m   2609\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[0;32m   2610\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m   2611\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   2612\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[0;32m   2613\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   2614\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\generation\\utils.py:3557\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[1;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[0;32m   3554\u001b[0m model_inputs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_hidden_states\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_hidden_states} \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;28;01melse\u001b[39;00m {})\n\u001b[0;32m   3556\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_prefill:\n\u001b[1;32m-> 3557\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_inputs, return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   3558\u001b[0m     is_prefill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   3559\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:1210\u001b[0m, in \u001b[0;36mGPT2LMHeadModel.forward\u001b[1;34m(self, input_ids, past_key_values, cache_position, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;124;03minput_ids (`torch.LongTensor` of shape `(batch_size, input_ids_length)`):\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;124;03m    `input_ids_length` = `sequence_length` if `past_key_values` is `None` else\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1206\u001b[0m \u001b[38;5;124;03m    are ignored (masked), the loss is only computed for labels in `[0, ..., config.vocab_size]`\u001b[39;00m\n\u001b[0;32m   1207\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1208\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1210\u001b[0m transformer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer(\n\u001b[0;32m   1211\u001b[0m     input_ids,\n\u001b[0;32m   1212\u001b[0m     past_key_values\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[0;32m   1213\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m   1214\u001b[0m     cache_position\u001b[38;5;241m=\u001b[39mcache_position,\n\u001b[0;32m   1215\u001b[0m     token_type_ids\u001b[38;5;241m=\u001b[39mtoken_type_ids,\n\u001b[0;32m   1216\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m   1217\u001b[0m     head_mask\u001b[38;5;241m=\u001b[39mhead_mask,\n\u001b[0;32m   1218\u001b[0m     inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds,\n\u001b[0;32m   1219\u001b[0m     encoder_hidden_states\u001b[38;5;241m=\u001b[39mencoder_hidden_states,\n\u001b[0;32m   1220\u001b[0m     encoder_attention_mask\u001b[38;5;241m=\u001b[39mencoder_attention_mask,\n\u001b[0;32m   1221\u001b[0m     use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[0;32m   1222\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m   1223\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[0;32m   1224\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[0;32m   1225\u001b[0m )\n\u001b[0;32m   1226\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m transformer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1228\u001b[0m \u001b[38;5;66;03m# Set device for model parallelism\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:868\u001b[0m, in \u001b[0;36mGPT2Model.forward\u001b[1;34m(self, input_ids, past_key_values, cache_position, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m    865\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m position_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    866\u001b[0m     position_ids \u001b[38;5;241m=\u001b[39m cache_position\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m--> 868\u001b[0m position_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwpe(position_ids)\n\u001b[0;32m    869\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m inputs_embeds \u001b[38;5;241m+\u001b[39m position_embeds\u001b[38;5;241m.\u001b[39mto(inputs_embeds\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    871\u001b[0m \u001b[38;5;66;03m# Attention mask.\u001b[39;00m\n\u001b[0;32m    872\u001b[0m \u001b[38;5;66;03m# ._update_causal_mask() and ._prepare_4d_causal_attention_mask_with_cache_position() copied from LlamaModel\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\sparse.py:190\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39membedding(\n\u001b[0;32m    191\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m    192\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight,\n\u001b[0;32m    193\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_idx,\n\u001b[0;32m    194\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_norm,\n\u001b[0;32m    195\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm_type,\n\u001b[0;32m    196\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale_grad_by_freq,\n\u001b[0;32m    197\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msparse,\n\u001b[0;32m    198\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\functional.py:2551\u001b[0m, in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   2545\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[0;32m   2546\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[0;32m   2547\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[0;32m   2548\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[0;32m   2549\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[0;32m   2550\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[1;32m-> 2551\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39membedding(weight, \u001b[38;5;28minput\u001b[39m, padding_idx, scale_grad_by_freq, sparse)\n",
      "\u001b[1;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# Step 6. 예시 질의 실행\n",
    "# ===============================\n",
    "\n",
    "# 예시 질의 목록\n",
    "example_queries = [\n",
    "    \"김문수 후보의 GTX 확장 계획은 무엇인가요?\",\n",
    "    # \"이재명 후보는 공공의료를 어떻게 강화하려고 하나요?\",\n",
    "    # \"두 후보는 AI 산업을 어떻게 육성하려고 하나요?\",\n",
    "    # \"서울에서 자취 중인 20대입니다. 주거 지원 공약이 있나요?\",\n",
    "    # \"AI 창업을 준비 중인 청년에게 도움이 될 공약이 있나요?\",\n",
    "    # \"소상공인 지원 공약은 어떤 후보가 더 실질적인가요?\"\n",
    "]\n",
    "\n",
    "# 각 질문에 대해 Agent 실행\n",
    "for q in example_queries:\n",
    "    print(f\"\\n🟡 질문: {q}\\n\")\n",
    "    response = react_agent.run(q)\n",
    "    print(f\"🟢 응답:\\n{response}\\n\")\n",
    "    print(\"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 626
    },
    "id": "4y_6TrmIalii",
    "jupyter": {
     "source_hidden": true
    },
    "outputId": "c3d3126f-5d93-41f0-a0f7-14c5f739a322",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mParsing LLM output produced both a final answer and a parse-able action:: Answer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "ElectionPolicySearch(*args: Any, callbacks: Union[list[langchain_core.callbacks.base.BaseCallbackHandler], langchain_core.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[list[str]] = None, metadata: Optional[dict[str, Any]] = None, **kwargs: Any) -> Any - 대통령 후보 공약을 기반으로 질문에 답하는 도우미 도구입니다.\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [ElectionPolicySearch]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin!\n",
      "\n",
      "Question: 김문수 후보의 GTX 확장 계획은 무엇인가요?\n",
      "Thought: KAINES! Winter. be your contribution contribution of the contracts and public control situations.\n",
      "Observation: The contracts repeat N times\n",
      "Thought: KAINES! Winter. be your contracts\n",
      "Final Answer:\n",
      "A\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \u001b[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m results \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m case \u001b[38;5;129;01min\u001b[39;00m test_cases:\n\u001b[1;32m---> 17\u001b[0m     response \u001b[38;5;241m=\u001b[39m react_agent\u001b[38;5;241m.\u001b[39mrun(case[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m질문\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     18\u001b[0m     matched \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m kw \u001b[38;5;129;01min\u001b[39;00m case[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m기대 키워드\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m kw \u001b[38;5;129;01min\u001b[39;00m response)\n\u001b[0;32m     19\u001b[0m     accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mround\u001b[39m((matched \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(case[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m기대 키워드\u001b[39m\u001b[38;5;124m\"\u001b[39m])) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:191\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    189\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    190\u001b[0m     emit_warning()\n\u001b[1;32m--> 191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain\\chains\\base.py:603\u001b[0m, in \u001b[0;36mChain.run\u001b[1;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[0;32m    601\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    602\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`run` supports only one positional argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 603\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(args[\u001b[38;5;241m0\u001b[39m], callbacks\u001b[38;5;241m=\u001b[39mcallbacks, tags\u001b[38;5;241m=\u001b[39mtags, metadata\u001b[38;5;241m=\u001b[39mmetadata)[\n\u001b[0;32m    604\u001b[0m         _output_key\n\u001b[0;32m    605\u001b[0m     ]\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(kwargs, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, tags\u001b[38;5;241m=\u001b[39mtags, metadata\u001b[38;5;241m=\u001b[39mmetadata)[\n\u001b[0;32m    609\u001b[0m         _output_key\n\u001b[0;32m    610\u001b[0m     ]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:191\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    189\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    190\u001b[0m     emit_warning()\n\u001b[1;32m--> 191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain\\chains\\base.py:386\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[0;32m    355\u001b[0m \n\u001b[0;32m    356\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    377\u001b[0m \u001b[38;5;124;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[0;32m    378\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    379\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    380\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks,\n\u001b[0;32m    381\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m: tags,\n\u001b[0;32m    382\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[0;32m    383\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: run_name,\n\u001b[0;32m    384\u001b[0m }\n\u001b[1;32m--> 386\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minvoke(\n\u001b[0;32m    387\u001b[0m     inputs,\n\u001b[0;32m    388\u001b[0m     cast(RunnableConfig, {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m config\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m}),\n\u001b[0;32m    389\u001b[0m     return_only_outputs\u001b[38;5;241m=\u001b[39mreturn_only_outputs,\n\u001b[0;32m    390\u001b[0m     include_run_info\u001b[38;5;241m=\u001b[39minclude_run_info,\n\u001b[0;32m    391\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain\\chains\\base.py:167\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    166\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 167\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    168\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain\\chains\\base.py:157\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[0;32m    156\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 157\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs, run_manager\u001b[38;5;241m=\u001b[39mrun_manager)\n\u001b[0;32m    158\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[0;32m    160\u001b[0m     )\n\u001b[0;32m    162\u001b[0m     final_outputs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[0;32m    163\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[0;32m    164\u001b[0m     )\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain\\agents\\agent.py:1620\u001b[0m, in \u001b[0;36mAgentExecutor._call\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m   1618\u001b[0m \u001b[38;5;66;03m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_continue(iterations, time_elapsed):\n\u001b[1;32m-> 1620\u001b[0m     next_step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_take_next_step(\n\u001b[0;32m   1621\u001b[0m         name_to_tool_map,\n\u001b[0;32m   1622\u001b[0m         color_mapping,\n\u001b[0;32m   1623\u001b[0m         inputs,\n\u001b[0;32m   1624\u001b[0m         intermediate_steps,\n\u001b[0;32m   1625\u001b[0m         run_manager\u001b[38;5;241m=\u001b[39mrun_manager,\n\u001b[0;32m   1626\u001b[0m     )\n\u001b[0;32m   1627\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[0;32m   1628\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_return(\n\u001b[0;32m   1629\u001b[0m             next_step_output, intermediate_steps, run_manager\u001b[38;5;241m=\u001b[39mrun_manager\n\u001b[0;32m   1630\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain\\agents\\agent.py:1328\u001b[0m, in \u001b[0;36mAgentExecutor._take_next_step\u001b[1;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[0;32m   1317\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_take_next_step\u001b[39m(\n\u001b[0;32m   1318\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1319\u001b[0m     name_to_tool_map: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, BaseTool],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1323\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1324\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[AgentFinish, \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mtuple\u001b[39m[AgentAction, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[0;32m   1325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consume_next_step(\n\u001b[0;32m   1326\u001b[0m         [\n\u001b[0;32m   1327\u001b[0m             a\n\u001b[1;32m-> 1328\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_next_step(\n\u001b[0;32m   1329\u001b[0m                 name_to_tool_map,\n\u001b[0;32m   1330\u001b[0m                 color_mapping,\n\u001b[0;32m   1331\u001b[0m                 inputs,\n\u001b[0;32m   1332\u001b[0m                 intermediate_steps,\n\u001b[0;32m   1333\u001b[0m                 run_manager,\n\u001b[0;32m   1334\u001b[0m             )\n\u001b[0;32m   1335\u001b[0m         ]\n\u001b[0;32m   1336\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain\\agents\\agent.py:1354\u001b[0m, in \u001b[0;36mAgentExecutor._iter_next_step\u001b[1;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[0;32m   1351\u001b[0m     intermediate_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_intermediate_steps(intermediate_steps)\n\u001b[0;32m   1353\u001b[0m     \u001b[38;5;66;03m# Call the LLM to see what to do.\u001b[39;00m\n\u001b[1;32m-> 1354\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_action_agent\u001b[38;5;241m.\u001b[39mplan(\n\u001b[0;32m   1355\u001b[0m         intermediate_steps,\n\u001b[0;32m   1356\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child() \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1357\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs,\n\u001b[0;32m   1358\u001b[0m     )\n\u001b[0;32m   1359\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m OutputParserException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1360\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_parsing_errors, \u001b[38;5;28mbool\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain\\agents\\agent.py:800\u001b[0m, in \u001b[0;36mAgent.plan\u001b[1;34m(self, intermediate_steps, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    788\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Given input, decided what to do.\u001b[39;00m\n\u001b[0;32m    789\u001b[0m \n\u001b[0;32m    790\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    797\u001b[0m \u001b[38;5;124;03m    Action specifying what tool to use.\u001b[39;00m\n\u001b[0;32m    798\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    799\u001b[0m full_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_full_inputs(intermediate_steps, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 800\u001b[0m full_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_chain\u001b[38;5;241m.\u001b[39mpredict(callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfull_inputs)\n\u001b[0;32m    801\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_parser\u001b[38;5;241m.\u001b[39mparse(full_output)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain\\chains\\llm.py:319\u001b[0m, in \u001b[0;36mLLMChain.predict\u001b[1;34m(self, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    304\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, callbacks: Callbacks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m    305\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Format prompt with kwargs and pass to LLM.\u001b[39;00m\n\u001b[0;32m    306\u001b[0m \n\u001b[0;32m    307\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;124;03m            completion = llm.predict(adjective=\"funny\")\u001b[39;00m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 319\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(kwargs, callbacks\u001b[38;5;241m=\u001b[39mcallbacks)[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_key]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:191\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    189\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    190\u001b[0m     emit_warning()\n\u001b[1;32m--> 191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain\\chains\\base.py:386\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[0;32m    355\u001b[0m \n\u001b[0;32m    356\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    377\u001b[0m \u001b[38;5;124;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[0;32m    378\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    379\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    380\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks,\n\u001b[0;32m    381\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m: tags,\n\u001b[0;32m    382\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[0;32m    383\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: run_name,\n\u001b[0;32m    384\u001b[0m }\n\u001b[1;32m--> 386\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minvoke(\n\u001b[0;32m    387\u001b[0m     inputs,\n\u001b[0;32m    388\u001b[0m     cast(RunnableConfig, {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m config\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m}),\n\u001b[0;32m    389\u001b[0m     return_only_outputs\u001b[38;5;241m=\u001b[39mreturn_only_outputs,\n\u001b[0;32m    390\u001b[0m     include_run_info\u001b[38;5;241m=\u001b[39minclude_run_info,\n\u001b[0;32m    391\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain\\chains\\base.py:167\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    166\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 167\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    168\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain\\chains\\base.py:157\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[0;32m    156\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 157\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs, run_manager\u001b[38;5;241m=\u001b[39mrun_manager)\n\u001b[0;32m    158\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[0;32m    160\u001b[0m     )\n\u001b[0;32m    162\u001b[0m     final_outputs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[0;32m    163\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[0;32m    164\u001b[0m     )\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain\\chains\\llm.py:127\u001b[0m, in \u001b[0;36mLLMChain._call\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call\u001b[39m(\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    124\u001b[0m     inputs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[0;32m    125\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    126\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m--> 127\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate([inputs], run_manager\u001b[38;5;241m=\u001b[39mrun_manager)\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_outputs(response)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain\\chains\\llm.py:139\u001b[0m, in \u001b[0;36mLLMChain.generate\u001b[1;34m(self, input_list, run_manager)\u001b[0m\n\u001b[0;32m    137\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m run_manager\u001b[38;5;241m.\u001b[39mget_child() \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm, BaseLanguageModel):\n\u001b[1;32m--> 139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm\u001b[38;5;241m.\u001b[39mgenerate_prompt(\n\u001b[0;32m    140\u001b[0m         prompts,\n\u001b[0;32m    141\u001b[0m         stop,\n\u001b[0;32m    142\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[0;32m    143\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_kwargs,\n\u001b[0;32m    144\u001b[0m     )\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    146\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm\u001b[38;5;241m.\u001b[39mbind(stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_kwargs)\u001b[38;5;241m.\u001b[39mbatch(\n\u001b[0;32m    147\u001b[0m         cast(\u001b[38;5;28mlist\u001b[39m, prompts), {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks}\n\u001b[0;32m    148\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:766\u001b[0m, in \u001b[0;36mBaseLLM.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    757\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m    758\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[0;32m    759\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    763\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    764\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m    765\u001b[0m     prompt_strings \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_string() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[1;32m--> 766\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(prompt_strings, stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:973\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[1;34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    958\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m get_llm_cache() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m    959\u001b[0m     run_managers \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    960\u001b[0m         callback_manager\u001b[38;5;241m.\u001b[39mon_llm_start(\n\u001b[0;32m    961\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_serialized,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    971\u001b[0m         )\n\u001b[0;32m    972\u001b[0m     ]\n\u001b[1;32m--> 973\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_helper(\n\u001b[0;32m    974\u001b[0m         prompts,\n\u001b[0;32m    975\u001b[0m         stop,\n\u001b[0;32m    976\u001b[0m         run_managers,\n\u001b[0;32m    977\u001b[0m         new_arg_supported\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m(new_arg_supported),\n\u001b[0;32m    978\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    979\u001b[0m     )\n\u001b[0;32m    980\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing_prompts) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    981\u001b[0m     run_managers \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    982\u001b[0m         callback_managers[idx]\u001b[38;5;241m.\u001b[39mon_llm_start(\n\u001b[0;32m    983\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_serialized,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    990\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m missing_prompt_idxs\n\u001b[0;32m    991\u001b[0m     ]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:792\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[1;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[0;32m    781\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_generate_helper\u001b[39m(\n\u001b[0;32m    782\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    783\u001b[0m     prompts: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    788\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    789\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m    790\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    791\u001b[0m         output \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 792\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(\n\u001b[0;32m    793\u001b[0m                 prompts,\n\u001b[0;32m    794\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    795\u001b[0m                 \u001b[38;5;66;03m# TODO: support multiple run managers\u001b[39;00m\n\u001b[0;32m    796\u001b[0m                 run_manager\u001b[38;5;241m=\u001b[39mrun_managers[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    797\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    798\u001b[0m             )\n\u001b[0;32m    799\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    800\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(prompts, stop\u001b[38;5;241m=\u001b[39mstop)\n\u001b[0;32m    801\u001b[0m         )\n\u001b[0;32m    802\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    803\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_community\\llms\\huggingface_pipeline.py:285\u001b[0m, in \u001b[0;36mHuggingFacePipeline._generate\u001b[1;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    282\u001b[0m batch_prompts \u001b[38;5;241m=\u001b[39m prompts[i : i \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size]\n\u001b[0;32m    284\u001b[0m \u001b[38;5;66;03m# Process batch of prompts\u001b[39;00m\n\u001b[1;32m--> 285\u001b[0m responses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpipeline(\n\u001b[0;32m    286\u001b[0m     batch_prompts,\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpipeline_kwargs,\n\u001b[0;32m    288\u001b[0m )\n\u001b[0;32m    290\u001b[0m \u001b[38;5;66;03m# Process each response in the batch\u001b[39;00m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j, response \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(responses):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\pipelines\\text_generation.py:302\u001b[0m, in \u001b[0;36mTextGenerationPipeline.__call__\u001b[1;34m(self, text_inputs, **kwargs)\u001b[0m\n\u001b[0;32m    300\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    301\u001b[0m                 \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mlist\u001b[39m(chats), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 302\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(text_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\pipelines\\base.py:1412\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[1;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1408\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m can_use_iterator:\n\u001b[0;32m   1409\u001b[0m     final_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iterator(\n\u001b[0;32m   1410\u001b[0m         inputs, num_workers, batch_size, preprocess_params, forward_params, postprocess_params\n\u001b[0;32m   1411\u001b[0m     )\n\u001b[1;32m-> 1412\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(final_iterator)\n\u001b[0;32m   1413\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n\u001b[0;32m   1414\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\pipelines\\pt_utils.py:124\u001b[0m, in \u001b[0;36mPipelineIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_item()\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# We're out of items within a batch\u001b[39;00m\n\u001b[1;32m--> 124\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterator)\n\u001b[0;32m    125\u001b[0m processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfer(item, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams)\n\u001b[0;32m    126\u001b[0m \u001b[38;5;66;03m# We now have a batch of \"inferred things\".\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\pipelines\\pt_utils.py:125\u001b[0m, in \u001b[0;36mPipelineIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# We're out of items within a batch\u001b[39;00m\n\u001b[0;32m    124\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterator)\n\u001b[1;32m--> 125\u001b[0m processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfer(item, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams)\n\u001b[0;32m    126\u001b[0m \u001b[38;5;66;03m# We now have a batch of \"inferred things\".\u001b[39;00m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;66;03m# Try to infer the size of the batch\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\pipelines\\base.py:1338\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[1;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[0;32m   1336\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[0;32m   1337\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m-> 1338\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward(model_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mforward_params)\n\u001b[0;32m   1339\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m   1340\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\pipelines\\text_generation.py:400\u001b[0m, in \u001b[0;36mTextGenerationPipeline._forward\u001b[1;34m(self, model_inputs, **generate_kwargs)\u001b[0m\n\u001b[0;32m    397\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneration_config\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m generate_kwargs:\n\u001b[0;32m    398\u001b[0m     generate_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneration_config\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgeneration_config\n\u001b[1;32m--> 400\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mgenerate(input_ids\u001b[38;5;241m=\u001b[39minput_ids, attention_mask\u001b[38;5;241m=\u001b[39mattention_mask, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mgenerate_kwargs)\n\u001b[0;32m    402\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, ModelOutput):\n\u001b[0;32m    403\u001b[0m     generated_sequence \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39msequences\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\generation\\utils.py:2597\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[0m\n\u001b[0;32m   2589\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[0;32m   2590\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m   2591\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[0;32m   2592\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[0;32m   2593\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   2594\u001b[0m     )\n\u001b[0;32m   2596\u001b[0m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[1;32m-> 2597\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sample(\n\u001b[0;32m   2598\u001b[0m         input_ids,\n\u001b[0;32m   2599\u001b[0m         logits_processor\u001b[38;5;241m=\u001b[39mprepared_logits_processor,\n\u001b[0;32m   2600\u001b[0m         stopping_criteria\u001b[38;5;241m=\u001b[39mprepared_stopping_criteria,\n\u001b[0;32m   2601\u001b[0m         generation_config\u001b[38;5;241m=\u001b[39mgeneration_config,\n\u001b[0;32m   2602\u001b[0m         synced_gpus\u001b[38;5;241m=\u001b[39msynced_gpus,\n\u001b[0;32m   2603\u001b[0m         streamer\u001b[38;5;241m=\u001b[39mstreamer,\n\u001b[0;32m   2604\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   2605\u001b[0m     )\n\u001b[0;32m   2607\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[0;32m   2608\u001b[0m     \u001b[38;5;66;03m# 11. interleave input_ids with `num_beams` additional sequences per batch\u001b[39;00m\n\u001b[0;32m   2609\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[0;32m   2610\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m   2611\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   2612\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[0;32m   2613\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   2614\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\generation\\utils.py:3557\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[1;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[0;32m   3554\u001b[0m model_inputs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_hidden_states\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_hidden_states} \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;28;01melse\u001b[39;00m {})\n\u001b[0;32m   3556\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_prefill:\n\u001b[1;32m-> 3557\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_inputs, return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   3558\u001b[0m     is_prefill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   3559\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:1210\u001b[0m, in \u001b[0;36mGPT2LMHeadModel.forward\u001b[1;34m(self, input_ids, past_key_values, cache_position, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;124;03minput_ids (`torch.LongTensor` of shape `(batch_size, input_ids_length)`):\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;124;03m    `input_ids_length` = `sequence_length` if `past_key_values` is `None` else\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1206\u001b[0m \u001b[38;5;124;03m    are ignored (masked), the loss is only computed for labels in `[0, ..., config.vocab_size]`\u001b[39;00m\n\u001b[0;32m   1207\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1208\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1210\u001b[0m transformer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer(\n\u001b[0;32m   1211\u001b[0m     input_ids,\n\u001b[0;32m   1212\u001b[0m     past_key_values\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[0;32m   1213\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m   1214\u001b[0m     cache_position\u001b[38;5;241m=\u001b[39mcache_position,\n\u001b[0;32m   1215\u001b[0m     token_type_ids\u001b[38;5;241m=\u001b[39mtoken_type_ids,\n\u001b[0;32m   1216\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m   1217\u001b[0m     head_mask\u001b[38;5;241m=\u001b[39mhead_mask,\n\u001b[0;32m   1218\u001b[0m     inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds,\n\u001b[0;32m   1219\u001b[0m     encoder_hidden_states\u001b[38;5;241m=\u001b[39mencoder_hidden_states,\n\u001b[0;32m   1220\u001b[0m     encoder_attention_mask\u001b[38;5;241m=\u001b[39mencoder_attention_mask,\n\u001b[0;32m   1221\u001b[0m     use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[0;32m   1222\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m   1223\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[0;32m   1224\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[0;32m   1225\u001b[0m )\n\u001b[0;32m   1226\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m transformer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1228\u001b[0m \u001b[38;5;66;03m# Set device for model parallelism\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:868\u001b[0m, in \u001b[0;36mGPT2Model.forward\u001b[1;34m(self, input_ids, past_key_values, cache_position, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m    865\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m position_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    866\u001b[0m     position_ids \u001b[38;5;241m=\u001b[39m cache_position\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m--> 868\u001b[0m position_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwpe(position_ids)\n\u001b[0;32m    869\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m inputs_embeds \u001b[38;5;241m+\u001b[39m position_embeds\u001b[38;5;241m.\u001b[39mto(inputs_embeds\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    871\u001b[0m \u001b[38;5;66;03m# Attention mask.\u001b[39;00m\n\u001b[0;32m    872\u001b[0m \u001b[38;5;66;03m# ._update_causal_mask() and ._prepare_4d_causal_attention_mask_with_cache_position() copied from LlamaModel\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\sparse.py:190\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39membedding(\n\u001b[0;32m    191\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m    192\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight,\n\u001b[0;32m    193\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_idx,\n\u001b[0;32m    194\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_norm,\n\u001b[0;32m    195\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm_type,\n\u001b[0;32m    196\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale_grad_by_freq,\n\u001b[0;32m    197\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msparse,\n\u001b[0;32m    198\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\functional.py:2551\u001b[0m, in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   2545\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[0;32m   2546\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[0;32m   2547\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[0;32m   2548\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[0;32m   2549\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[0;32m   2550\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[1;32m-> 2551\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39membedding(weight, \u001b[38;5;28minput\u001b[39m, padding_idx, scale_grad_by_freq, sparse)\n",
      "\u001b[1;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# 테스트 질문 및 기대 키워드 정의\n",
    "test_cases = [\n",
    "    {\n",
    "        \"질문\": \"김문수 후보의 GTX 확장 계획은 무엇인가요?\",\n",
    "        \"기대 키워드\": [\"GTX\", \"전국 5대 광역권\", \"수도권\", \"초광역\", \"교통 체증\"]\n",
    "    },\n",
    "    {\n",
    "        \"질문\": \"이재명 후보는 발달장애인 돌봄에 대해 어떤 정책을 제안했나요?\",\n",
    "        \"기대 키워드\": [\"지역돌봄체계\", \"모든 사람의 권리가 보장\", \"국가책임제\"]\n",
    "    }\n",
    "]\n",
    "\n",
    "# 평가 수행\n",
    "results = []\n",
    "for case in test_cases:\n",
    "    response = react_agent.run(case[\"질문\"])\n",
    "    matched = sum(1 for kw in case[\"기대 키워드\"] if kw in response)\n",
    "    accuracy = round((matched / len(case[\"기대 키워드\"])) * 5, 2)\n",
    "    richness = 5 if len(response) > 400 and matched >= 3 else 3 if matched else 1\n",
    "    results.append({\n",
    "        \"질문\": case[\"질문\"],\n",
    "        \"응답\": response,\n",
    "        \"정확성 점수(1~5)\": accuracy,\n",
    "        \"풍부성 점수(1~5)\": richness\n",
    "    })\n",
    "\n",
    "df_result = pd.DataFrame(results)\n",
    "\n",
    "df_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y3cyyTIDfrwX",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 2단계: 프롬프트 개선\n",
    "- 문제의 원인 분석\n",
    "- 문서 검색 (retriever)\t성공적으로 관련 chunk는 찾아냄\n",
    "-  GPT 응답 형식은 응답을 너무 일반화된 문장으로 축소함 → 핵심 키워드 누락\n",
    "-  프롬프트는\t“공약의 수단, 대상, 용어, 수치 등을 구체적으로 제시하라”는 지시가 부족\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8BcZOQQ2gCH5"
   },
   "outputs": [],
   "source": [
    "TAMPLATE_2 = \"\"\"\n",
    "아래 문서는 대통령 후보의 공약이다. 질문에 대해 다음 요소를 포함하여 답변하라:\n",
    "- 정책의 목적\n",
    "- 구체적 수단 (시설, 제도, 법안 등)\n",
    "- 실행 대상 또는 지역\n",
    "- 문서상 등장한 구체적인 단어(용어)를 사용\n",
    "- 한국어로\n",
    "\n",
    "문맥:\n",
    "{context}\n",
    "\n",
    "질문:\n",
    "{question}\n",
    "\n",
    "답변:\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oGhJfPxDgMHq"
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.agents import Tool, initialize_agent\n",
    "from langchain.agents.agent_types import AgentType\n",
    "\n",
    "# 1. API 키 설정\n",
    "# import os\n",
    "# os.environ['OPENAI_API_KEY'] = input(\"Enter your OpenAI API key: \")\n",
    "\n",
    "# ===============================\n",
    "# Step 1. PDF 로딩 및 후보 정보 부여\n",
    "# ===============================\n",
    "file_paths = {\n",
    "    \"이재명\": [\"20250603_대한민국_이재명_10대공약.pdf\", \"20250603_대한민국_이재명_선거공약서.pdf\"],\n",
    "    \"김문수\": [\"20250603_대한민국_김문수_10대공약.pdf\", \"20250603_대한민국_김문수_선거공약서.pdf\"],\n",
    "}\n",
    "\n",
    "all_documents = []\n",
    "for name, paths in file_paths.items():\n",
    "    for path in paths:\n",
    "        loader = PyMuPDFLoader(path)\n",
    "        data = loader.load()\n",
    "        for d in data:\n",
    "            d.metadata[\"candidate\"] = name\n",
    "        all_documents.extend(data)\n",
    "\n",
    "# ===============================\n",
    "# Step 2. 텍스트 분할\n",
    "# ===============================\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=1000, chunk_overlap=200, encoding_name='cl100k_base'\n",
    ")\n",
    "documents = text_splitter.split_documents(all_documents)\n",
    "\n",
    "# ===============================\n",
    "# Step 3. 벡터스토어 생성 (후보 이름 포함)\n",
    "# ===============================\n",
    "embeddings_model = HuggingFaceEmbeddings(\n",
    "    model_name='jhgan/ko-sbert-nli',\n",
    "    model_kwargs={'device':'cpu'},\n",
    "    encode_kwargs={'normalize_embeddings':True},\n",
    ")\n",
    "vectorstore = FAISS.from_documents(documents, embedding=embeddings_model)\n",
    "\n",
    "# ===============================\n",
    "# Step 4. 프롬프트 템플릿 정의 및 QA 체인 구성 (ReAct 사용 가능 구조)\n",
    "# FAISS retriever → 문서 검색 → LLM에 전달 → 응답 반환\n",
    "# ===============================\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=TAMPLATE_2)\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3}) #상위 3개의 유사한 문서 조각(chunks)을 반환함\n",
    "llm = ChatOpenAI(temperature=0.3) #창의성 제어 수치 (0.0 = 완전 결정적, 1.0 = 매우 창의적)\n",
    "\n",
    "#“질문 → 관련 문서 검색 → LLM으로 답변 생성” 흐름을 구성\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type= \"refine\",  # 여러 문서 처리 시 중복 답변 방지 및 단일 호출에 가까운 처리\n",
    "    #\"stuff\", #문서를 어떻게 LLM에 넣을지 방식 설정. stuff는 문서들을 하나로 이어 붙여서 넣는 방식\n",
    "    retriever=retriever,\n",
    "    chain_type_kwargs={\"prompt\": prompt_template} #LLM에게 넘겨줄 프롬프트 템플릿 설정\n",
    ")\n",
    "\n",
    "# ===============================\n",
    "# Step 5. 툴 정의 및 ReAct Agent 구성\n",
    "# Tool 객체로 QA 체인 기능을 wrapping\n",
    "# ===============================\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"ElectionPolicySearch\",\n",
    "        func=qa_chain.run,\n",
    "        description=\"대통령 후보 공약을 기반으로 질문에 답하는 도우미 도구입니다.\"\n",
    "    )\n",
    "]\n",
    "\n",
    "react_agent = initialize_agent(\n",
    "    tools=tools, #Agent가 사용할 수 있는 도구 목록\n",
    "    llm=llm,       #Agent 내부에서 사용하는 언어 모델\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, #\"도구 이름 + 설명\"만 있으면 GPT가 추론을 통해 직접 도구를 골라 사용함\n",
    "    verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 773
    },
    "id": "t2ihpyZFghRl",
    "outputId": "f6da64ee-70d0-4a9a-c181-4d93946a0a01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI should use the ElectionPolicySearch tool to find the information about 김문수 후보의 GTX 확장 계획.\n",
      "Action: ElectionPolicySearch\n",
      "Action Input: \"김문수 후보의 GTX 확장 계획\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m- 정책의 목적: GTX를 수도권에서 전국 5대 광역권으로 확장하여 국토 균형발전 촉진, 지역균형발전과 미래 전략산업 활성화, 교통 체증 해소 및 국민 삶의 질 개선\n",
      "- 구체적 수단: 수도권 GTX 모델을 전국 5대 광역권으로 확장하여 '전국급행철도망' 구축, 광역철도 및 도시철도 확충, 초광역권 메가시티 조성, 미래첨단산업기반 마련을 위한 메가프리존 도입, 중앙정부의 권한과 자원 지방 이양 확대\n",
      "- 실행 대상 또는 지역: 전국 5대 광역권 (수도권, 부울경권, 대구경북권, 충청권, 광주전남권)\n",
      "- 문서상 등장한 구체적인 단어(용어): GTX, 광역철도, 도시철도, 메가시티, 메가프리존, 국토 균형발전, 교통 체증 해소, 국가자치분권회의, 지방교부세, 국가연구개발\n",
      "\n",
      "한국어로 요약하면, 김문수 후보의 GTX 확장 계획은 전국 5대 광역권으로의 확장을 통해 국토 균형발전과 교통 체증 해소를 목표로 하고, 광역철도 및 도시철도 확충, 메가시티 조성, 메가프리존 도입 등의 수단을 활용하여 실행될 예정이며, 전국 5대 광역권이 실행 대상이 될 것입니다.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have gathered all the necessary information about 김문수 후보의 GTX 확장 계획.\n",
      "Final Answer: 김문수 후보의 GTX 확장 계획은 전국 5대 광역권으로의 확장을 통해 국토 균형발전과 교통 체증 해소를 목표로 합니다.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI should use the ElectionPolicySearch tool to find out about Lee Jae-myung's policies on caring for people with developmental disabilities.\n",
      "Action: ElectionPolicySearch\n",
      "Action Input: 이재명 발달장애인 돌봄 정책\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m- 정책의 목적: 발달장애인을 포함한 장애인들에게 생애주기별로 지원을 강화하여 자립을 돕고, 돌봄 서비스를 제공하여 그들의 삶의 질을 향상시키는 것\n",
      "- 구체적 수단: 사회 서비스형 어르신 복지 일자리 확충, 장애인 원스톱 생활지원센터 설치, 건강권 보장, 장애아동과 발달장애인을 위한 생애주기별 지원 강화\n",
      "- 실행 대상 또는 지역: 발달장애인 및 장애인 전반\n",
      "- 문서상 등장한 구체적인 단어(용어): 발달장애인 돌봄, 사회 서비스형 어르신 복지 일자리, 원스톱 생활지원센터, 건강권 보장, 생애주기별 지원\n",
      "- 한국어로: 이재명의 발달장애인 돌봄 정책은 발달장애인을 포함한 장애인들에게 생애주기별로 지원을 강화하여 자립을 돕고, 돌봄 서비스를 제공하여 그들의 삶의 질을 향상시키는 것을 목적으로 합니다. 구체적으로는 사회 서비스형 어르신 복지 일자리 확충, 장애인 원스톱 생활지원센터 설치, 건강권 보장, 장애아동과 발달장애인을 위한 생애주기별 지원을 통해 이루어집니다. 해당 정책은 발달장애인 및 장애인 전반을 대상으로 합니다.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer.\n",
      "\n",
      "Final Answer: 이재명 후보는 발달장애인 돌봄을 강화하여 자립을 돕고, 돌봄 서비스를 제공하여 삶의 질을 향상시키는 정책을 제안했습니다.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"df_result\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"\\uc9c8\\ubb38\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"\\uc774\\uc7ac\\uba85 \\ud6c4\\ubcf4\\ub294 \\ubc1c\\ub2ec\\uc7a5\\uc560\\uc778 \\ub3cc\\ubd04\\uc5d0 \\ub300\\ud574 \\uc5b4\\ub5a4 \\uc815\\ucc45\\uc744 \\uc81c\\uc548\\ud588\\ub098\\uc694?\",\n          \"\\uae40\\ubb38\\uc218 \\ud6c4\\ubcf4\\uc758 GTX \\ud655\\uc7a5 \\uacc4\\ud68d\\uc740 \\ubb34\\uc5c7\\uc778\\uac00\\uc694?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uc751\\ub2f5\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"\\uc774\\uc7ac\\uba85 \\ud6c4\\ubcf4\\ub294 \\ubc1c\\ub2ec\\uc7a5\\uc560\\uc778 \\ub3cc\\ubd04\\uc744 \\uac15\\ud654\\ud558\\uc5ec \\uc790\\ub9bd\\uc744 \\ub3d5\\uace0, \\ub3cc\\ubd04 \\uc11c\\ube44\\uc2a4\\ub97c \\uc81c\\uacf5\\ud558\\uc5ec \\uc0b6\\uc758 \\uc9c8\\uc744 \\ud5a5\\uc0c1\\uc2dc\\ud0a4\\ub294 \\uc815\\ucc45\\uc744 \\uc81c\\uc548\\ud588\\uc2b5\\ub2c8\\ub2e4.\",\n          \"\\uae40\\ubb38\\uc218 \\ud6c4\\ubcf4\\uc758 GTX \\ud655\\uc7a5 \\uacc4\\ud68d\\uc740 \\uc804\\uad6d 5\\ub300 \\uad11\\uc5ed\\uad8c\\uc73c\\ub85c\\uc758 \\ud655\\uc7a5\\uc744 \\ud1b5\\ud574 \\uad6d\\ud1a0 \\uade0\\ud615\\ubc1c\\uc804\\uacfc \\uad50\\ud1b5 \\uccb4\\uc99d \\ud574\\uc18c\\ub97c \\ubaa9\\ud45c\\ub85c \\ud569\\ub2c8\\ub2e4.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uc77c\\uce58 \\ud0a4\\uc6cc\\ub4dc\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uc815\\ud655\\uc131 \\uc810\\uc218(1~5)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.4142135623730951,\n        \"min\": 1.0,\n        \"max\": 3.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          3.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\ud48d\\ubd80\\uc131 \\uc810\\uc218(1~5)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 3,\n        \"max\": 3,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "df_result"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-39df46bd-6ae4-4ec5-bdc3-c18289d0a1d2\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>질문</th>\n",
       "      <th>응답</th>\n",
       "      <th>일치 키워드</th>\n",
       "      <th>정확성 점수(1~5)</th>\n",
       "      <th>풍부성 점수(1~5)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>김문수 후보의 GTX 확장 계획은 무엇인가요?</td>\n",
       "      <td>김문수 후보의 GTX 확장 계획은 전국 5대 광역권으로의 확장을 통해 국토 균형발전...</td>\n",
       "      <td>[GTX, 전국 5대 광역권, 교통 체증]</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>이재명 후보는 발달장애인 돌봄에 대해 어떤 정책을 제안했나요?</td>\n",
       "      <td>이재명 후보는 발달장애인 돌봄을 강화하여 자립을 돕고, 돌봄 서비스를 제공하여 삶의...</td>\n",
       "      <td>[발달장애인]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-39df46bd-6ae4-4ec5-bdc3-c18289d0a1d2')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-39df46bd-6ae4-4ec5-bdc3-c18289d0a1d2 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-39df46bd-6ae4-4ec5-bdc3-c18289d0a1d2');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-27e829e4-83b8-4a94-961c-cac6d15a6bdc\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-27e829e4-83b8-4a94-961c-cac6d15a6bdc')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-27e829e4-83b8-4a94-961c-cac6d15a6bdc button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "  <div id=\"id_0b0df302-72f1-4739-bf67-a833e929bbb2\">\n",
       "    <style>\n",
       "      .colab-df-generate {\n",
       "        background-color: #E8F0FE;\n",
       "        border: none;\n",
       "        border-radius: 50%;\n",
       "        cursor: pointer;\n",
       "        display: none;\n",
       "        fill: #1967D2;\n",
       "        height: 32px;\n",
       "        padding: 0 0 0 0;\n",
       "        width: 32px;\n",
       "      }\n",
       "\n",
       "      .colab-df-generate:hover {\n",
       "        background-color: #E2EBFA;\n",
       "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "        fill: #174EA6;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate {\n",
       "        background-color: #3B4455;\n",
       "        fill: #D2E3FC;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate:hover {\n",
       "        background-color: #434B5C;\n",
       "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "        fill: #FFFFFF;\n",
       "      }\n",
       "    </style>\n",
       "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_result')\"\n",
       "            title=\"Generate code using this dataframe.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    <script>\n",
       "      (() => {\n",
       "      const buttonEl =\n",
       "        document.querySelector('#id_0b0df302-72f1-4739-bf67-a833e929bbb2 button.colab-df-generate');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      buttonEl.onclick = () => {\n",
       "        google.colab.notebook.generateWithVariable('df_result');\n",
       "      }\n",
       "      })();\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                   질문  \\\n",
       "0           김문수 후보의 GTX 확장 계획은 무엇인가요?   \n",
       "1  이재명 후보는 발달장애인 돌봄에 대해 어떤 정책을 제안했나요?   \n",
       "\n",
       "                                                  응답                   일치 키워드  \\\n",
       "0  김문수 후보의 GTX 확장 계획은 전국 5대 광역권으로의 확장을 통해 국토 균형발전...  [GTX, 전국 5대 광역권, 교통 체증]   \n",
       "1  이재명 후보는 발달장애인 돌봄을 강화하여 자립을 돕고, 돌봄 서비스를 제공하여 삶의...                  [발달장애인]   \n",
       "\n",
       "   정확성 점수(1~5)  풍부성 점수(1~5)  \n",
       "0          3.0            3  \n",
       "1          1.0            3  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 테스트 질문 및 기대 키워드 정의\n",
    "test_cases = [\n",
    "    {\n",
    "        \"질문\": \"김문수 후보의 GTX 확장 계획은 무엇인가요?\",\n",
    "        \"기대 키워드\": [\"GTX\", \"전국 5대 광역권\", \"수도권\", \"초광역\", \"교통 체증\"]\n",
    "    },\n",
    "    {\n",
    "        \"질문\": \"이재명 후보는 발달장애인 돌봄에 대해 어떤 정책을 제안했나요?\",\n",
    "        \"기대 키워드\": [\"발달장애인\", \"24시간 돌봄\", \"지역돌봄체계\", \"간병비\", \"공공신탁제도\"]\n",
    "    }\n",
    "]\n",
    "\n",
    "# 평가 수행\n",
    "results = []\n",
    "for case in test_cases:\n",
    "    response = react_agent.run(case[\"질문\"])\n",
    "    matched_keywords = [kw for kw in case[\"기대 키워드\"] if kw in response]\n",
    "    accuracy = round((len(matched_keywords) / len(case[\"기대 키워드\"])) * 5, 2)\n",
    "    richness = 5 if len(response) > 400 and len(matched_keywords) >= 3 else 3 if matched_keywords else 1\n",
    "    results.append({\n",
    "        \"질문\": case[\"질문\"],\n",
    "        \"응답\": response,\n",
    "        \"일치 키워드\": matched_keywords,\n",
    "        \"정확성 점수(1~5)\": accuracy,\n",
    "        \"풍부성 점수(1~5)\": richness\n",
    "    })\n",
    "\n",
    "df_result = pd.DataFrame(results)\n",
    "df_result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fD2QtpWse-b7"
   },
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X6XlPVbw9QXS"
   },
   "source": [
    "# 3단계:성능 검증을 위한 출처 추가\n",
    "- 핵심 변경 사항\n",
    "RetrievalQA 대신 load_qa_chain을 사용하여 문서 출처 포함을 제어할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 327
    },
    "id": "cvdzxDmZ9VAi",
    "outputId": "21658b35-9fac-4faf-c164-f1247fbd07ed"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"df_result\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"\\uc9c8\\ubb38\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"\\uc774\\uc7ac\\uba85 \\ud6c4\\ubcf4\\ub294 \\ubc1c\\ub2ec\\uc7a5\\uc560\\uc778 \\ub3cc\\ubd04\\uc5d0 \\ub300\\ud574 \\uc5b4\\ub5a4 \\uc815\\ucc45\\uc744 \\uc81c\\uc548\\ud588\\ub098\\uc694?\",\n          \"\\uae40\\ubb38\\uc218 \\ud6c4\\ubcf4\\uc758 GTX \\ud655\\uc7a5 \\uacc4\\ud68d\\uc740 \\ubb34\\uc5c7\\uc778\\uac00\\uc694?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uc751\\ub2f5\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"\\uc774\\uc7ac\\uba85 \\ud6c4\\ubcf4\\ub294 \\ubc1c\\ub2ec\\uc7a5\\uc560\\uc778 24\\uc2dc\\uac04 \\ub3cc\\ubd04 \\ub4f1 \\uc7a5\\uc560\\uc778 \\ub9de\\ucda4\\ud615 \\uc9c0\\uc5ed\\ub3cc\\ubd04\\uccb4\\uacc4 \\uad6c\\ucd95\\uc744 \\uc81c\\uc548\\ud588\\uc2b5\\ub2c8\\ub2e4. \\uc774\\ub97c \\ud1b5\\ud574 \\uc7a5\\uc560\\uc778\\ub4e4\\uc758 \\uc0ac\\ud68c\\ucc38\\uc5ec\\ub97c \\ucd09\\uc9c4\\ud558\\uace0 \\uad8c\\ub9ac\\ub97c \\ubcf4\\uc7a5\\ud558\\uace0\\uc790 \\ud569\\ub2c8\\ub2e4.\",\n          \"\\uae40\\ubb38\\uc218 \\ud6c4\\ubcf4\\uc758 GTX \\ud655\\uc7a5 \\uacc4\\ud68d\\uc740 \\uc218\\ub3c4\\uad8c\\uc5d0\\uc11c \\uc804\\uad6d 5\\ub300 \\uad11\\uc5ed\\uad8c\\uc73c\\ub85c \\ud655\\uc7a5\\ud558\\uc5ec \\uad6d\\ud1a0 \\uade0\\ud615\\ubc1c\\uc804\\uc744 \\ucd09\\uc9c4\\ud558\\uace0 \\uc9c0\\uc5ed\\uade0\\ud615\\ubc1c\\uc804\\uacfc \\ubbf8\\ub798 \\uc804\\ub7b5\\uc0b0\\uc5c5 \\ud65c\\uc131\\ud654\\ub97c \\uc704\\ud55c \\ucd08\\uad11\\uc5ed\\uad8c \\uba54\\uac00\\uc2dc\\ud2f0\\ub97c \\ucd94\\uc9c4\\ud558\\ub294 \\uac83\\uc785\\ub2c8\\ub2e4. \\uc774\\ub97c \\uc704\\ud574 \\uc218\\ub3c4\\uad8c GTX \\ubaa8\\ub378\\uc744 \\uc804\\uad6d 5\\ub300 \\uad11\\uc5ed\\uad8c\\uc73c\\ub85c \\ud655\\uc7a5\\ud558\\uc5ec '\\uc804\\uad6d\\uae09\\ud589\\ucca0\\ub3c4\\ub9dd'\\uc744 \\uad6c\\ucd95\\ud558\\uace0, \\uac01 \\uad11\\uc5ed\\uad8c\\ubcc4\\ub85c GTX \\ub178\\uc120\\uc744 \\uac1c\\ud1b5\\ud558\\uace0 \\uc5f0\\uc7a5\\ud558\\ub294 \\ub4f1\\uc758 \\ubc29\\ubc95\\uc744 \\ud1b5\\ud574 \\uc2e4\\ud589\\ub420 \\uc608\\uc815\\uc785\\ub2c8\\ub2e4.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\ucd9c\\ucc98\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uc77c\\uce58 \\ud0a4\\uc6cc\\ub4dc\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uc815\\ud655\\uc131 \\uc810\\uc218(1~5)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7071067811865476,\n        \"min\": 3.0,\n        \"max\": 4.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          3.0,\n          4.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\ud48d\\ubd80\\uc131 \\uc810\\uc218(1~5)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 3,\n        \"max\": 3,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "df_result"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-c69ba55d-ef66-45cc-a8d4-0b711483d386\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>질문</th>\n",
       "      <th>응답</th>\n",
       "      <th>출처</th>\n",
       "      <th>일치 키워드</th>\n",
       "      <th>정확성 점수(1~5)</th>\n",
       "      <th>풍부성 점수(1~5)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>김문수 후보의 GTX 확장 계획은 무엇인가요?</td>\n",
       "      <td>김문수 후보의 GTX 확장 계획은 수도권에서 전국 5대 광역권으로 확장하여 국토 균...</td>\n",
       "      <td>[20250603_대한민국_김문수_10대공약.pdf:p5, 20250603_대한민국...</td>\n",
       "      <td>[GTX, 전국 5대 광역권, 수도권, 초광역]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>이재명 후보는 발달장애인 돌봄에 대해 어떤 정책을 제안했나요?</td>\n",
       "      <td>이재명 후보는 발달장애인 24시간 돌봄 등 장애인 맞춤형 지역돌봄체계 구축을 제안했...</td>\n",
       "      <td>[20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민...</td>\n",
       "      <td>[발달장애인, 24시간 돌봄, 지역돌봄체계]</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c69ba55d-ef66-45cc-a8d4-0b711483d386')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-c69ba55d-ef66-45cc-a8d4-0b711483d386 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-c69ba55d-ef66-45cc-a8d4-0b711483d386');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-d28faff3-bc5e-45b7-82f0-5779204b29c6\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d28faff3-bc5e-45b7-82f0-5779204b29c6')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-d28faff3-bc5e-45b7-82f0-5779204b29c6 button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "  <div id=\"id_e4f4ab00-7b33-407c-9f32-761626136ecb\">\n",
       "    <style>\n",
       "      .colab-df-generate {\n",
       "        background-color: #E8F0FE;\n",
       "        border: none;\n",
       "        border-radius: 50%;\n",
       "        cursor: pointer;\n",
       "        display: none;\n",
       "        fill: #1967D2;\n",
       "        height: 32px;\n",
       "        padding: 0 0 0 0;\n",
       "        width: 32px;\n",
       "      }\n",
       "\n",
       "      .colab-df-generate:hover {\n",
       "        background-color: #E2EBFA;\n",
       "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "        fill: #174EA6;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate {\n",
       "        background-color: #3B4455;\n",
       "        fill: #D2E3FC;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate:hover {\n",
       "        background-color: #434B5C;\n",
       "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "        fill: #FFFFFF;\n",
       "      }\n",
       "    </style>\n",
       "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_result')\"\n",
       "            title=\"Generate code using this dataframe.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    <script>\n",
       "      (() => {\n",
       "      const buttonEl =\n",
       "        document.querySelector('#id_e4f4ab00-7b33-407c-9f32-761626136ecb button.colab-df-generate');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      buttonEl.onclick = () => {\n",
       "        google.colab.notebook.generateWithVariable('df_result');\n",
       "      }\n",
       "      })();\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                   질문  \\\n",
       "0           김문수 후보의 GTX 확장 계획은 무엇인가요?   \n",
       "1  이재명 후보는 발달장애인 돌봄에 대해 어떤 정책을 제안했나요?   \n",
       "\n",
       "                                                  응답  \\\n",
       "0  김문수 후보의 GTX 확장 계획은 수도권에서 전국 5대 광역권으로 확장하여 국토 균...   \n",
       "1  이재명 후보는 발달장애인 24시간 돌봄 등 장애인 맞춤형 지역돌봄체계 구축을 제안했...   \n",
       "\n",
       "                                                  출처  \\\n",
       "0  [20250603_대한민국_김문수_10대공약.pdf:p5, 20250603_대한민국...   \n",
       "1  [20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민...   \n",
       "\n",
       "                       일치 키워드  정확성 점수(1~5)  풍부성 점수(1~5)  \n",
       "0  [GTX, 전국 5대 광역권, 수도권, 초광역]          4.0            3  \n",
       "1    [발달장애인, 24시간 돌봄, 지역돌봄체계]          3.0            3  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 전체 코드 재정리: 출처에 페이지 번호 포함\n",
    "\n",
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "from langchain.agents import Tool, initialize_agent\n",
    "from langchain.agents.agent_types import AgentType\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# ✅ API 키 설정\n",
    "# import os\n",
    "# os.environ['OPENAI_API_KEY'] = input(\"Enter your OpenAI API key: \")\n",
    "\n",
    "# ✅ Step 1. PDF 로딩 및 후보 정보 부여 + 출처 설정 (페이지 포함)\n",
    "file_paths = {\n",
    "    \"이재명\": [\"20250603_대한민국_이재명_10대공약.pdf\", \"20250603_대한민국_이재명_선거공약서.pdf\"],\n",
    "    \"김문수\": [\"20250603_대한민국_김문수_10대공약.pdf\", \"20250603_대한민국_김문수_선거공약서.pdf\"],\n",
    "}\n",
    "all_documents = []\n",
    "for name, paths in file_paths.items():\n",
    "    for path in paths:\n",
    "        loader = PyMuPDFLoader(path)\n",
    "        data = loader.load()\n",
    "        for d in data:\n",
    "            d.metadata[\"candidate\"] = name\n",
    "            page = d.metadata.get(\"page\", \"?\")\n",
    "            d.metadata[\"source\"] = f\"{path.split('/')[-1]}:p{page}\"  # ✅ 출처 형식 수정\n",
    "        all_documents.extend(data)\n",
    "\n",
    "# ✅ Step 2. 텍스트 분할\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=1000, chunk_overlap=200, encoding_name='cl100k_base'\n",
    ")\n",
    "documents = text_splitter.split_documents(all_documents)\n",
    "\n",
    "# ✅ Step 3. 벡터스토어 생성\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name='jhgan/ko-sbert-nli',\n",
    "    model_kwargs={'device': 'cpu'},\n",
    "    encode_kwargs={'normalize_embeddings': True},\n",
    ")\n",
    "vectorstore = FAISS.from_documents(documents, embedding=embedding_model)\n",
    "\n",
    "# ✅ Step 4. 프롬프트 및 QA 체인 정의\n",
    "TAMPLATE_2 = \"\"\"\n",
    "아래 문서는 대통령 후보의 공약이다. 질문에 대해 다음 요소를 포함하여 답변하라:\n",
    "- 정책의 목적\n",
    "- 구체적 수단 (시설, 제도, 법안 등)\n",
    "- 실행 대상 또는 지역\n",
    "- 문서상 등장한 구체적인 단어(용어)를 사용\n",
    "- 반드시 한국어로 답변할 것\n",
    "\n",
    "문맥:\n",
    "{summaries}\n",
    "\n",
    "질문:\n",
    "{question}\n",
    "\n",
    "답변:\n",
    "\"\"\"\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"summaries\", \"question\"],\n",
    "    template=TAMPLATE_2\n",
    ")\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 6})\n",
    "llm = ChatOpenAI(temperature=0.3)\n",
    "\n",
    "qa_chain = RetrievalQAWithSourcesChain.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    chain_type=\"stuff\",\n",
    "    chain_type_kwargs={\"prompt\": prompt_template},\n",
    "    return_source_documents=True  # ✅ 출처 추출하기위해\n",
    ")\n",
    "\n",
    "# ✅ Step 5. ReAct Agent 구성\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"ElectionPolicySearch\",\n",
    "        func=lambda q: qa_chain.invoke({\"question\": q}),  # invoke로 dict 반환\n",
    "        description=\"대통령 후보 공약을 기반으로 질문에 답하는 도우미 도구입니다.\"\n",
    "    )\n",
    "]\n",
    "react_agent = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# ✅ Step 6. 테스트 및 평가\n",
    "test_cases = [\n",
    "    {\n",
    "        \"질문\": \"김문수 후보의 GTX 확장 계획은 무엇인가요?\",\n",
    "        \"기대 키워드\": [\"GTX\", \"전국 5대 광역권\", \"수도권\", \"초광역\", \"교통 체증\"]\n",
    "    },\n",
    "    {\n",
    "        \"질문\": \"이재명 후보는 발달장애인 돌봄에 대해 어떤 정책을 제안했나요?\",\n",
    "        \"기대 키워드\": [\"발달장애인\", \"24시간 돌봄\", \"지역돌봄체계\", \"간병비\", \"공공신탁제도\"]\n",
    "    }\n",
    "]\n",
    "\n",
    "results = []\n",
    "for case in test_cases:\n",
    "    # result = react_agent.run(case[\"질문\"])  # 이 부분은 str만 반환됨\n",
    "    # 전체 정보가 필요할 경우 아래를 직접 수행\n",
    "    qa_result = qa_chain.invoke({\"question\": case[\"질문\"]})\n",
    "    answer = qa_result[\"answer\"]\n",
    "    docs = qa_result.get(\"source_documents\", [])\n",
    "    sources = [f\"{doc.metadata.get('source')}\" for doc in docs]\n",
    "\n",
    "    matched_keywords = [kw for kw in case[\"기대 키워드\"] if kw in answer]\n",
    "    accuracy = round((len(matched_keywords) / len(case[\"기대 키워드\"])) * 5, 2)\n",
    "    richness = 5 if len(answer) > 400 and len(matched_keywords) >= 3 else 3 if matched_keywords else 1\n",
    "\n",
    "    results.append({\n",
    "        \"질문\": case[\"질문\"],\n",
    "        \"응답\": answer,\n",
    "        \"출처\": sources,\n",
    "        \"일치 키워드\": matched_keywords,\n",
    "        \"정확성 점수(1~5)\": accuracy,\n",
    "        \"풍부성 점수(1~5)\": richness\n",
    "    })\n",
    "\n",
    "\n",
    "df_result = pd.DataFrame(results)\n",
    "\n",
    "df_result\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hv4UrFd_JBqr"
   },
   "source": [
    ">  [문제 원인]\n",
    ">  - 김문수 후보에 대한 질의에 이재명 후보의 공약 문서까지 포함되어 검색되고 있다는 것은,\n",
    "현재 RAG 시스템이 후보 구분 없이 전체 문서에서 유사도 기반 검색을 하고 있다는 뜻입니다.\n",
    "\n",
    "> - 현재\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 6})\n",
    "→ 이 설정은 이재명, 김문수 모든 후보의 문서가 하나의 벡터 공간에 저장되어 있고, 질의에 대해 후보 구분 없이 유사 문서를 찾게 만듭니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tRAH0aoYc2jy",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 4단계:FAISS에서 ChromaDB로 변경\n",
    "\n",
    "- Chroma를 사용하면서 후보별 질의와 후보 간 비교까지 지원하려면, 핵심은 candidate 메타데이터를 기준으로 필터링이 가능한 Retriever 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "STFRb3-Yep0d",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "1fb6b880-dde1-4722-f49a-717610de4744"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: chromadb in /usr/local/lib/python3.11/dist-packages (1.0.12)\n",
      "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.2.2.post1)\n",
      "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (2.11.4)\n",
      "Requirement already satisfied: fastapi==0.115.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.115.9)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.34.3)\n",
      "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.11/dist-packages (from chromadb) (2.0.2)\n",
      "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.2.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.13.2)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.22.0)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.33.1)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.33.1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.54b1)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.33.1)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.21.1)\n",
      "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.67.1)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.71.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.3.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.15.3)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (32.0.1)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (9.1.2)\n",
      "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.0.2)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (5.1.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.10.18)\n",
      "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.28.1)\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (13.9.4)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.23.0)\n",
      "Requirement already satisfied: starlette<0.46.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi==0.115.9->chromadb) (0.45.3)\n",
      "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (24.2)\n",
      "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (4.9.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.25.1)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.38.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.32.3)\n",
      "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.4.0)\n",
      "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (0.10)\n",
      "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.4)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.18)\n",
      "Requirement already satisfied: importlib-metadata<8.7.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.6.1)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.70.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.33.1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.33.1)\n",
      "Requirement already satisfied: opentelemetry-proto==1.33.1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.33.1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.54b1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.54b1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.54b1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.54b1)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.54b1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.54b1)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.54b1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.54b1)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation==0.54b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.2)\n",
      "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-asgi==0.54b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (1.9.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (0.4.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (2.19.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.13.2->chromadb) (0.31.4)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (8.2.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
      "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.0)\n",
      "Requirement already satisfied: uvloop>=0.15.1 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.5)\n",
      "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.3.2)\n",
      "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 381
    },
    "id": "SSLF_krQJMHC",
    "outputId": "28545627-0cfd-42de-cd4e-ecb81365eb95"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-bd2052e1f88e>:46: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  vectorstore.persist()\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"df_result\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"\\uc9c8\\ubb38\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"\\uc774\\uc7ac\\uba85 \\ud6c4\\ubcf4\\ub294 \\ubc1c\\ub2ec\\uc7a5\\uc560\\uc778 \\ub3cc\\ubd04\\uc5d0 \\ub300\\ud574 \\uc5b4\\ub5a4 \\uc815\\ucc45\\uc744 \\uc81c\\uc548\\ud588\\ub098\\uc694?\",\n          \"\\uae40\\ubb38\\uc218 \\ud6c4\\ubcf4\\uc758 GTX \\ud655\\uc7a5 \\uacc4\\ud68d\\uc740 \\ubb34\\uc5c7\\uc778\\uac00\\uc694?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uc751\\ub2f5\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"\\uc774\\uc7ac\\uba85 \\ud6c4\\ubcf4\\ub294 \\ubc1c\\ub2ec\\uc7a5\\uc560\\uc778 24\\uc2dc\\uac04 \\ub3cc\\ubd04 \\ub4f1 \\uc7a5\\uc560\\uc778 \\ub9de\\ucda4\\ud615 \\uc9c0\\uc5ed\\ub3cc\\ubd04\\uccb4\\uacc4 \\uad6c\\ucd95\\uc744 \\uc81c\\uc548\\ud588\\uc2b5\\ub2c8\\ub2e4.\",\n          \"\\uae40\\ubb38\\uc218 \\ud6c4\\ubcf4\\uc758 GTX \\ud655\\uc7a5 \\uacc4\\ud68d\\uc740 \\uc218\\ub3c4\\uad8c\\uc744 \\ud3ec\\ud568\\ud55c \\uc804\\uad6d 5\\ub300 \\uad11\\uc5ed\\uad8c\\uc73c\\ub85c \\ud655\\uc7a5\\ud558\\uc5ec \\uad6d\\ud1a0 \\uade0\\ud615\\ubc1c\\uc804\\uc744 \\ucd09\\uc9c4\\ud558\\uace0 \\uc9c0\\uc5ed\\uade0\\ud615\\ubc1c\\uc804\\uacfc \\ubbf8\\ub798 \\uc804\\ub7b5\\uc0b0\\uc5c5 \\ud65c\\uc131\\ud654\\ub97c \\uc704\\ud55c \\ucd08\\uad11\\uc5ed\\uad8c \\uba54\\uac00\\uc2dc\\ud2f0\\ub97c \\ucd94\\uc9c4\\ud558\\ub294 \\uac83\\uc785\\ub2c8\\ub2e4. \\uc774\\ub97c \\uc704\\ud574 \\uc218\\ub3c4\\uad8c GTX \\ubaa8\\ub378\\uc744 \\uc804\\uad6d 5\\ub300 \\uad11\\uc5ed\\uad8c\\uc73c\\ub85c \\ud655\\uc7a5\\ud558\\uc5ec '\\uc804\\uad6d\\uae09\\ud589\\ucca0\\ub3c4\\ub9dd'\\uc744 \\uad6c\\ucd95\\ud558\\uace0, \\uac01 \\uad11\\uc5ed\\uad8c\\ub9c8\\ub2e4 GTX \\ub178\\uc120\\uc744 \\uac1c\\ud1b5\\ud558\\uace0 \\uc5f0\\uc7a5\\ud558\\ub294 \\ubc29\\uc548\\uc744 \\uc81c\\uc2dc\\ud558\\uace0 \\uc788\\uc2b5\\ub2c8\\ub2e4. \\ub610\\ud55c \\uad11\\uc5ed\\ucca0\\ub3c4\\uc640 \\ub3c4\\uc2dc\\ucca0\\ub3c4\\ub97c \\ud655\\ucda9\\ud558\\uc5ec 30\\ubd84 \\ucd9c\\ud1f4\\uadfc \\ud601\\uba85\\uc744 \\uc774\\ub8e8\\uace0 \\uad50\\ud1b5\\uc2dc\\uc124\\uc744 \\ud655\\ucda9\\ud558\\uba70, \\uad50\\uc721, \\uc758\\ub8cc, \\ubb38\\ud654, \\uccb4\\uc721\\uc2dc\\uc124\\uc744 \\ud655\\ucda9\\ud558\\uc5ec \\uad6d\\ubbfc\\uc758 \\uc0b6\\uc758 \\uc9c8\\uc744 \\uac1c\\uc120\\ud558\\uace0\\uc790 \\ud569\\ub2c8\\ub2e4.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\ucd9c\\ucc98\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"20250603_\\ub300\\ud55c\\ubbfc\\uad6d_\\uc774\\uc7ac\\uba85_10\\ub300\\uacf5\\uc57d.pdf:p16, 20250603_\\ub300\\ud55c\\ubbfc\\uad6d_\\uc774\\uc7ac\\uba85_10\\ub300\\uacf5\\uc57d.pdf:p16, 20250603_\\ub300\\ud55c\\ubbfc\\uad6d_\\uc774\\uc7ac\\uba85_10\\ub300\\uacf5\\uc57d.pdf:p14, 20250603_\\ub300\\ud55c\\ubbfc\\uad6d_\\uc774\\uc7ac\\uba85_10\\ub300\\uacf5\\uc57d.pdf:p14, 20250603_\\ub300\\ud55c\\ubbfc\\uad6d_\\uc774\\uc7ac\\uba85_10\\ub300\\uacf5\\uc57d.pdf:p4, 20250603_\\ub300\\ud55c\\ubbfc\\uad6d_\\uc774\\uc7ac\\uba85_10\\ub300\\uacf5\\uc57d.pdf:p4\",\n          \"20250603_\\ub300\\ud55c\\ubbfc\\uad6d_\\uae40\\ubb38\\uc218_10\\ub300\\uacf5\\uc57d.pdf:p5, 20250603_\\ub300\\ud55c\\ubbfc\\uad6d_\\uae40\\ubb38\\uc218_10\\ub300\\uacf5\\uc57d.pdf:p5, 20250603_\\ub300\\ud55c\\ubbfc\\uad6d_\\uae40\\ubb38\\uc218_\\uc120\\uac70\\uacf5\\uc57d\\uc11c.pdf:p25, 20250603_\\ub300\\ud55c\\ubbfc\\uad6d_\\uae40\\ubb38\\uc218_\\uc120\\uac70\\uacf5\\uc57d\\uc11c.pdf:p25, 20250603_\\ub300\\ud55c\\ubbfc\\uad6d_\\uae40\\ubb38\\uc218_\\uc120\\uac70\\uacf5\\uc57d\\uc11c.pdf:p21, 20250603_\\ub300\\ud55c\\ubbfc\\uad6d_\\uae40\\ubb38\\uc218_\\uc120\\uac70\\uacf5\\uc57d\\uc11c.pdf:p21\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uc77c\\uce58 \\ud0a4\\uc6cc\\ub4dc\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"\\ubc1c\\ub2ec\\uc7a5\\uc560\\uc778, 24\\uc2dc\\uac04 \\ub3cc\\ubd04, \\uc9c0\\uc5ed\\ub3cc\\ubd04\\uccb4\\uacc4\",\n          \"GTX, \\uc804\\uad6d 5\\ub300 \\uad11\\uc5ed\\uad8c, \\uc218\\ub3c4\\uad8c, \\ucd08\\uad11\\uc5ed\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uc815\\ud655\\uc131 \\uc810\\uc218(1~5)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7071067811865476,\n        \"min\": 3.0,\n        \"max\": 4.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          3.0,\n          4.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\ud48d\\ubd80\\uc131 \\uc810\\uc218(1~5)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 3,\n        \"max\": 3,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "df_result"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-a438de86-11b3-4b1d-b6a9-f5fb30cc658a\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>질문</th>\n",
       "      <th>응답</th>\n",
       "      <th>출처</th>\n",
       "      <th>일치 키워드</th>\n",
       "      <th>정확성 점수(1~5)</th>\n",
       "      <th>풍부성 점수(1~5)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>김문수 후보의 GTX 확장 계획은 무엇인가요?</td>\n",
       "      <td>김문수 후보의 GTX 확장 계획은 수도권을 포함한 전국 5대 광역권으로 확장하여 국...</td>\n",
       "      <td>20250603_대한민국_김문수_10대공약.pdf:p5, 20250603_대한민국_...</td>\n",
       "      <td>GTX, 전국 5대 광역권, 수도권, 초광역</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>이재명 후보는 발달장애인 돌봄에 대해 어떤 정책을 제안했나요?</td>\n",
       "      <td>이재명 후보는 발달장애인 24시간 돌봄 등 장애인 맞춤형 지역돌봄체계 구축을 제안했...</td>\n",
       "      <td>20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국...</td>\n",
       "      <td>발달장애인, 24시간 돌봄, 지역돌봄체계</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a438de86-11b3-4b1d-b6a9-f5fb30cc658a')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-a438de86-11b3-4b1d-b6a9-f5fb30cc658a button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-a438de86-11b3-4b1d-b6a9-f5fb30cc658a');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-d7df2bef-06c6-494a-bac6-9a71b5a33998\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d7df2bef-06c6-494a-bac6-9a71b5a33998')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-d7df2bef-06c6-494a-bac6-9a71b5a33998 button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "  <div id=\"id_3364c720-6bac-40ab-9ce2-f18f111f8d88\">\n",
       "    <style>\n",
       "      .colab-df-generate {\n",
       "        background-color: #E8F0FE;\n",
       "        border: none;\n",
       "        border-radius: 50%;\n",
       "        cursor: pointer;\n",
       "        display: none;\n",
       "        fill: #1967D2;\n",
       "        height: 32px;\n",
       "        padding: 0 0 0 0;\n",
       "        width: 32px;\n",
       "      }\n",
       "\n",
       "      .colab-df-generate:hover {\n",
       "        background-color: #E2EBFA;\n",
       "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "        fill: #174EA6;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate {\n",
       "        background-color: #3B4455;\n",
       "        fill: #D2E3FC;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate:hover {\n",
       "        background-color: #434B5C;\n",
       "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "        fill: #FFFFFF;\n",
       "      }\n",
       "    </style>\n",
       "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_result')\"\n",
       "            title=\"Generate code using this dataframe.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    <script>\n",
       "      (() => {\n",
       "      const buttonEl =\n",
       "        document.querySelector('#id_3364c720-6bac-40ab-9ce2-f18f111f8d88 button.colab-df-generate');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      buttonEl.onclick = () => {\n",
       "        google.colab.notebook.generateWithVariable('df_result');\n",
       "      }\n",
       "      })();\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                   질문  \\\n",
       "0           김문수 후보의 GTX 확장 계획은 무엇인가요?   \n",
       "1  이재명 후보는 발달장애인 돌봄에 대해 어떤 정책을 제안했나요?   \n",
       "\n",
       "                                                  응답  \\\n",
       "0  김문수 후보의 GTX 확장 계획은 수도권을 포함한 전국 5대 광역권으로 확장하여 국...   \n",
       "1  이재명 후보는 발달장애인 24시간 돌봄 등 장애인 맞춤형 지역돌봄체계 구축을 제안했...   \n",
       "\n",
       "                                                  출처  \\\n",
       "0  20250603_대한민국_김문수_10대공약.pdf:p5, 20250603_대한민국_...   \n",
       "1  20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국...   \n",
       "\n",
       "                     일치 키워드  정확성 점수(1~5)  풍부성 점수(1~5)  \n",
       "0  GTX, 전국 5대 광역권, 수도권, 초광역          4.0            3  \n",
       "1    발달장애인, 24시간 돌봄, 지역돌봄체계          3.0            3  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 후보 이름 자동 감지 포함 전체 코드 (Chroma 기반)\n",
    "\n",
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# ✅ API 키 설정\n",
    "# import os\n",
    "# os.environ['OPENAI_API_KEY'] = input(\"Enter your OpenAI API key: \")\n",
    "\n",
    "# ✅ Step 1. PDF 로딩 및 후보 정보 메타데이터 추가\n",
    "file_paths = {\n",
    "    \"이재명\": [\"20250603_대한민국_이재명_10대공약.pdf\", \"20250603_대한민국_이재명_선거공약서.pdf\"],\n",
    "    \"김문수\": [\"20250603_대한민국_김문수_10대공약.pdf\", \"20250603_대한민국_김문수_선거공약서.pdf\"],\n",
    "}\n",
    "all_documents = []\n",
    "for name, paths in file_paths.items():\n",
    "    for path in paths:\n",
    "        loader = PyMuPDFLoader(path)\n",
    "        data = loader.load()\n",
    "        for d in data:\n",
    "            d.metadata[\"candidate\"] = name\n",
    "            page = d.metadata.get(\"page\", \"?\")\n",
    "            d.metadata[\"source\"] = f\"{os.path.basename(path)}:p{page}\"\n",
    "        all_documents.extend(data)\n",
    "\n",
    "# ✅ Step 2. 텍스트 분할\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=1000, chunk_overlap=200, encoding_name='cl100k_base'\n",
    ")\n",
    "documents = text_splitter.split_documents(all_documents)\n",
    "\n",
    "# ✅ Step 3. Chroma 벡터스토어 생성\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name='jhgan/ko-sbert-nli',\n",
    "    model_kwargs={'device': 'cpu'},\n",
    "    encode_kwargs={'normalize_embeddings': True},\n",
    ")\n",
    "chroma_db_path = \"chroma_db\"\n",
    "vectorstore = Chroma.from_documents(documents, embedding=embedding_model, persist_directory=chroma_db_path)\n",
    "vectorstore.persist()\n",
    "\n",
    "# ✅ Step 4. 프롬프트 및 후보별 QA 체인 정의\n",
    "TEMPLATE = \"\"\"\n",
    "아래 문서는 대통령 후보의 공약이다. 질문에 대해 다음 요소를 포함하여 답변하라:\n",
    "- 정책의 목적\n",
    "- 구체적 수단 (시설, 제도, 법안 등)\n",
    "- 실행 대상 또는 지역\n",
    "- 문서상 등장한 구체적인 단어(용어)를 사용\n",
    "- 반드시 한국어로 답변할 것\n",
    "\n",
    "문맥:\n",
    "{summaries}\n",
    "\n",
    "질문:\n",
    "{question}\n",
    "\n",
    "답변:\n",
    "\"\"\"\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"summaries\", \"question\"],\n",
    "    template=TEMPLATE\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.2)  # 재시도 줄이기\n",
    "\n",
    "retrievers = {\n",
    "    \"이재명\": vectorstore.as_retriever(search_kwargs={\"k\": 6, \"filter\": {\"candidate\": \"이재명\"}}),\n",
    "    \"김문수\": vectorstore.as_retriever(search_kwargs={\"k\": 6, \"filter\": {\"candidate\": \"김문수\"}})\n",
    "}\n",
    "\n",
    "qa_chains = {\n",
    "    name: RetrievalQAWithSourcesChain.from_chain_type(\n",
    "        llm=llm,\n",
    "        retriever=retriever,\n",
    "        chain_type=\"stuff\",\n",
    "        chain_type_kwargs={\"prompt\": prompt_template},\n",
    "        return_source_documents=True\n",
    "    ) for name, retriever in retrievers.items()\n",
    "}\n",
    "\n",
    "# ✅ Step 5. 후보 이름 자동 감지 함수\n",
    "def detect_candidate(question: str):\n",
    "    if \"이재명\" in question:\n",
    "        return \"이재명\"\n",
    "    elif \"김문수\" in question:\n",
    "        return \"김문수\"\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# ✅ Step 6. 테스트 및 평가\n",
    "test_cases = [\n",
    "    {\n",
    "        \"질문\": \"김문수 후보의 GTX 확장 계획은 무엇인가요?\",\n",
    "        \"기대 키워드\": [\"GTX\", \"전국 5대 광역권\", \"수도권\", \"초광역\", \"교통 체증\"]\n",
    "    },\n",
    "    {\n",
    "        \"질문\": \"이재명 후보는 발달장애인 돌봄에 대해 어떤 정책을 제안했나요?\",\n",
    "        \"기대 키워드\": [\"발달장애인\", \"24시간 돌봄\", \"지역돌봄체계\", \"간병비\", \"공공신탁제도\"]\n",
    "    }\n",
    "]\n",
    "\n",
    "results = []\n",
    "for case in test_cases:\n",
    "    candidate = detect_candidate(case[\"질문\"])\n",
    "    if candidate and candidate in qa_chains:\n",
    "        qa_result = qa_chains[candidate].invoke({\"question\": case[\"질문\"]})\n",
    "        answer = qa_result[\"answer\"]\n",
    "        docs = qa_result.get(\"source_documents\", [])\n",
    "        sources = [f\"{doc.metadata.get('source')}\" for doc in docs]\n",
    "\n",
    "        matched_keywords = [kw for kw in case[\"기대 키워드\"] if kw in answer]\n",
    "        accuracy = round((len(matched_keywords) / len(case[\"기대 키워드\"])) * 5, 2)\n",
    "        richness = 5 if len(answer) > 400 and len(matched_keywords) >= 3 else 3 if matched_keywords else 1\n",
    "\n",
    "        results.append({\n",
    "            \"질문\": case[\"질문\"],\n",
    "            \"응답\": answer,\n",
    "            \"출처\": \", \".join(sources),\n",
    "            \"일치 키워드\": \", \".join(matched_keywords),\n",
    "            \"정확성 점수(1~5)\": accuracy,\n",
    "            \"풍부성 점수(1~5)\": richness\n",
    "        })\n",
    "\n",
    "df_result = pd.DataFrame(results)\n",
    "df_result\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k5wdZR4ful4V"
   },
   "source": [
    "# 5단계:고급 프롬프트 적용:prompt chaining\n",
    "- 질문 입력 → 후보 감지 → vectorstore 검색 → GPT 응답\n",
    "- 예: \"이재명 후보의 부동산 정책은?\" → \"이재명\" 추출 → Chroma filter → GPT 응답\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "WQHE_8ExvDCE"
   },
   "outputs": [],
   "source": [
    "# 전체 실행 코드: Prompt Chaining 기반 대통령 후보 공약 질의 시스템\n",
    "\n",
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQAWithSourcesChain, LLMChain\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# ✅ 1. API 설정 및 모델 초기화\n",
    "# import os\n",
    "# os.environ['OPENAI_API_KEY'] = input(\"Enter your OpenAI API key: \")\n",
    "\n",
    "# ✅ 2. 문서 로딩 및 후보 메타데이터 추가\n",
    "file_paths = {\n",
    "    \"이재명\": [\"20250603_대한민국_이재명_10대공약.pdf\", \"20250603_대한민국_이재명_선거공약서.pdf\"],\n",
    "    \"김문수\": [\"20250603_대한민국_김문수_10대공약.pdf\", \"20250603_대한민국_김문수_선거공약서.pdf\"],\n",
    "}\n",
    "all_documents = []\n",
    "for name, paths in file_paths.items():\n",
    "    for path in paths:\n",
    "        loader = PyMuPDFLoader(path)\n",
    "        data = loader.load()\n",
    "        for d in data:\n",
    "            d.metadata[\"candidate\"] = name\n",
    "            page = d.metadata.get(\"page\", \"?\")\n",
    "            d.metadata[\"source\"] = f\"{os.path.basename(path)}:p{page}\"\n",
    "        all_documents.extend(data)\n",
    "\n",
    "# ✅ 3. 텍스트 분할\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=1000, chunk_overlap=200, encoding_name='cl100k_base'\n",
    ")\n",
    "documents = text_splitter.split_documents(all_documents)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ✅ 4. Chroma 벡터 저장소 생성\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name='jhgan/ko-sbert-nli',\n",
    "    model_kwargs={'device': 'cpu'},\n",
    "    encode_kwargs={'normalize_embeddings': True},\n",
    ")\n",
    "vectorstore = Chroma.from_documents(documents, embedding=embedding_model, persist_directory=\"chroma_db\")\n",
    "vectorstore.persist()\n",
    "\n",
    "# ✅ 5. 프롬프트 정의 및 후보별 QA 체인 구성\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"summaries\", \"question\"],\n",
    "    template=\"\"\"\n",
    "아래 문서는 대통령 후보의 공약이다. 질문에 대해 다음 요소를 포함하여 답변하라:\n",
    "- 정책의 목적\n",
    "- 구체적 수단 (시설, 제도, 법안 등)\n",
    "- 실행 대상 또는 지역\n",
    "- 문서상 등장한 구체적인 단어(용어)를 사용\n",
    "- 반드시 한국어로 답변할 것\n",
    "\n",
    "문맥:\n",
    "{summaries}\n",
    "\n",
    "질문:\n",
    "{question}\n",
    "\n",
    "답변:\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "retrievers = {\n",
    "    \"이재명\": vectorstore.as_retriever(search_kwargs={\"k\": 6, \"filter\": {\"candidate\": \"이재명\"}}),\n",
    "    \"김문수\": vectorstore.as_retriever(search_kwargs={\"k\": 6, \"filter\": {\"candidate\": \"김문수\"}})\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\umsh2\\AppData\\Local\\Temp\\ipykernel_3648\\1337776851.py:18: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  candidate_chain = LLMChain(llm=llm, prompt=candidate_prompt)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "llm = ChatOpenAI(temperature=0.3)\n",
    "\n",
    "qa_chains = {\n",
    "    name: RetrievalQAWithSourcesChain.from_chain_type(\n",
    "        llm=llm,\n",
    "        retriever=retriever,\n",
    "        chain_type=\"stuff\",\n",
    "        chain_type_kwargs={\"prompt\": prompt_template},\n",
    "        return_source_documents=True\n",
    "    ) for name, retriever in retrievers.items()\n",
    "}\n",
    "\n",
    "# ✅ 6. 후보명 추출용 체인 구성 (Prompt Chaining 핵심)\n",
    "candidate_prompt = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"다음 질문에서 언급된 대통령 후보의 이름을 정확히 추출하시오.\\n\\n질문: {question}\\n후보 이름:\"\n",
    ")\n",
    "candidate_chain = LLMChain(llm=llm, prompt=candidate_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ✅ 7. 전체 실행 체인\n",
    "def run_prompt_chaining(question: str, expected_keywords: list):\n",
    "    detected_name = candidate_chain.run({\"question\": question}).strip()\n",
    "    candidate = None\n",
    "    for name in qa_chains:\n",
    "        if name in detected_name:\n",
    "            candidate = name\n",
    "            break\n",
    "\n",
    "    if not candidate:\n",
    "        return {\n",
    "            \"질문\": question,\n",
    "            \"후보\": \"감지 실패\",\n",
    "            \"응답\": \"질문에서 후보 이름을 인식하지 못했습니다.\",\n",
    "            \"출처\": \"\",\n",
    "            \"일치 키워드\": \"\",\n",
    "            \"정확성 점수(1~5)\": 1,\n",
    "            \"풍부성 점수(1~5)\": 1\n",
    "        }\n",
    "\n",
    "    qa_result = qa_chains[candidate].invoke({\"question\": question})\n",
    "    answer = qa_result[\"answer\"]\n",
    "    docs = qa_result.get(\"source_documents\", [])\n",
    "    sources = [f\"{doc.metadata.get('source')}\" for doc in docs]\n",
    "\n",
    "    matched_keywords = [kw for kw in expected_keywords if kw in answer]\n",
    "    accuracy = round((len(matched_keywords) / len(expected_keywords)) * 5, 2)\n",
    "    richness = 5 if len(answer) > 400 and len(matched_keywords) >= 3 else 3 if matched_keywords else 1\n",
    "\n",
    "    return {\n",
    "        \"질문\": question,\n",
    "        \"후보\": candidate,\n",
    "        \"응답\": answer,\n",
    "        \"출처\": \", \".join(sources),\n",
    "        \"일치 키워드\": \", \".join(matched_keywords),\n",
    "        \"정확성 점수(1~5)\": accuracy,\n",
    "        \"풍부성 점수(1~5)\": richness\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\umsh2\\AppData\\Local\\Temp\\ipykernel_3648\\118754881.py:3: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  detected_name = candidate_chain.run({\"question\": question}).strip()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>질문</th>\n",
       "      <th>후보</th>\n",
       "      <th>응답</th>\n",
       "      <th>출처</th>\n",
       "      <th>일치 키워드</th>\n",
       "      <th>정확성 점수(1~5)</th>\n",
       "      <th>풍부성 점수(1~5)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>김문수 후보의 GTX 확장 계획은 무엇인가요?</td>\n",
       "      <td>김문수</td>\n",
       "      <td>김문수 후보의 GTX 확장 계획은 수도권에서 전국 5대 광역권으로 확장하여 국토 균형발전을 촉진하고 지역균형발전과 미래 전략산업 활성화를 위한 초광역권 메가시티를 추진하는 것입니다. 이를 위해 수도권 GTX 모델을 전국 5대 광역권으로 확장하여 '전국급행철도망'을 구축하고, 각 광역권마다 GTX 노선을 개통하고 연장하는 방안을 제시하고 있습니다. 또한 광역철도 및 도시철도를 확충하여 30분 출퇴근 혁명을 이루고 교통시설을 확충하며 교육, 의료, 문화, 체육시설을 확대하여 국민의 삶의 질을 개선하고자 합니다.</td>\n",
       "      <td>20250603_대한민국_김문수_10대공약.pdf:p5, 20250603_대한민국_김문수_10대공약.pdf:p5, 20250603_대한민국_김문수_10대공약.pdf:p5, 20250603_대한민국_김문수_선거공약서.pdf:p25, 20250603_대한민국_김문수_선거공약서.pdf:p25, 20250603_대한민국_김문수_선거공약서.pdf:p25</td>\n",
       "      <td>GTX, 전국 5대 광역권, 수도권, 초광역</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>이재명 후보는 발달장애인 돌봄에 대해 어떤 정책을 제안했나요?</td>\n",
       "      <td>이재명</td>\n",
       "      <td>이재명 후보는 발달장애인 24시간 돌봄 등 장애인 맞춤형 지역돌봄체계 구축을 제안했습니다.</td>\n",
       "      <td>20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p14, 20250603_대한민국_이재명_10대공약.pdf:p14, 20250603_대한민국_이재명_10대공약.pdf:p14</td>\n",
       "      <td>발달장애인, 24시간 돌봄, 지역돌봄체계</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   질문   후보  \\\n",
       "0           김문수 후보의 GTX 확장 계획은 무엇인가요?  김문수   \n",
       "1  이재명 후보는 발달장애인 돌봄에 대해 어떤 정책을 제안했나요?  이재명   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                               응답  \\\n",
       "0  김문수 후보의 GTX 확장 계획은 수도권에서 전국 5대 광역권으로 확장하여 국토 균형발전을 촉진하고 지역균형발전과 미래 전략산업 활성화를 위한 초광역권 메가시티를 추진하는 것입니다. 이를 위해 수도권 GTX 모델을 전국 5대 광역권으로 확장하여 '전국급행철도망'을 구축하고, 각 광역권마다 GTX 노선을 개통하고 연장하는 방안을 제시하고 있습니다. 또한 광역철도 및 도시철도를 확충하여 30분 출퇴근 혁명을 이루고 교통시설을 확충하며 교육, 의료, 문화, 체육시설을 확대하여 국민의 삶의 질을 개선하고자 합니다.   \n",
       "1                                                                                                                                                                                                                                              이재명 후보는 발달장애인 24시간 돌봄 등 장애인 맞춤형 지역돌봄체계 구축을 제안했습니다.   \n",
       "\n",
       "                                                                                                                                                                                                     출처  \\\n",
       "0     20250603_대한민국_김문수_10대공약.pdf:p5, 20250603_대한민국_김문수_10대공약.pdf:p5, 20250603_대한민국_김문수_10대공약.pdf:p5, 20250603_대한민국_김문수_선거공약서.pdf:p25, 20250603_대한민국_김문수_선거공약서.pdf:p25, 20250603_대한민국_김문수_선거공약서.pdf:p25   \n",
       "1  20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p14, 20250603_대한민국_이재명_10대공약.pdf:p14, 20250603_대한민국_이재명_10대공약.pdf:p14   \n",
       "\n",
       "                     일치 키워드  정확성 점수(1~5)  풍부성 점수(1~5)  \n",
       "0  GTX, 전국 5대 광역권, 수도권, 초광역          4.0            3  \n",
       "1    발달장애인, 24시간 돌봄, 지역돌봄체계          3.0            3  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# ✅ 8. 테스트 케이스 실행\n",
    "test_cases = [\n",
    "    {\n",
    "        \"질문\": \"김문수 후보의 GTX 확장 계획은 무엇인가요?\",\n",
    "        \"기대 키워드\": [\"GTX\", \"전국 5대 광역권\", \"수도권\", \"초광역\", \"교통 체증\"]\n",
    "    },\n",
    "    {\n",
    "        \"질문\": \"이재명 후보는 발달장애인 돌봄에 대해 어떤 정책을 제안했나요?\",\n",
    "        \"기대 키워드\": [\"발달장애인\", \"24시간 돌봄\", \"지역돌봄체계\", \"간병비\", \"공공신탁제도\"]\n",
    "    }\n",
    "]\n",
    "\n",
    "results = [run_prompt_chaining(tc[\"질문\"], tc[\"기대 키워드\"]) for tc in test_cases]\n",
    "df_final = pd.DataFrame(results)\n",
    "\n",
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>질문</th>\n",
       "      <th>후보</th>\n",
       "      <th>응답</th>\n",
       "      <th>출처</th>\n",
       "      <th>일치 키워드</th>\n",
       "      <th>정확성 점수(1~5)</th>\n",
       "      <th>풍부성 점수(1~5)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>김문수 후보의 GTX 확장 계획은 무엇인가요?</td>\n",
       "      <td>김문수</td>\n",
       "      <td>김문수 후보의 GTX 확장 계획은 수도권에서 전국 5대 광역권으로 확장하여 국토 균형발전을 촉진하고 지역균형발전과 미래 전략산업 활성화를 위한 초광역권 메가시티를 추진하는 것입니다. 이를 위해 수도권 GTX 모델을 전국 5대 광역권으로 확장하여 '전국급행철도망'을 구축하고, 각 광역권마다 GTX 노선을 개통하고 연장하는 방안을 제시하고 있습니다. 또한 광역철도 및 도시철도를 확충하여 30분 출퇴근 혁명을 이루고 교통시설을 확충하며 교육, 의료, 문화, 체육시설을 확대하여 국민의 삶의 질을 개선하고자 합니다.</td>\n",
       "      <td>20250603_대한민국_김문수_10대공약.pdf:p5, 20250603_대한민국_김문수_10대공약.pdf:p5, 20250603_대한민국_김문수_10대공약.pdf:p5, 20250603_대한민국_김문수_선거공약서.pdf:p25, 20250603_대한민국_김문수_선거공약서.pdf:p25, 20250603_대한민국_김문수_선거공약서.pdf:p25</td>\n",
       "      <td>GTX, 전국 5대 광역권, 수도권, 초광역</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>이재명 후보는 발달장애인 돌봄에 대해 어떤 정책을 제안했나요?</td>\n",
       "      <td>이재명</td>\n",
       "      <td>이재명 후보는 발달장애인 24시간 돌봄 등 장애인 맞춤형 지역돌봄체계 구축을 제안했습니다.</td>\n",
       "      <td>20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p14, 20250603_대한민국_이재명_10대공약.pdf:p14, 20250603_대한민국_이재명_10대공약.pdf:p14</td>\n",
       "      <td>발달장애인, 24시간 돌봄, 지역돌봄체계</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   질문   후보  \\\n",
       "0           김문수 후보의 GTX 확장 계획은 무엇인가요?  김문수   \n",
       "1  이재명 후보는 발달장애인 돌봄에 대해 어떤 정책을 제안했나요?  이재명   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                               응답  \\\n",
       "0  김문수 후보의 GTX 확장 계획은 수도권에서 전국 5대 광역권으로 확장하여 국토 균형발전을 촉진하고 지역균형발전과 미래 전략산업 활성화를 위한 초광역권 메가시티를 추진하는 것입니다. 이를 위해 수도권 GTX 모델을 전국 5대 광역권으로 확장하여 '전국급행철도망'을 구축하고, 각 광역권마다 GTX 노선을 개통하고 연장하는 방안을 제시하고 있습니다. 또한 광역철도 및 도시철도를 확충하여 30분 출퇴근 혁명을 이루고 교통시설을 확충하며 교육, 의료, 문화, 체육시설을 확대하여 국민의 삶의 질을 개선하고자 합니다.   \n",
       "1                                                                                                                                                                                                                                              이재명 후보는 발달장애인 24시간 돌봄 등 장애인 맞춤형 지역돌봄체계 구축을 제안했습니다.   \n",
       "\n",
       "                                                                                                                                                                                                     출처  \\\n",
       "0     20250603_대한민국_김문수_10대공약.pdf:p5, 20250603_대한민국_김문수_10대공약.pdf:p5, 20250603_대한민국_김문수_10대공약.pdf:p5, 20250603_대한민국_김문수_선거공약서.pdf:p25, 20250603_대한민국_김문수_선거공약서.pdf:p25, 20250603_대한민국_김문수_선거공약서.pdf:p25   \n",
       "1  20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p14, 20250603_대한민국_이재명_10대공약.pdf:p14, 20250603_대한민국_이재명_10대공약.pdf:p14   \n",
       "\n",
       "                     일치 키워드  정확성 점수(1~5)  풍부성 점수(1~5)  \n",
       "0  GTX, 전국 5대 광역권, 수도권, 초광역          4.0            3  \n",
       "1    발달장애인, 24시간 돌봄, 지역돌봄체계          3.0            3  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모든 열을 넓게 출력할 수 있도록 설정\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.width', None)  # 줄바꿈 없이 가로로 다 출력\n",
    "\n",
    "# 다시 출력\n",
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\umsh2\\AppData\\Local\\Temp\\ipykernel_2836\\3154175888.py:41: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceEmbeddings(model_name='jhgan/ko-sbert-nli', model_kwargs={'device': 'cpu'}, encode_kwargs={'normalize_embeddings': True})\n",
      "C:\\Users\\umsh2\\AppData\\Local\\Temp\\ipykernel_2836\\3154175888.py:43: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  vectorstore.persist()\n",
      "C:\\Users\\umsh2\\AppData\\Local\\Temp\\ipykernel_2836\\3154175888.py:88: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  candidate_chain = LLMChain(llm=llm, prompt=candidate_detect_prompt)\n",
      "C:\\Users\\umsh2\\AppData\\Local\\Temp\\ipykernel_2836\\3154175888.py:156: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
      "  agent = initialize_agent(\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.agents import Tool, initialize_agent\n",
    "from langchain.agents.agent_types import AgentType\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain, RetrievalQAWithSourcesChain\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# ✅ 1. API 설정 및 모델 초기화\n",
    "# import os\n",
    "# os.environ['OPENAI_API_KEY'] = input(\"Enter your OpenAI API key: \")\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.3)\n",
    "\n",
    "# ✅ 후보 정보\n",
    "candidates = [\"이재명\", \"김문수\"]\n",
    "\n",
    "# ✅ 문서 로딩 및 벡터 저장소 생성\n",
    "file_paths = {\n",
    "    \"이재명\": [\"20250603_대한민국_이재명_10대공약.pdf\", \"20250603_대한민국_이재명_선거공약서.pdf\"],\n",
    "    \"김문수\": [\"20250603_대한민국_김문수_10대공약.pdf\", \"20250603_대한민국_김문수_선거공약서.pdf\"],\n",
    "}\n",
    "all_documents = []\n",
    "for name, paths in file_paths.items():\n",
    "    for path in paths:\n",
    "        loader = PyMuPDFLoader(path)\n",
    "        data = loader.load()\n",
    "        for d in data:\n",
    "            d.metadata[\"candidate\"] = name\n",
    "            page = d.metadata.get(\"page\", \"?\")\n",
    "            d.metadata[\"source\"] = f\"{os.path.basename(path)}:p{page}\"\n",
    "        all_documents.extend(data)\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=1000, chunk_overlap=200, encoding_name='cl100k_base')\n",
    "documents = splitter.split_documents(all_documents)\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(model_name='jhgan/ko-sbert-nli', model_kwargs={'device': 'cpu'}, encode_kwargs={'normalize_embeddings': True})\n",
    "vectorstore = Chroma.from_documents(documents, embedding=embedding_model, persist_directory=\"chroma_db\")\n",
    "vectorstore.persist()\n",
    "\n",
    "# ✅ Retriever 및 QA 체인 구성\n",
    "retrievers = {c: vectorstore.as_retriever(search_kwargs={\"k\": 6, \"filter\": {\"candidate\": c}}) for c in candidates}\n",
    "\n",
    "policy_prompt = PromptTemplate(\n",
    "    input_variables=[\"summaries\", \"question\"],\n",
    "    template=\"\"\"\n",
    "아래 문서는 대통령 후보의 공약이다. 질문에 대해 다음 요소를 포함하여 답변하라:\n",
    "- 정책의 목적\n",
    "- 구체적 수단 (시설, 제도, 법안 등)\n",
    "- 실행 대상 또는 지역\n",
    "- 문서상 등장한 구체적인 단어(용어)를 사용\n",
    "- 반드시 한국어로 답변할 것\n",
    "\n",
    "문맥:\n",
    "{summaries}\n",
    "\n",
    "질문:\n",
    "{question}\n",
    "\n",
    "답변:\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "qa_chains = {\n",
    "    name: RetrievalQAWithSourcesChain.from_chain_type(\n",
    "        llm=llm,\n",
    "        retriever=retrievers[name],\n",
    "        chain_type=\"stuff\",\n",
    "        chain_type_kwargs={\"prompt\": policy_prompt},\n",
    "        return_source_documents=True\n",
    "    ) for name in candidates\n",
    "}\n",
    "\n",
    "# ✅ 후보명 추출 체인\n",
    "candidate_detect_prompt = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"\"\"\n",
    "다음 질문에서 언급된 대통령 후보의 이름을 정확히 추출하시오. 두 명 이상일 경우 모두 출력하시오.\n",
    "\n",
    "질문: {question}\n",
    "후보 이름:\n",
    "\"\"\"\n",
    ")\n",
    "candidate_chain = LLMChain(llm=llm, prompt=candidate_detect_prompt)\n",
    "\n",
    "# ✅ 비교 요약 프롬프트\n",
    "compare_prompt = PromptTemplate(\n",
    "    input_variables=[\"cand1\", \"cand2\", \"topic\", \"resp1\", \"resp2\"],\n",
    "    template=\"\"\"\n",
    "아래는 대통령 후보 {cand1}와 {cand2}의 \"{topic}\" 공약에 대한 요약입니다. 다음 형식에 따라 비교하십시오:\n",
    "\n",
    "1. 정책의 목적 비교:\n",
    "2. 구체적 수단 비교:\n",
    "3. 실행 대상 또는 지역 비교:\n",
    "4. 문서상 등장한 구체적 용어 비교:\n",
    "5. 종합 요약 (한국어로):\n",
    "\n",
    "[{cand1}의 공약]:\n",
    "{resp1}\n",
    "\n",
    "[{cand2}의 공약]:\n",
    "{resp2}\n",
    "\n",
    "위 내용을 기반으로 반드시 **한국어로 작성하십시오**.\n",
    "\"\"\"\n",
    ")\n",
    "compare_chain = LLMChain(llm=llm, prompt=compare_prompt)\n",
    "\n",
    "# ✅ 번역 프롬프트 및 체인\n",
    "translation_prompt = PromptTemplate(\n",
    "    input_variables=[\"english_text\"],\n",
    "    template=\"\"\"\n",
    "다음 영어 텍스트를 자연스럽고 정확한 한국어로 번역하십시오:\n",
    "\n",
    "{english_text}\n",
    "\n",
    "번역:\n",
    "\"\"\"\n",
    ")\n",
    "translation_chain = LLMChain(llm=llm, prompt=translation_prompt)\n",
    "\n",
    "# ✅ Tool 정의 (번역 내장)\n",
    "def run_candidate_policy_qa(input):\n",
    "    result = candidate_chain.invoke({\"question\": input})[\"text\"]\n",
    "    target = next((c for c in candidates if c in result), None)\n",
    "    if not target:\n",
    "        return \"후보 이름을 인식할 수 없습니다.\"\n",
    "    answer = qa_chains[target].invoke({\"question\": input})[\"answer\"]\n",
    "    translated = translation_chain.invoke({\"english_text\": answer})[\"text\"]\n",
    "    return f\"Final Answer: {translated}\"\n",
    "\n",
    "def run_policy_compare(input):\n",
    "    result = candidate_chain.invoke({\"question\": input})[\"text\"]\n",
    "    involved = [c for c in candidates if c in result]\n",
    "    if len(involved) != 2:\n",
    "        return \"비교하려는 두 후보를 명확히 질문에 포함해주세요.\"\n",
    "    cand1, cand2 = involved\n",
    "    answer1 = qa_chains[cand1].invoke({\"question\": input})[\"answer\"]\n",
    "    answer2 = qa_chains[cand2].invoke({\"question\": input})[\"answer\"]\n",
    "    comparison = compare_chain.invoke({\"cand1\": cand1, \"cand2\": cand2, \"topic\": input, \"resp1\": answer1, \"resp2\": answer2})[\"text\"]\n",
    "    translated = translation_chain.invoke({\"english_text\": comparison})[\"text\"]\n",
    "    return f\"Final Answer: {translated}\"\n",
    "\n",
    "\n",
    "# ✅ Tool 목록\n",
    "react_tools = [\n",
    "    Tool(name=\"CandidatePolicyQA\", func=run_candidate_policy_qa, description=\"질문에서 후보를 식별하고 해당 공약을 검색함.\"),\n",
    "    Tool(name=\"ComparePolicies\", func=run_policy_compare, description=\"질문에서 두 후보를 식별하고 해당 공약을 비교함.\")\n",
    "]\n",
    "\n",
    "# ✅ ReAct Agent 초기화\n",
    "agent = initialize_agent(\n",
    "    tools=react_tools,\n",
    "    llm=llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True,\n",
    "    agent_kwargs={\n",
    "        \"system_message\": (\n",
    "            \"당신은 반드시 한국어로 사고하고 응답하는 정책 분석 도우미입니다. \"\n",
    "            \"Thought, Action, Observation, Final Answer 형식을 사용, \"\n",
    "            \" Thought와 Final Answer도 반드시 한국어여야 합니다.\"\n",
    "        )\n",
    "    },\n",
    "    handle_parsing_errors=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5단계 이후 작업 수행(수정사항)\n",
    "- 사용자 프로필 및 테스트 케이스 수정\n",
    "- 정확성 점수를 키워드 매칭 대신 임베딩 유사도로 수정\n",
    "- 단어 키워드에서 문장키워드로 수정\n",
    "- 문장키워드 자동 생성하여 임베딩 유사도에 활용\n",
    "- 한 줄 요약 추가하여 표아래에 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>질문</th>\n",
       "      <th>후보</th>\n",
       "      <th>응답</th>\n",
       "      <th>출처</th>\n",
       "      <th>정확성 점수(1~5)</th>\n",
       "      <th>풍부성 점수(1~5)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>대학생 취업과 학자금 문제 해결을 위해 이재명 후보는 어떤 정책을 내놨어?</td>\n",
       "      <td>이재명</td>\n",
       "      <td>정책의 목적은 대학생 취업과 학자금 문제를 해결하기 위한 것입니다. 구체적 수단으로는 자녀 수에 비례한 신용카드 소득공제율 및 공제 한도 상향, 초등학생 예체능학원 및 체육시설 이용료를 교육비 세액공제 대상에 추가하는 것 등이 있습니다. 이 정책은 아이를 키우는 가정을 지원하고, 신혼부부 결혼출산지원을 확대하며, 공공임대주택 공급을 확대하는 등의 방법으로 대학생 취업과 학자금 문제를 해결하고자 합니다. 해당 정책은 이재명 후보의 교육·복지 분야 공약 중 일부로 나타납니다.</td>\n",
       "      <td>20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>수도권 교통문제 해결을 위해 김문수 후보가 제시한 정책은?</td>\n",
       "      <td>김문수</td>\n",
       "      <td>- 정책의 목적: 수도권 교통 체증 해소 및 통근 시간 단축을 통한 국민 삶의 질 개선 - 구체적 수단: GTX를 수도권에서 전국 5대 광역권으로 확장하여 '전국급행철도망' 구축, 역내 광역급행철도(GTX)·광역철도‧도시철도 등을 통한 교통시설 확충 - 실행 대상 또는 지역: 수도권 및 전국 5대 광역권 - 문서상 등장한 구체적인 단어(용어): GTX, 광역철도, 도시철도, 광역급행철도, 메가프리존  김문수 후보는 수도권 교통 문제 해결을 위해 GTX를 수도권에서 전국 5대 광역권으로 확장하고 '전국급행철도망'을 구축하는 정책을 제시했습니다. 또한 역내 광역급행철도(GTX)·광역철도‧도시철도 등을 통해 교통시설을 확충하여 30분 출퇴근 혁명 및 정주환경 대혁신을 이루고자 합니다. 이를 통해 지역균형발전과 미래 전략산업 활성화를 위한 초광역권 메가시티를 추진하고, 국토 균형발전을 촉진하여 국민의 삶의 질을 개선하고자 합니다.</td>\n",
       "      <td>20250603_대한민국_김문수_선거공약서.pdf:p25, 20250603_대한민국_김문수_선거공약서.pdf:p25, 20250603_대한민국_김문수_선거공약서.pdf:p25, 20250603_대한민국_김문수_선거공약서.pdf:p25, 20250603_대한민국_김문수_선거공약서.pdf:p25, 20250603_대한민국_김문수_10대공약.pdf:p5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          질문   후보  \\\n",
       "0  대학생 취업과 학자금 문제 해결을 위해 이재명 후보는 어떤 정책을 내놨어?  이재명   \n",
       "1           수도권 교통문제 해결을 위해 김문수 후보가 제시한 정책은?  김문수   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   응답  \\\n",
       "0                                                                                                                                                                                                          정책의 목적은 대학생 취업과 학자금 문제를 해결하기 위한 것입니다. 구체적 수단으로는 자녀 수에 비례한 신용카드 소득공제율 및 공제 한도 상향, 초등학생 예체능학원 및 체육시설 이용료를 교육비 세액공제 대상에 추가하는 것 등이 있습니다. 이 정책은 아이를 키우는 가정을 지원하고, 신혼부부 결혼출산지원을 확대하며, 공공임대주택 공급을 확대하는 등의 방법으로 대학생 취업과 학자금 문제를 해결하고자 합니다. 해당 정책은 이재명 후보의 교육·복지 분야 공약 중 일부로 나타납니다.   \n",
       "1  - 정책의 목적: 수도권 교통 체증 해소 및 통근 시간 단축을 통한 국민 삶의 질 개선 - 구체적 수단: GTX를 수도권에서 전국 5대 광역권으로 확장하여 '전국급행철도망' 구축, 역내 광역급행철도(GTX)·광역철도‧도시철도 등을 통한 교통시설 확충 - 실행 대상 또는 지역: 수도권 및 전국 5대 광역권 - 문서상 등장한 구체적인 단어(용어): GTX, 광역철도, 도시철도, 광역급행철도, 메가프리존  김문수 후보는 수도권 교통 문제 해결을 위해 GTX를 수도권에서 전국 5대 광역권으로 확장하고 '전국급행철도망'을 구축하는 정책을 제시했습니다. 또한 역내 광역급행철도(GTX)·광역철도‧도시철도 등을 통해 교통시설을 확충하여 30분 출퇴근 혁명 및 정주환경 대혁신을 이루고자 합니다. 이를 통해 지역균형발전과 미래 전략산업 활성화를 위한 초광역권 메가시티를 추진하고, 국토 균형발전을 촉진하여 국민의 삶의 질을 개선하고자 합니다.   \n",
       "\n",
       "                                                                                                                                                                                                    출처  \\\n",
       "0  20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p4   \n",
       "1  20250603_대한민국_김문수_선거공약서.pdf:p25, 20250603_대한민국_김문수_선거공약서.pdf:p25, 20250603_대한민국_김문수_선거공약서.pdf:p25, 20250603_대한민국_김문수_선거공약서.pdf:p25, 20250603_대한민국_김문수_선거공약서.pdf:p25, 20250603_대한민국_김문수_10대공약.pdf:p5   \n",
       "\n",
       "   정확성 점수(1~5)  풍부성 점수(1~5)  \n",
       "0          5.0            3  \n",
       "1          5.0            5  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📌 한 줄 요약:\n",
      "➡️ 이재명 후보의 정책은 대학생 취업과 학자금 문제를 해결하기 위해 아이를 키우는 가정을 지원하고, 교육비 세액공제 대상을 확대하는 방안을 제시하고 있습니다.\n",
      "➡️ 김문수 후보는 GTX를 확장하여 전국급행철도망을 구축하고 교통시설을 확충하여 국민 삶의 질을 개선하고자 합니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQAWithSourcesChain, LLMChain\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# ✅ 사용자 프로필\n",
    "user_profile = \"\"\"\n",
    "나는 수도권에 거주 중이고 통학하는 20대 대학생이야. 취업과 학자금 지원에 관심이 많아.\n",
    "\"\"\"\n",
    "\n",
    "# ✅ PDF 문서 로딩\n",
    "file_paths = {\n",
    "    \"이재명\": [\"20250603_대한민국_이재명_10대공약.pdf\", \"20250603_대한민국_이재명_선거공약서.pdf\"],\n",
    "    \"김문수\": [\"20250603_대한민국_김문수_10대공약.pdf\", \"20250603_대한민국_김문수_선거공약서.pdf\"],\n",
    "}\n",
    "all_documents = []\n",
    "for name, paths in file_paths.items():\n",
    "    for path in paths:\n",
    "        loader = PyMuPDFLoader(path)\n",
    "        data = loader.load()\n",
    "        for d in data:\n",
    "            d.metadata[\"candidate\"] = name\n",
    "            page = d.metadata.get(\"page\", \"?\")\n",
    "            d.metadata[\"source\"] = f\"{os.path.basename(path)}:p{page}\"\n",
    "        all_documents.extend(data)\n",
    "\n",
    "# ✅ 문서 분할\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=1000, chunk_overlap=200, encoding_name='cl100k_base')\n",
    "documents = text_splitter.split_documents(all_documents)\n",
    "\n",
    "# ✅ 벡터스토어 구축\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name='jhgan/ko-sbert-nli',\n",
    "    model_kwargs={'device': 'cpu'},\n",
    "    encode_kwargs={'normalize_embeddings': True},\n",
    ")\n",
    "vectorstore = Chroma.from_documents(documents, embedding=embedding_model, persist_directory=\"chroma_db\")\n",
    "vectorstore.persist()\n",
    "\n",
    "# ✅ 프롬프트 정의\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"profile\", \"summaries\", \"question\"],\n",
    "    template=\"\"\"\n",
    "당신은 정책 분석가입니다. 다음은 사용자 프로필과 대통령 후보의 공약 문서입니다.\n",
    "사용자 프로필에 맞는 정책을 찾아서 설명해주십시오. 질문에 대해 다음 사항을 반드시 포함하여 답변하십시오.\n",
    "\n",
    "[포함 사항]\n",
    "- 정책의 목적\n",
    "- 구체적 수단 (시설, 제도, 법안 등)\n",
    "- 실행 대상 또는 지역\n",
    "- 문서상 등장한 구체적인 단어(용어)를 사용\n",
    "- 반드시 한국어로 답변할 것\n",
    "\n",
    "사용자 프로필\n",
    "{profile}\n",
    "\n",
    "문맥:\n",
    "{summaries}\n",
    "\n",
    "질문:\n",
    "{question}\n",
    "\n",
    "답변:\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "summary_prompt = PromptTemplate(\n",
    "    input_variables=[\"answer\"],\n",
    "    template=\"다음 응답 내용을 바탕으로 한 문장으로 요약해 주세요.\\n\\n응답: {answer}\\n\\n한 줄 요약:\"\n",
    ")\n",
    "summary_chain = LLMChain(llm=ChatOpenAI(temperature=0.3), prompt=summary_prompt)\n",
    "\n",
    "sentence_keyword_prompt = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"\"\"\n",
    "다음 질문을 보고, 이 질문에 답하기 위해 대통령 후보의 정책 문서에서 등장할 것으로 기대되는 핵심 문장형 키워드를 3~5개 생성하세요.\n",
    "각 문장은 해당 정책의 방향, 수단, 대상 등을 포함해야 하며, 실제 문서에서 나올 수 있는 표현이어야 합니다.\n",
    "\n",
    "[질문]\n",
    "{question}\n",
    "\n",
    "[기대 문장형 키워드]\n",
    "1.\n",
    "2.\n",
    "3.\n",
    "\"\"\"\n",
    ")\n",
    "sentence_keyword_chain = LLMChain(llm=ChatOpenAI(temperature=0.3), prompt=sentence_keyword_prompt)\n",
    "\n",
    "def extract_sentence_keywords(question: str):\n",
    "    result = sentence_keyword_chain.run({\"question\": question})\n",
    "    return [line.strip()[2:].strip() for line in result.split(\"\\n\") if line.strip().startswith(tuple(\"12345\"))]\n",
    "\n",
    "# ✅ 후보명 추출 체인\n",
    "candidate_prompt = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"다음 질문에서 언급된 대통령 후보의 이름을 정확히 추출하시오.\\n\\n질문: {question}\\n후보 이름:\"\n",
    ")\n",
    "candidate_chain = LLMChain(llm=ChatOpenAI(temperature=0.3), prompt=candidate_prompt)\n",
    "\n",
    "# ✅ 유사도 모델\n",
    "similarity_model = SentenceTransformer(\"jhgan/ko-sbert-nli\")\n",
    "\n",
    "# ✅ QA 체인 생성\n",
    "retrievers = {\n",
    "    name: vectorstore.as_retriever(search_kwargs={\"k\": 6, \"filter\": {\"candidate\": name}})\n",
    "    for name in file_paths\n",
    "}\n",
    "llm = ChatOpenAI(temperature=0.3)\n",
    "qa_chains = {\n",
    "    name: RetrievalQAWithSourcesChain.from_chain_type(\n",
    "        llm=llm,\n",
    "        retriever=retriever,\n",
    "        chain_type=\"stuff\",\n",
    "        chain_type_kwargs={\"prompt\": prompt_template},\n",
    "        return_source_documents=True\n",
    "    ) for name, retriever in retrievers.items()\n",
    "}\n",
    "\n",
    "# ✅ 실행 함수\n",
    "def run_prompt_chaining(question: str):\n",
    "    auto_keywords = extract_sentence_keywords(question)\n",
    "    detected_name = candidate_chain.invoke({\"question\": question})[\"text\"].strip()\n",
    "    candidate = next((name for name in qa_chains if name in detected_name), None)\n",
    "\n",
    "    if not candidate:\n",
    "        return {\n",
    "            \"질문\": question,\n",
    "            \"후보\": \"감지 실패\",\n",
    "            \"응답\": \"질문에서 후보 이름을 인식하지 못했습니다.\",\n",
    "            \"출처\": \"\",\n",
    "            \"정확성 점수(1~5)\": 1,\n",
    "            \"풍부성 점수(1~5)\": 1,\n",
    "            \"한 줄 요약\": \"한 줄 요약 불가\"\n",
    "        }\n",
    "\n",
    "    qa_result = qa_chains[candidate].invoke({\"profile\": user_profile, \"question\": question})\n",
    "    answer = qa_result[\"answer\"].replace(\"\\n\", \" \").strip()\n",
    "    sources = [doc.metadata.get(\"source\") for doc in qa_result.get(\"source_documents\", [])]\n",
    "\n",
    "    summary = summary_chain.run({\"answer\": answer})\n",
    "\n",
    "    answer_embedding = similarity_model.encode(answer, convert_to_tensor=True)\n",
    "    keyword_embeddings = similarity_model.encode(auto_keywords, convert_to_tensor=True)\n",
    "    similarities = util.cos_sim(answer_embedding, keyword_embeddings)[0].cpu().tolist()\n",
    "    high_score_count = sum(score > 0.4 for score in similarities)\n",
    "    accuracy_score = round((high_score_count / len(auto_keywords)) * 5, 2)\n",
    "    richness = 5 if len(answer) > 400 and high_score_count >= 3 else 3 if high_score_count else 1\n",
    "\n",
    "    return {\n",
    "        \"질문\": question,\n",
    "        \"후보\": candidate,\n",
    "        \"응답\": answer,\n",
    "        \"출처\": \", \".join(sources),\n",
    "        \"정확성 점수(1~5)\": accuracy_score,\n",
    "        \"풍부성 점수(1~5)\": richness,\n",
    "        \"한 줄 요약\": summary\n",
    "    }\n",
    "\n",
    "# ✅ 테스트\n",
    "questions = [\n",
    "    \"대학생 취업과 학자금 문제 해결을 위해 이재명 후보는 어떤 정책을 내놨어?\",\n",
    "    \"수도권 교통문제 해결을 위해 김문수 후보가 제시한 정책은?\"\n",
    "]\n",
    "results = [run_prompt_chaining(q) for q in questions]\n",
    "df_final = pd.DataFrame([{k: v for k, v in row.items() if k != \"한 줄 요약\"} for row in results])\n",
    "display(df_final)\n",
    "\n",
    "print(\"\\n📌 한 줄 요약:\")\n",
    "for row in results:\n",
    "    print(f\"➡️ {row['한 줄 요약']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6단계 코드 반영"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ 통합된 코드 구조\n",
    "\n",
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQAWithSourcesChain, LLMChain\n",
    "from langchain.agents import initialize_agent, Tool, AgentType\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# ✅ 기본 설정\n",
    "llm = ChatOpenAI(temperature=0.3)\n",
    "candidates = [\"이재명\", \"김문수\"]\n",
    "\n",
    "# ✅ 사용자 프로필\n",
    "user_profile = \"\"\"\n",
    "나는 수도권에 거주 중이고 통학하는 20대 대학생이야. 취업과 학자금 지원에 관심이 많아.\n",
    "\"\"\"\n",
    "\n",
    "# ✅ 문서 로딩 및 전처리\n",
    "file_paths = {\n",
    "    \"이재명\": [\"20250603_대한민국_이재명_10대공약.pdf\", \"20250603_대한민국_이재명_선거공약서.pdf\"],\n",
    "    \"김문수\": [\"20250603_대한민국_김문수_10대공약.pdf\", \"20250603_대한민국_김문수_선거공약서.pdf\"],\n",
    "}\n",
    "all_documents = []\n",
    "for name, paths in file_paths.items():\n",
    "    for path in paths:\n",
    "        loader = PyMuPDFLoader(path)\n",
    "        data = loader.load()\n",
    "        for d in data:\n",
    "            d.metadata[\"candidate\"] = name\n",
    "            page = d.metadata.get(\"page\", \"?\")\n",
    "            d.metadata[\"source\"] = f\"{os.path.basename(path)}:p{page}\"\n",
    "        all_documents.extend(data)\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=1000, chunk_overlap=200, encoding_name='cl100k_base')\n",
    "documents = splitter.split_documents(all_documents)\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(model_name='jhgan/ko-sbert-nli', model_kwargs={'device': 'cpu'}, encode_kwargs={'normalize_embeddings': True})\n",
    "vectorstore = Chroma.from_documents(documents, embedding=embedding_model, persist_directory=\"chroma_db\")\n",
    "vectorstore.persist()\n",
    "\n",
    "# ✅ Retriever 및 QA 체인 구성\n",
    "retrievers = {c: vectorstore.as_retriever(search_kwargs={\"k\": 6, \"filter\": {\"candidate\": c}}) for c in candidates}\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"profile\", \"summaries\", \"question\"],\n",
    "    template=\"\"\"\n",
    "당신은 정책 분석가입니다. 다음은 사용자 프로필과 대통령 후보의 공약 문서입니다.\n",
    "사용자 프로필에 맞는 정책을 찾아서 설명해주십시오. 질문에 대해 다음 사항을 반드시 포함하여 답변하십시오.\n",
    "\n",
    "[포함 사항]\n",
    "- 정책의 목적\n",
    "- 구체적 수단 (시설, 제도, 법안 등)\n",
    "- 실행 대상 또는 지역\n",
    "- 문서상 등장한 구체적인 단어(용어)를 사용\n",
    "- 반드시 한국어로 답변할 것\n",
    "\n",
    "사용자 프로필\n",
    "{profile}\n",
    "\n",
    "문맥:\n",
    "{summaries}\n",
    "\n",
    "질문:\n",
    "{question}\n",
    "\n",
    "답변:\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "qa_chains = {\n",
    "    name: RetrievalQAWithSourcesChain.from_chain_type(\n",
    "        llm=llm,\n",
    "        retriever=retrievers[name],\n",
    "        chain_type=\"stuff\",\n",
    "        chain_type_kwargs={\"prompt\": policy_prompt},\n",
    "        return_source_documents=True\n",
    "    ) for name in candidates\n",
    "}\n",
    "\n",
    "# ✅ 후보명 추출, 키워드 추출, 요약\n",
    "candidate_detect_prompt = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"\"\"\n",
    "다음 질문에서 언급된 대통령 후보의 이름을 정확히 추출하시오. 두 명 이상일 경우 모두 출력하시오.\n",
    "\n",
    "질문: {question}\n",
    "후보 이름:\n",
    "\"\"\"\n",
    ")\n",
    "candidate_chain = LLMChain(llm=llm, prompt=candidate_detect_prompt)\n",
    "\n",
    "sentence_keyword_prompt = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"\"\"\n",
    "다음 질문을 보고, 이 질문에 답하기 위해 대통령 후보의 정책 문서에서 등장할 것으로 기대되는 핵심 문장형 키워드를 3~5개 생성하세요.\n",
    "각 문장은 해당 정책의 방향, 수단, 대상 등을 포함해야 하며, 실제 문서에서 나올 수 있는 표현이어야 합니다.\n",
    "\n",
    "[질문]\n",
    "{question}\n",
    "\n",
    "[기대 문장형 키워드]\n",
    "1.\n",
    "2.\n",
    "3.\n",
    "\"\"\"\n",
    ")\n",
    "sentence_keyword_chain = LLMChain(llm=llm, prompt=sentence_keyword_prompt)\n",
    "\n",
    "def extract_sentence_keywords(question: str):\n",
    "    result = sentence_keyword_chain.run({\"question\": question})\n",
    "    return [line.strip()[2:].strip() for line in result.split(\"\\n\") if line.strip().startswith(tuple(\"12345\"))]\n",
    "\n",
    "summary_prompt = PromptTemplate(\n",
    "    input_variables=[\"answer\"],\n",
    "    template=\"\"\"\n",
    "다음 응답 내용을 바탕으로 한 문장으로 요약해 주세요. ~습니다의 어투로 통일해 주세요.\n",
    "\n",
    "응답: {answer}\n",
    "\n",
    "한 줄 요약:\n",
    "\"\"\"\n",
    ")\n",
    "summary_chain = LLMChain(llm=llm, prompt=summary_prompt)\n",
    "\n",
    "# ✅ 번역 & 비교 프롬프트\n",
    "translation_prompt = PromptTemplate(\n",
    "    input_variables=[\"english_text\"],\n",
    "    template=\"\"\"\n",
    "다음 영어 텍스트를 자연스럽고 정확한 한국어로 번역하십시오:\n",
    "\n",
    "{english_text}\n",
    "\n",
    "번역:\n",
    "\"\"\"\n",
    ")\n",
    "translation_chain = LLMChain(llm=llm, prompt=translation_prompt)\n",
    "\n",
    "compare_prompt = PromptTemplate(\n",
    "    input_variables=[\"cand1\", \"cand2\", \"topic\", \"resp1\", \"resp2\"],\n",
    "    template=\"\"\"\n",
    "아래는 대통령 후보 {cand1}와 {cand2}의 \"{topic}\" 공약에 대한 요약입니다. 다음 형식에 따라 비교하십시오:\n",
    "\n",
    "1. 정책의 목적 비교:\n",
    "2. 구체적 수단 비교:\n",
    "3. 실행 대상 또는 지역 비교:\n",
    "4. 문서상 등장한 구체적 용어 비교:\n",
    "5. 종합 요약 (한국어로):\n",
    "\n",
    "[{cand1}의 공약]:\n",
    "{resp1}\n",
    "\n",
    "[{cand2}의 공약]:\n",
    "{resp2}\n",
    "\n",
    "위 내용을 기반으로 반드시 **한국어로 작성하십시오**.\n",
    "\"\"\"\n",
    ")\n",
    "compare_chain = LLMChain(llm=llm, prompt=compare_prompt)\n",
    "\n",
    "# ✅ Tool 정의\n",
    "\n",
    "def run_candidate_policy_qa(input):\n",
    "    result = candidate_chain.invoke({\"question\": input})[\"text\"]\n",
    "    target = next((c for c in candidates if c in result), None)\n",
    "    if not target:\n",
    "        return \"후보 이름을 인식할 수 없습니다.\"\n",
    "    answer = qa_chains[target].invoke({\"profile\": user_profile, \"question\": input})[\"answer\"]\n",
    "    translated = translation_chain.invoke({\"english_text\": answer})[\"text\"]\n",
    "    return f\"Final Answer: {translated}\"\n",
    "\n",
    "def run_policy_compare(input):\n",
    "    result = candidate_chain.invoke({\"question\": input})[\"text\"]\n",
    "    involved = [c for c in candidates if c in result]\n",
    "    if len(involved) != 2:\n",
    "        return \"비교하려는 두 후보를 명확히 질문에 포함해주세요.\"\n",
    "    cand1, cand2 = involved\n",
    "    answer1 = qa_chains[cand1].invoke({\"profile\": user_profile, \"question\": input})[\"answer\"]\n",
    "    answer2 = qa_chains[cand2].invoke({\"profile\": user_profile, \"question\": input})[\"answer\"]\n",
    "    comparison = compare_chain.invoke({\"cand1\": cand1, \"cand2\": cand2, \"topic\": input, \"resp1\": answer1, \"resp2\": answer2})[\"text\"]\n",
    "    translated = translation_chain.invoke({\"english_text\": comparison})[\"text\"]\n",
    "    return f\"Final Answer: {translated}\"\n",
    "\n",
    "# ✅ Agent 구성\n",
    "react_tools = [\n",
    "    Tool(name=\"CandidatePolicyQA\", func=run_candidate_policy_qa, description=\"질문에서 후보를 식별하고 해당 공약을 검색함.\"),\n",
    "    Tool(name=\"ComparePolicies\", func=run_policy_compare, description=\"질문에서 두 후보를 식별하고 해당 공약을 비교함.\")\n",
    "]\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools=react_tools,\n",
    "    llm=llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True,\n",
    "    agent_kwargs={\n",
    "        \"system_message\": (\n",
    "            \"당신은 반드시 한국어로 사고하고 응답하는 정책 분석 도우미입니다. \"\n",
    "            \"Thought, Action, Observation, Final Answer 형식을 사용, \"\n",
    "            \"Thought와 Final Answer도 반드시 한국어여야 합니다.\"\n",
    "        )\n",
    "    },\n",
    "    handle_parsing_errors=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>질문</th>\n",
       "      <th>후보</th>\n",
       "      <th>응답</th>\n",
       "      <th>출처</th>\n",
       "      <th>정확성 점수(1~5)</th>\n",
       "      <th>풍부성 점수(1~5)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>대학생 취업과 학자금 문제 해결을 위해 이재명 후보는 어떤 정책을 내놨어?</td>\n",
       "      <td>이재명</td>\n",
       "      <td>- 정책의 목적: 대학생 취업과 학자금 문제 해결 - 구체적 수단: 자녀 수에 비례한 신용카드 소득공제율‧공제 한도 상향, 초등학생 예체능학원‧체육시설 이용료 교육비 세액공제 대상 추가, 신혼부부 결혼출산지원 확대, 신혼부부 공공임대주택 공급 확대 - 실행 대상 또는 지역: 대학생 및 신혼부부 - 문서상 등장한 구체적인 단어(용어): 자녀 수에 비례한 신용카드 소득공제율, 공제 한도 상향, 초등학생 예체능학원‧체육시설 이용료, 신혼부부 결혼출산지원, 공공임대주택  이재명 후보는 대학생 취업과 학자금 문제를 해결하기 위해 자녀 수에 비례한 신용카드 소득공제율과 공제 한도를 상향하고, 초등학생 교육비 세액공제 대상에 예체능학원‧체육시설 이용료를 추가하는 등의 정책을 내놓았습니다. 또한, 신혼부부를 위한 결혼출산지원 및 공공임대주택 공급 확대도 추진할 예정입니다.</td>\n",
       "      <td>20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>수도권 교통문제 해결을 위해 김문수 후보가 제시한 정책은?</td>\n",
       "      <td>김문수</td>\n",
       "      <td>- 정책의 목적: 수도권 교통문제 해결 - 구체적 수단: 교통 시설 개선, 교통 인프라 확충, 교통 정책 개선 - 실행 대상 또는 지역: 수도권 지역 - 문서상 등장한 구체적인 단어: 교통 시설, 교통 인프라, 교통 정책  김문수 후보가 제시한 정책은 수도권 교통문제 해결을 위해 교통 시설 개선, 교통 인프라 확충, 그리고 교통 정책 개선을 포함하는 것으로 보입니다. 이 정책은 수도권 지역의 교통 문제를 해결하고 교통 효율성을 향상시키는 것을 목표로 합니다.</td>\n",
       "      <td>20250603_대한민국_김문수_선거공약서.pdf:p25, 20250603_대한민국_김문수_선거공약서.pdf:p25, 20250603_대한민국_김문수_선거공약서.pdf:p25, 20250603_대한민국_김문수_선거공약서.pdf:p25, 20250603_대한민국_김문수_선거공약서.pdf:p25, 20250603_대한민국_김문수_선거공약서.pdf:p25</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>이재명과 김문수의 주거지원 정책을 비교해줘.</td>\n",
       "      <td>이재명</td>\n",
       "      <td>이재명의 주거지원 정책은 고령자 친화 주택 및 은퇴자 도시 조성, 공공임대주택 공급 확대 등을 포함하고 있습니다. 이는 고령화 사회에 대한 대응책으로 노인들의 주거 문제를 해결하고 건강한 주거 환경을 조성하는 것을 목표로 합니다.  반면 김문수의 주거지원 정책은 문서에서 언급되지 않았기 때문에 구체적으로 비교할 수 있는 내용이 없습니다. 따라서 김문수의 주거지원 정책에 대한 정보가 추가로 제공되어야 비교 분석이 가능할 것입니다.</td>\n",
       "      <td>20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          질문   후보  \\\n",
       "0  대학생 취업과 학자금 문제 해결을 위해 이재명 후보는 어떤 정책을 내놨어?  이재명   \n",
       "1           수도권 교통문제 해결을 위해 김문수 후보가 제시한 정책은?  김문수   \n",
       "2                   이재명과 김문수의 주거지원 정책을 비교해줘.  이재명   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                              응답  \\\n",
       "0  - 정책의 목적: 대학생 취업과 학자금 문제 해결 - 구체적 수단: 자녀 수에 비례한 신용카드 소득공제율‧공제 한도 상향, 초등학생 예체능학원‧체육시설 이용료 교육비 세액공제 대상 추가, 신혼부부 결혼출산지원 확대, 신혼부부 공공임대주택 공급 확대 - 실행 대상 또는 지역: 대학생 및 신혼부부 - 문서상 등장한 구체적인 단어(용어): 자녀 수에 비례한 신용카드 소득공제율, 공제 한도 상향, 초등학생 예체능학원‧체육시설 이용료, 신혼부부 결혼출산지원, 공공임대주택  이재명 후보는 대학생 취업과 학자금 문제를 해결하기 위해 자녀 수에 비례한 신용카드 소득공제율과 공제 한도를 상향하고, 초등학생 교육비 세액공제 대상에 예체능학원‧체육시설 이용료를 추가하는 등의 정책을 내놓았습니다. 또한, 신혼부부를 위한 결혼출산지원 및 공공임대주택 공급 확대도 추진할 예정입니다.   \n",
       "1                                                                                                                                                                             - 정책의 목적: 수도권 교통문제 해결 - 구체적 수단: 교통 시설 개선, 교통 인프라 확충, 교통 정책 개선 - 실행 대상 또는 지역: 수도권 지역 - 문서상 등장한 구체적인 단어: 교통 시설, 교통 인프라, 교통 정책  김문수 후보가 제시한 정책은 수도권 교통문제 해결을 위해 교통 시설 개선, 교통 인프라 확충, 그리고 교통 정책 개선을 포함하는 것으로 보입니다. 이 정책은 수도권 지역의 교통 문제를 해결하고 교통 효율성을 향상시키는 것을 목표로 합니다.   \n",
       "2                                                                                                                                                                                              이재명의 주거지원 정책은 고령자 친화 주택 및 은퇴자 도시 조성, 공공임대주택 공급 확대 등을 포함하고 있습니다. 이는 고령화 사회에 대한 대응책으로 노인들의 주거 문제를 해결하고 건강한 주거 환경을 조성하는 것을 목표로 합니다.  반면 김문수의 주거지원 정책은 문서에서 언급되지 않았기 때문에 구체적으로 비교할 수 있는 내용이 없습니다. 따라서 김문수의 주거지원 정책에 대한 정보가 추가로 제공되어야 비교 분석이 가능할 것입니다.   \n",
       "\n",
       "                                                                                                                                                                                                     출처  \\\n",
       "0  20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16   \n",
       "1  20250603_대한민국_김문수_선거공약서.pdf:p25, 20250603_대한민국_김문수_선거공약서.pdf:p25, 20250603_대한민국_김문수_선거공약서.pdf:p25, 20250603_대한민국_김문수_선거공약서.pdf:p25, 20250603_대한민국_김문수_선거공약서.pdf:p25, 20250603_대한민국_김문수_선거공약서.pdf:p25   \n",
       "2  20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16   \n",
       "\n",
       "   정확성 점수(1~5)  풍부성 점수(1~5)  \n",
       "0            5            5  \n",
       "1            5            3  \n",
       "2            5            3  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📌 한 줄 요약:\n",
      "➡️ 이재명 후보는 대학생 취업과 학자금 문제를 해결하기 위해 다양한 정책을 내놓았다.\n",
      "➡️ 김문수 후보의 정책은 수도권 교통문제를 해결하기 위해 교통 시설 개선, 인프라 확충, 정책 개선을 포함한다.\n",
      "➡️ 이재명의 주거지원 정책은 고령자와 은퇴자를 위한 주택 지원과 공공임대주택 공급을 포함하고 있으며, 김문수의 정책은 아직 구체적으로 알려지지 않아 비교가 어렵다.\n"
     ]
    }
   ],
   "source": [
    "def extract_sentence_keywords(question: str):\n",
    "    result = sentence_keyword_chain.run({\"question\": question})\n",
    "    return [line.strip()[2:].strip() for line in result.split(\"\\n\") if line.strip().startswith(tuple(\"12345\"))]\n",
    "\n",
    "# ✅ 후보명 추출 체인\n",
    "candidate_prompt = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"다음 질문에서 언급된 대통령 후보의 이름을 정확히 추출하시오.\\n\\n질문: {question}\\n후보 이름:\"\n",
    ")\n",
    "candidate_chain = LLMChain(llm=ChatOpenAI(temperature=0.3), prompt=candidate_prompt)\n",
    "\n",
    "# ✅ 유사도 모델\n",
    "similarity_model = SentenceTransformer(\"jhgan/ko-sbert-nli\")\n",
    "\n",
    "# ✅ QA 체인 생성\n",
    "retrievers = {\n",
    "    name: vectorstore.as_retriever(search_kwargs={\"k\": 6, \"filter\": {\"candidate\": name}})\n",
    "    for name in file_paths\n",
    "}\n",
    "llm = ChatOpenAI(temperature=0.3)\n",
    "qa_chains = {\n",
    "    name: RetrievalQAWithSourcesChain.from_chain_type(\n",
    "        llm=llm,\n",
    "        retriever=retriever,\n",
    "        chain_type=\"stuff\",\n",
    "        chain_type_kwargs={\"prompt\": prompt_template},\n",
    "        return_source_documents=True\n",
    "    ) for name, retriever in retrievers.items()\n",
    "}\n",
    "\n",
    "# ✅ 실행 함수\n",
    "def run_prompt_chaining(question: str):\n",
    "    auto_keywords = extract_sentence_keywords(question)\n",
    "    detected_name = candidate_chain.invoke({\"question\": question})[\"text\"].strip()\n",
    "    candidate = next((name for name in qa_chains if name in detected_name), None)\n",
    "\n",
    "    if not candidate:\n",
    "        return {\n",
    "            \"질문\": question,\n",
    "            \"후보\": \"감지 실패\",\n",
    "            \"응답\": \"질문에서 후보 이름을 인식하지 못했습니다.\",\n",
    "            \"출처\": \"\",\n",
    "            \"정확성 점수(1~5)\": 1,\n",
    "            \"풍부성 점수(1~5)\": 1,\n",
    "            \"한 줄 요약\": \"한 줄 요약 불가\"\n",
    "        }\n",
    "\n",
    "    qa_result = qa_chains[candidate].invoke({\"profile\": user_profile, \"question\": question})\n",
    "    answer = qa_result[\"answer\"].replace(\"\\n\", \" \").strip()\n",
    "    sources = [doc.metadata.get(\"source\") for doc in qa_result.get(\"source_documents\", [])]\n",
    "\n",
    "    summary = summary_chain.run({\"answer\": answer})\n",
    "\n",
    "    answer_embedding = similarity_model.encode(answer, convert_to_tensor=True)\n",
    "    keyword_embeddings = similarity_model.encode(auto_keywords, convert_to_tensor=True)\n",
    "    similarities = util.cos_sim(answer_embedding, keyword_embeddings)[0].cpu().tolist()\n",
    "    high_score_count = sum(score > 0.4 for score in similarities)\n",
    "    accuracy_score = round((high_score_count / len(auto_keywords)) * 5)\n",
    "    richness = 5 if len(answer) > 400 and high_score_count >= 3 else 3 if high_score_count else 1\n",
    "\n",
    "    return {\n",
    "        \"질문\": question,\n",
    "        \"후보\": candidate,\n",
    "        \"응답\": answer,\n",
    "        \"출처\": \", \".join(sources),\n",
    "        \"정확성 점수(1~5)\": accuracy_score,\n",
    "        \"풍부성 점수(1~5)\": richness,\n",
    "        \"한 줄 요약\": summary\n",
    "    }\n",
    "\n",
    "# ✅ 테스트\n",
    "questions = [\n",
    "    \"대학생 취업과 학자금 문제 해결을 위해 이재명 후보는 어떤 정책을 내놨어?\",\n",
    "    \"수도권 교통문제 해결을 위해 김문수 후보가 제시한 정책은?\",\n",
    "    \"이재명과 김문수의 주거지원 정책을 비교해줘.\"\n",
    "]\n",
    "results = [run_prompt_chaining(q) for q in questions]\n",
    "df_final = pd.DataFrame([{k: v for k, v in row.items() if k != \"한 줄 요약\"} for row in results])\n",
    "display(df_final)\n",
    "\n",
    "print(\"\\n📌 한 줄 요약:\")\n",
    "for row in results:\n",
    "    print(f\"➡️ {row['한 줄 요약']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>질문</th>\n",
       "      <th>후보</th>\n",
       "      <th>응답</th>\n",
       "      <th>출처</th>\n",
       "      <th>정확성 점수(1~5)</th>\n",
       "      <th>풍부성 점수(1~5)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>대학생 취업과 학자금 문제 해결을 위해 이재명 후보는 어떤 정책을 내놨어?</td>\n",
       "      <td>이재명</td>\n",
       "      <td>- 정책의 목적: 대학생 취업과 학자금 문제 해결을 위한 지원\\n- 구체적 수단: 자녀 수에 비례한 신용카드 소득공제율\\n‧공제 한도 상향, 초등학생 예체능학원\\n‧체육시설 이용료 교육비 세액공제 대상 추가, '우리아이자립펀드' 도입 및 신혼부부 결혼출산지원 확대, 신혼부부 공공임대주택 공급 확대, 난임부부 치료지원 강화 등\\n- 실행 대상 또는 지역: 대학생 및 신혼부부\\n- 문서상 등장한 구체적인 단어(용어): 자녀 수에 비례한 신용카드 소득공제율, 공제 한도 상향, 초등학생 예체능학원\\n‧체육시설 이용료, '우리아이자립펀드', 신혼부부 공공임대주택, 난임부부 치료지원  이재명 후보는 대학생 취업과 학자금 문제 해결을 위해 자녀 수에 비례한 신용카드 소득공제율과 공제 한도를 상향하고, 초등학생 예체능학원\\n‧체육시설 이용료를 교육비 세액공제 대상에 추가하며, '우리아이자립펀드'를 도입하고 신혼부부 결혼출산지원을 확대하며, 신혼부부 공공임대주택을 확대하고, 난임부부 치료지원을 강화하는 정책을 내놓았습니다.</td>\n",
       "      <td>20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>수도권 교통문제 해결을 위해 김문수 후보가 제시한 정책은?</td>\n",
       "      <td>김문수</td>\n",
       "      <td>- 정책의 목적: 수도권 교통문제 해결\\n- 구체적 수단: 교통 인프라 개선, 대중교통 확충, 교통체증 완화를 위한 정책 추진\\n- 실행 대상 또는 지역: 수도권 지역\\n- 문서상 등장한 구체적인 단어(용어): 교통, 대중교통, 교통체증  김문수 후보가 제시한 정책은 수도권 교통문제 해결을 위해 교통 인프라 개선, 대중교통 확충, 교통체증 완화를 위한 정책을 추진할 것이라고 나와 있습니다. 이 정책은 수도권 지역의 교통 문제를 개선하고 대중교통을 강화하여 교통체증을 완화하는 것을 목표로 합니다.</td>\n",
       "      <td>20250603_대한민국_김문수_선거공약서.pdf:p25, 20250603_대한민국_김문수_선거공약서.pdf:p25, 20250603_대한민국_김문수_선거공약서.pdf:p25, 20250603_대한민국_김문수_선거공약서.pdf:p25, 20250603_대한민국_김문수_선거공약서.pdf:p25, 20250603_대한민국_김문수_선거공약서.pdf:p25</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>이재명과 김문수의 주거지원 정책을 비교해줘.</td>\n",
       "      <td>이재명</td>\n",
       "      <td>이재명의 주거지원 정책은 고령화 대책 혁신과 아이부터 어르신까지 돌보는 국가를 만드는 것을 목표로 하고 있습니다. 구체적으로는 신혼부부 공공임대주택 공급 확대, 어르신 주거 문제 해결을 위한 고령자 친화 주택·은퇴자 도시 조성 등이 제시되어 있습니다. 이를 통해 주거환경을 개선하고 고령자와 신혼부부의 주거 문제를 해결하려는 방향으로 정책이 이루어지고 있습니다.  김문수의 주거지원 정책은 공약 문서에서 확인되지 않습니다. 따라서 이재명의 주거지원 정책과 김문수의 주거지원 정책을 직접 비교할 수는 없습니다.</td>\n",
       "      <td>20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          질문   후보  \\\n",
       "0  대학생 취업과 학자금 문제 해결을 위해 이재명 후보는 어떤 정책을 내놨어?  이재명   \n",
       "1           수도권 교통문제 해결을 위해 김문수 후보가 제시한 정책은?  김문수   \n",
       "2                   이재명과 김문수의 주거지원 정책을 비교해줘.  이재명   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   응답  \\\n",
       "0  - 정책의 목적: 대학생 취업과 학자금 문제 해결을 위한 지원\\n- 구체적 수단: 자녀 수에 비례한 신용카드 소득공제율\\n‧공제 한도 상향, 초등학생 예체능학원\\n‧체육시설 이용료 교육비 세액공제 대상 추가, '우리아이자립펀드' 도입 및 신혼부부 결혼출산지원 확대, 신혼부부 공공임대주택 공급 확대, 난임부부 치료지원 강화 등\\n- 실행 대상 또는 지역: 대학생 및 신혼부부\\n- 문서상 등장한 구체적인 단어(용어): 자녀 수에 비례한 신용카드 소득공제율, 공제 한도 상향, 초등학생 예체능학원\\n‧체육시설 이용료, '우리아이자립펀드', 신혼부부 공공임대주택, 난임부부 치료지원  이재명 후보는 대학생 취업과 학자금 문제 해결을 위해 자녀 수에 비례한 신용카드 소득공제율과 공제 한도를 상향하고, 초등학생 예체능학원\\n‧체육시설 이용료를 교육비 세액공제 대상에 추가하며, '우리아이자립펀드'를 도입하고 신혼부부 결혼출산지원을 확대하며, 신혼부부 공공임대주택을 확대하고, 난임부부 치료지원을 강화하는 정책을 내놓았습니다.   \n",
       "1                                                                                                                                                                                                                                             - 정책의 목적: 수도권 교통문제 해결\\n- 구체적 수단: 교통 인프라 개선, 대중교통 확충, 교통체증 완화를 위한 정책 추진\\n- 실행 대상 또는 지역: 수도권 지역\\n- 문서상 등장한 구체적인 단어(용어): 교통, 대중교통, 교통체증  김문수 후보가 제시한 정책은 수도권 교통문제 해결을 위해 교통 인프라 개선, 대중교통 확충, 교통체증 완화를 위한 정책을 추진할 것이라고 나와 있습니다. 이 정책은 수도권 지역의 교통 문제를 개선하고 대중교통을 강화하여 교통체증을 완화하는 것을 목표로 합니다.   \n",
       "2                                                                                                                                                                                                                                        이재명의 주거지원 정책은 고령화 대책 혁신과 아이부터 어르신까지 돌보는 국가를 만드는 것을 목표로 하고 있습니다. 구체적으로는 신혼부부 공공임대주택 공급 확대, 어르신 주거 문제 해결을 위한 고령자 친화 주택·은퇴자 도시 조성 등이 제시되어 있습니다. 이를 통해 주거환경을 개선하고 고령자와 신혼부부의 주거 문제를 해결하려는 방향으로 정책이 이루어지고 있습니다.  김문수의 주거지원 정책은 공약 문서에서 확인되지 않습니다. 따라서 이재명의 주거지원 정책과 김문수의 주거지원 정책을 직접 비교할 수는 없습니다.   \n",
       "\n",
       "                                                                                                                                                                                                     출처  \\\n",
       "0  20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16   \n",
       "1  20250603_대한민국_김문수_선거공약서.pdf:p25, 20250603_대한민국_김문수_선거공약서.pdf:p25, 20250603_대한민국_김문수_선거공약서.pdf:p25, 20250603_대한민국_김문수_선거공약서.pdf:p25, 20250603_대한민국_김문수_선거공약서.pdf:p25, 20250603_대한민국_김문수_선거공약서.pdf:p25   \n",
       "2  20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16   \n",
       "\n",
       "   정확성 점수(1~5)  풍부성 점수(1~5)  \n",
       "0            4            5  \n",
       "1            5            3  \n",
       "2            5            3  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📌 한 줄 요약:\n",
      "➡️ 이재명 후보는 대학생 취업과 학자금 문제 해결을 위해 다양한 지원 정책을 제안했습니다.\n",
      "➡️ 김문수 후보의 정책은 수도권 교통문제 해결을 위해 교통 인프라 개선과 대중교통 확충, 교통체증 완화를 추진할 것이다.\n",
      "➡️ 이재명의 주거지원 정책은 고령화 대책과 신혼부부를 위한 공공임대주택 확대 등을 통해 주거환경을 개선하고 국가적으로 돌보는 방향으로 진행되고 있으며, 김문수의 주거지원 정책은 공약 문서에서 확인되지 않아 직접 비교할 수 없다.\n"
     ]
    }
   ],
   "source": [
    "# ✅ 실행 함수\n",
    "def run_prompt_chaining(question: str):\n",
    "    auto_keywords = extract_sentence_keywords(question)\n",
    "    detected_name = candidate_chain.invoke({\"question\": question})[\"text\"].strip()\n",
    "    candidate = next((name for name in qa_chains if name in detected_name), None)\n",
    "\n",
    "    if not candidate:\n",
    "        return {\n",
    "            \"질문\": question,\n",
    "            \"후보\": \"감지 실패\",\n",
    "            \"응답\": \"질문에서 후보 이름을 인식하지 못했습니다.\",\n",
    "            \"출처\": \"\",\n",
    "            \"정확성 점수(1~5)\": 1,\n",
    "            \"풍부성 점수(1~5)\": 1,\n",
    "            \"한 줄 요약\": \"한 줄 요약 불가\"\n",
    "        }\n",
    "\n",
    "    qa_result = qa_chains[candidate].invoke({\"profile\": user_profile, \"question\": question})\n",
    "    raw_answer = qa_result[\"answer\"]\n",
    "    answer = raw_answer.replace(\"\\n\", \" \").strip()\n",
    "    answer = answer.replace(\" -\", \"\\n-\").replace(\"‧\", \"\\n‧\")\n",
    "    sources = [doc.metadata.get(\"source\") for doc in qa_result.get(\"source_documents\", [])]\n",
    "\n",
    "    summary = summary_chain.run({\"answer\": answer})\n",
    "\n",
    "    answer_embedding = similarity_model.encode(answer, convert_to_tensor=True)\n",
    "    keyword_embeddings = similarity_model.encode(auto_keywords, convert_to_tensor=True)\n",
    "    similarities = util.cos_sim(answer_embedding, keyword_embeddings)[0].cpu().tolist()\n",
    "    high_score_count = sum(score > 0.4 for score in similarities)\n",
    "    accuracy_score = int(round((high_score_count / len(auto_keywords)) * 5))\n",
    "    richness = 5 if len(answer) > 400 and high_score_count >= 3 else 3 if high_score_count else 1\n",
    "\n",
    "    return {\n",
    "        \"질문\": question,\n",
    "        \"후보\": candidate,\n",
    "        \"응답\": answer,\n",
    "        \"출처\": \", \".join(sources),\n",
    "        \"정확성 점수(1~5)\": accuracy_score,\n",
    "        \"풍부성 점수(1~5)\": richness,\n",
    "        \"한 줄 요약\": summary\n",
    "    }\n",
    "\n",
    "# ✅ 테스트\n",
    "questions = [\n",
    "    \"대학생 취업과 학자금 문제 해결을 위해 이재명 후보는 어떤 정책을 내놨어?\",\n",
    "    \"수도권 교통문제 해결을 위해 김문수 후보가 제시한 정책은?\",\n",
    "    \"이재명과 김문수의 주거지원 정책을 비교해줘.\"\n",
    "]\n",
    "results = [run_prompt_chaining(q) for q in questions]\n",
    "df_final = pd.DataFrame([{k: v for k, v in row.items() if k != \"한 줄 요약\"} for row in results])\n",
    "display(df_final)\n",
    "\n",
    "print(\"\\n📌 한 줄 요약:\")\n",
    "for row in results:\n",
    "    print(f\"➡️ {row['한 줄 요약']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>질문</th>\n",
       "      <th>후보</th>\n",
       "      <th>응답</th>\n",
       "      <th>출처</th>\n",
       "      <th>정확성 점수(1~5)</th>\n",
       "      <th>풍부성 점수(1~5)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>대학생 취업과 학자금 문제 해결을 위해 이재명 후보는 어떤 정책을 내놨어?</td>\n",
       "      <td>이재명</td>\n",
       "      <td>- 정책의 목적: 대학생 취업과 학자금 문제 해결\\n- 구체적 수단: 자녀 수에 비례한 신용카드 소득공제율 및 공제 한도 상향, 초등학생 예체능학원 및 체육시설 이용료 교육비 세액공제 대상 추가, 신혼부부 공공임대주택 공급 확대, 난임부부 치료지원 강화\\n- 실행 대상 또는 지역: 전국적으로 취업과 학자금에 어려움을 겪는 대학생들\\n- 문서상 등장한 구체적인 단어: 자녀 수에 비례한 신용카드 소득공제율, 공제 한도 상향, 초등학생 예체능학원, 체육시설 이용료, 신혼부부 공공임대주택, 난임부부 치료지원  이재명 후보는 대학생 취업과 학자금 문제를 해결하기 위해 자녀 수에 비례한 신용카드 소득공제율 및 공제 한도를 상향하고, 교육비 세액공제 대상에 초등학생 예체능학원 및 체육시설 이용료를 추가하는 등의 정책을 내놓았습니다. 또한, 신혼부부 공공임대주택을 확대하고 난임부부 치료지원을 강화하여 대학생들의 경제적 부담을 줄이고 취업 기회를 높이는 데 도움을 주고자 합니다.</td>\n",
       "      <td>20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>수도권 교통문제 해결을 위해 김문수 후보가 제시한 정책은?</td>\n",
       "      <td>김문수</td>\n",
       "      <td>- 정책의 목적: 수도권 교통문제 해결\\n- 구체적 수단: 교통 인프라 개선, 교통 정책 개편\\n- 실행 대상 또는 지역: 수도권 지역\\n- 문서상 등장한 구체적인 단어(용어): 교통문제 해결, 교통 인프라 개선, 교통 정책 개편  김문수 후보가 제시한 정책은 수도권 교통문제 해결을 위해 교통 인프라 개선과 교통 정책 개편을 통해 수도권 지역의 교통 문제를 해결하고자 한다는 것을 알 수 있습니다.</td>\n",
       "      <td>20250603_대한민국_김문수_선거공약서.pdf:p25, 20250603_대한민국_김문수_선거공약서.pdf:p25, 20250603_대한민국_김문수_선거공약서.pdf:p25, 20250603_대한민국_김문수_선거공약서.pdf:p25, 20250603_대한민국_김문수_선거공약서.pdf:p25, 20250603_대한민국_김문수_선거공약서.pdf:p25</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>이재명과 김문수의 주거지원 정책을 비교해줘.</td>\n",
       "      <td>이재명</td>\n",
       "      <td>이재명의 주거지원 정책은 고령화 대책 혁신과 아이부터 어르신까지 함께 돌보는 국가를 만드는 것을 목표로 하고 있습니다. 이를 위해 난임부부 치료지원 강화, 공공임대주택 공급 확대, 고령자 친화 주택·은퇴자 도시 조성 등의 구체적인 수단을 제시하고 있습니다. 또한, 국민연금 수급 연령에 맞춘 정년 연장과 주택연금 제도개선을 통해 노후 소득 보장을 강화하고 있습니다.  반면 김문수의 주거지원 정책은 공약 문서에서 확인할 수 없습니다. 따라서 이재명의 주거지원 정책에 대한 구체적인 내용만을 비교할 수 있습니다.</td>\n",
       "      <td>20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "# ✅ 응답 칼럼 안에서 보기 좋게 줄바꿈 ( - 또는 ‧ 앞에서 줄바꿈)\n",
    "df_final[\"응답\"] = df_final[\"응답\"].apply(lambda x: x.replace(\" -\", \"<br>-\").replace(\"‧\", \"<br>‧\"))\n",
    "\n",
    "# ✅ 줄바꿈이 적용된 HTML 표 출력\n",
    "HTML(df_final.to_html(escape=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_ba8c0_row0_col2, #T_ba8c0_row1_col2, #T_ba8c0_row2_col2 {\n",
       "  white-space: pre-wrap;\n",
       "  text-align: left;\n",
       "  vertical-align: top;\n",
       "  line-height: 1.5;\n",
       "  font-family: sans-serif;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_ba8c0\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_ba8c0_level0_col0\" class=\"col_heading level0 col0\" >질문</th>\n",
       "      <th id=\"T_ba8c0_level0_col1\" class=\"col_heading level0 col1\" >후보</th>\n",
       "      <th id=\"T_ba8c0_level0_col2\" class=\"col_heading level0 col2\" >응답</th>\n",
       "      <th id=\"T_ba8c0_level0_col3\" class=\"col_heading level0 col3\" >출처</th>\n",
       "      <th id=\"T_ba8c0_level0_col4\" class=\"col_heading level0 col4\" >정확성 점수(1~5)</th>\n",
       "      <th id=\"T_ba8c0_level0_col5\" class=\"col_heading level0 col5\" >풍부성 점수(1~5)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_ba8c0_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_ba8c0_row0_col0\" class=\"data row0 col0\" >대학생 취업과 학자금 문제 해결을 위해 이재명 후보는 어떤 정책을 내놨어?</td>\n",
       "      <td id=\"T_ba8c0_row0_col1\" class=\"data row0 col1\" >이재명</td>\n",
       "      <td id=\"T_ba8c0_row0_col2\" class=\"data row0 col2\" >- 정책의 목적: 대학생 취업과 학자금 문제 해결\n",
       "- 구체적 수단: 자녀 수에 비례한 신용카드 소득공제율 및 공제 한도 상향, 초등학생 예체능학원 및 체육시설 이용료 교육비 세액공제 대상 추가, 신혼부부 공공임대주택 공급 확대, 난임부부 치료지원 강화\n",
       "- 실행 대상 또는 지역: 전국적으로 취업과 학자금에 어려움을 겪는 대학생들\n",
       "- 문서상 등장한 구체적인 단어: 자녀 수에 비례한 신용카드 소득공제율, 공제 한도 상향, 초등학생 예체능학원, 체육시설 이용료, 신혼부부 공공임대주택, 난임부부 치료지원  이재명 후보는 대학생 취업과 학자금 문제를 해결하기 위해 자녀 수에 비례한 신용카드 소득공제율 및 공제 한도를 상향하고, 교육비 세액공제 대상에 초등학생 예체능학원 및 체육시설 이용료를 추가하는 등의 정책을 내놓았습니다. 또한, 신혼부부 공공임대주택을 확대하고 난임부부 치료지원을 강화하여 대학생들의 경제적 부담을 줄이고 취업 기회를 높이는 데 도움을 주고자 합니다.</td>\n",
       "      <td id=\"T_ba8c0_row0_col3\" class=\"data row0 col3\" >20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16</td>\n",
       "      <td id=\"T_ba8c0_row0_col4\" class=\"data row0 col4\" >5.000000</td>\n",
       "      <td id=\"T_ba8c0_row0_col5\" class=\"data row0 col5\" >5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ba8c0_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_ba8c0_row1_col0\" class=\"data row1 col0\" >수도권 교통문제 해결을 위해 김문수 후보가 제시한 정책은?</td>\n",
       "      <td id=\"T_ba8c0_row1_col1\" class=\"data row1 col1\" >김문수</td>\n",
       "      <td id=\"T_ba8c0_row1_col2\" class=\"data row1 col2\" >- 정책의 목적: 수도권 교통문제 해결\n",
       "- 구체적 수단: 교통 인프라 개선, 교통 정책 개편\n",
       "- 실행 대상 또는 지역: 수도권 지역\n",
       "- 문서상 등장한 구체적인 단어(용어): 교통문제 해결, 교통 인프라 개선, 교통 정책 개편  김문수 후보가 제시한 정책은 수도권 교통문제 해결을 위해 교통 인프라 개선과 교통 정책 개편을 통해 수도권 지역의 교통 문제를 해결하고자 한다는 것을 알 수 있습니다.</td>\n",
       "      <td id=\"T_ba8c0_row1_col3\" class=\"data row1 col3\" >20250603_대한민국_김문수_선거공약서.pdf:p25, 20250603_대한민국_김문수_선거공약서.pdf:p25, 20250603_대한민국_김문수_선거공약서.pdf:p25, 20250603_대한민국_김문수_선거공약서.pdf:p25, 20250603_대한민국_김문수_선거공약서.pdf:p25, 20250603_대한민국_김문수_선거공약서.pdf:p25</td>\n",
       "      <td id=\"T_ba8c0_row1_col4\" class=\"data row1 col4\" >5.000000</td>\n",
       "      <td id=\"T_ba8c0_row1_col5\" class=\"data row1 col5\" >3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ba8c0_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_ba8c0_row2_col0\" class=\"data row2 col0\" >이재명과 김문수의 주거지원 정책을 비교해줘.</td>\n",
       "      <td id=\"T_ba8c0_row2_col1\" class=\"data row2 col1\" >이재명</td>\n",
       "      <td id=\"T_ba8c0_row2_col2\" class=\"data row2 col2\" >이재명의 주거지원 정책은 고령화 대책 혁신과 아이부터 어르신까지 함께 돌보는 국가를 만드는 것을 목표로 하고 있습니다. 이를 위해 난임부부 치료지원 강화, 공공임대주택 공급 확대, 고령자 친화 주택·은퇴자 도시 조성 등의 구체적인 수단을 제시하고 있습니다. 또한, 국민연금 수급 연령에 맞춘 정년 연장과 주택연금 제도개선을 통해 노후 소득 보장을 강화하고 있습니다.  반면 김문수의 주거지원 정책은 공약 문서에서 확인할 수 없습니다. 따라서 이재명의 주거지원 정책에 대한 구체적인 내용만을 비교할 수 있습니다.</td>\n",
       "      <td id=\"T_ba8c0_row2_col3\" class=\"data row2 col3\" >20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16</td>\n",
       "      <td id=\"T_ba8c0_row2_col4\" class=\"data row2 col4\" >5.000000</td>\n",
       "      <td id=\"T_ba8c0_row2_col5\" class=\"data row2 col5\" >3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x22154edf1a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📌 한 줄 요약:\n",
      "➡️ 이재명 후보는 대학생 취업과 학자금 문제를 해결하기 위해 다양한 정책을 내놓았습니다.\n",
      "➡️ 김문수 후보는 수도권 교통문제를 해결하기 위해 교통 인프라 개선과 교통 정책 개편을 제안하고 있다.\n",
      "➡️ 이재명의 주거지원 정책은 고령화 대책과 아이부터 어르신까지 함께 돌보는 국가를 만드는 것을 목표로 하고 있으며, 국민연금 수급 연령에 맞춘 정년 연장과 주택연금 제도개선을 통해 노후 소득 보장을 강화하고 있다.\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "# ✅ 스타일 적용 함수\n",
    "def clean_response_column(df, col=\"응답\"):\n",
    "    styled_df = df.style.set_properties(\n",
    "        subset=[col],\n",
    "        **{\n",
    "            'white-space': 'pre-wrap',        # 줄바꿈 허용\n",
    "            'text-align': 'left',             # 왼쪽 정렬\n",
    "            'vertical-align': 'top',          # 셀 상단 정렬\n",
    "            'line-height': '1.5',             # 줄 간격 조정\n",
    "            'font-family': 'sans-serif',      # 읽기 쉬운 글꼴\n",
    "        }\n",
    "    )\n",
    "    return styled_df\n",
    "\n",
    "# ✅ 적용 및 출력\n",
    "display(clean_response_column(df_final))\n",
    "print(\"\\n📌 한 줄 요약:\")\n",
    "for row in results:\n",
    "    print(f\"➡️ {row['한 줄 요약']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 다양한 테스트 케이스 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>질문</th>\n",
       "      <th>후보</th>\n",
       "      <th>응답</th>\n",
       "      <th>출처</th>\n",
       "      <th>정확성 점수(1~5)</th>\n",
       "      <th>풍부성 점수(1~5)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>청년 일자리 마련을 위해 이재명 후보는 어떤 정책을 제시했어?</td>\n",
       "      <td>이재명</td>\n",
       "      <td>- 정책의 목적: 청년 일자리 마련을 통해 청년들의 경제적 안정을 도모하고 국민 전반의 삶의 질 향상을 도모 - 구체적 수단: 청년·국민·어르신 패스 3종 도입으로 국민 교통비 절감 - 실행 대상 또는 지역: 청년층 - 문서상 등장한 구체적인 단어(용어): 청년·국민·어르신 패스 3종 - 이재명 후보는 청년 일자리 마련을 위해 국민 교통비를 절감하기 위해 청년·국민·어르신 패스 3종을 도입할 것을 공약으로 제시했습니다.</td>\n",
       "      <td>20250603_대한민국_이재명_10대공약.pdf:p14, 20250603_대한민국_이재명_10대공약.pdf:p14, 20250603_대한민국_이재명_10대공약.pdf:p14, 20250603_대한민국_이재명_10대공약.pdf:p14, 20250603_대한민국_이재명_10대공약.pdf:p14, 20250603_대한민국_이재명_10대공약.pdf:p14</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>수도권 주거 지원을 위해 김문수 후보가 제시한 정책은 뭐야?</td>\n",
       "      <td>김문수</td>\n",
       "      <td>정책의 목적은 수도권 주거 지원을 위한 것입니다. 구체적인 수단은 주거 환경 개선을 위한 정책으로, 주거 환경 개선 사업을 통해 수도권의 주거 환경을 개선하고자 합니다. 실행 대상은 수도권 거주자들이며, 서울 은평구에 이사를 하고자 하는 사용자에게 도움이 될 수 있습니다. 해당 정책은 김문수 후보의 선거 공약서에 등장한 내용입니다.</td>\n",
       "      <td>20250603_대한민국_김문수_선거공약서.pdf:p25, 20250603_대한민국_김문수_선거공약서.pdf:p25, 20250603_대한민국_김문수_선거공약서.pdf:p25, 20250603_대한민국_김문수_선거공약서.pdf:p25, 20250603_대한민국_김문수_선거공약서.pdf:p25, 20250603_대한민국_김문수_선거공약서.pdf:p25</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>이재명과 김문수의 청년 주거지원 정책을 비교해줘.</td>\n",
       "      <td>이재명</td>\n",
       "      <td>이재명의 정책은 저출생·고령화 위기를 극복하고 아이부터 어르신까지 함께 돌보는 국가를 만드는 것을 목표로 하고 있습니다. 이를 위해 자녀양육 지원 확대, 공공임대주택 공급 확대, 난임부부 치료지원 강화 등을 실행할 계획입니다. 이는 경기도에 거주 중인 30대 남성이 이직을 준비하며 서울 은평구로 이사를 하고 싶어하는 사용자에게 도움이 될 수 있는 정책입니다.  김문수의 청년 주거지원 정책은 혁신적인 주거지원 정책을 추진하고 청년들의 주거 문제를 해결하겠다는 내용을 담고 있습니다. 구체적인 수단은 주거안정자금 지원, 청년주택 공급 확대, 임대주택 공급 확대 등이 포함되어 있습니다. 이는 경기도에 거주 중인 30대 남성이 서울 은평구로 이사를 하고 싶어하는 상황에서 주거 문제를 해결해 줄 수 있는 정책입니다.  따라서, 경기도에 거주 중인 30대 남성이 서울 은평구로 이사를 하고 싶어하는 상황에서는 김문수의 청년 주거지원 정책이 더 적합할 수 있습니다.</td>\n",
       "      <td>20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   질문   후보  \\\n",
       "0  청년 일자리 마련을 위해 이재명 후보는 어떤 정책을 제시했어?  이재명   \n",
       "1   수도권 주거 지원을 위해 김문수 후보가 제시한 정책은 뭐야?  김문수   \n",
       "2         이재명과 김문수의 청년 주거지원 정책을 비교해줘.  이재명   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  응답  \\\n",
       "0                                                                                                                                                                                                                                                       - 정책의 목적: 청년 일자리 마련을 통해 청년들의 경제적 안정을 도모하고 국민 전반의 삶의 질 향상을 도모 - 구체적 수단: 청년·국민·어르신 패스 3종 도입으로 국민 교통비 절감 - 실행 대상 또는 지역: 청년층 - 문서상 등장한 구체적인 단어(용어): 청년·국민·어르신 패스 3종 - 이재명 후보는 청년 일자리 마련을 위해 국민 교통비를 절감하기 위해 청년·국민·어르신 패스 3종을 도입할 것을 공약으로 제시했습니다.   \n",
       "1                                                                                                                                                                                                                                                                                                         정책의 목적은 수도권 주거 지원을 위한 것입니다. 구체적인 수단은 주거 환경 개선을 위한 정책으로, 주거 환경 개선 사업을 통해 수도권의 주거 환경을 개선하고자 합니다. 실행 대상은 수도권 거주자들이며, 서울 은평구에 이사를 하고자 하는 사용자에게 도움이 될 수 있습니다. 해당 정책은 김문수 후보의 선거 공약서에 등장한 내용입니다.   \n",
       "2  이재명의 정책은 저출생·고령화 위기를 극복하고 아이부터 어르신까지 함께 돌보는 국가를 만드는 것을 목표로 하고 있습니다. 이를 위해 자녀양육 지원 확대, 공공임대주택 공급 확대, 난임부부 치료지원 강화 등을 실행할 계획입니다. 이는 경기도에 거주 중인 30대 남성이 이직을 준비하며 서울 은평구로 이사를 하고 싶어하는 사용자에게 도움이 될 수 있는 정책입니다.  김문수의 청년 주거지원 정책은 혁신적인 주거지원 정책을 추진하고 청년들의 주거 문제를 해결하겠다는 내용을 담고 있습니다. 구체적인 수단은 주거안정자금 지원, 청년주택 공급 확대, 임대주택 공급 확대 등이 포함되어 있습니다. 이는 경기도에 거주 중인 30대 남성이 서울 은평구로 이사를 하고 싶어하는 상황에서 주거 문제를 해결해 줄 수 있는 정책입니다.  따라서, 경기도에 거주 중인 30대 남성이 서울 은평구로 이사를 하고 싶어하는 상황에서는 김문수의 청년 주거지원 정책이 더 적합할 수 있습니다.   \n",
       "\n",
       "                                                                                                                                                                                                     출처  \\\n",
       "0  20250603_대한민국_이재명_10대공약.pdf:p14, 20250603_대한민국_이재명_10대공약.pdf:p14, 20250603_대한민국_이재명_10대공약.pdf:p14, 20250603_대한민국_이재명_10대공약.pdf:p14, 20250603_대한민국_이재명_10대공약.pdf:p14, 20250603_대한민국_이재명_10대공약.pdf:p14   \n",
       "1  20250603_대한민국_김문수_선거공약서.pdf:p25, 20250603_대한민국_김문수_선거공약서.pdf:p25, 20250603_대한민국_김문수_선거공약서.pdf:p25, 20250603_대한민국_김문수_선거공약서.pdf:p25, 20250603_대한민국_김문수_선거공약서.pdf:p25, 20250603_대한민국_김문수_선거공약서.pdf:p25   \n",
       "2  20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16   \n",
       "\n",
       "   정확성 점수(1~5)  풍부성 점수(1~5)  \n",
       "0            5            3  \n",
       "1            5            3  \n",
       "2            5            5  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "▶ 한 줄 요약:\n",
      "→ 이재명 후보는 청년 일자리를 위해 국민 교통비를 절감하기 위해 청년·국민·어르신 패스 3종을 도입할 것을 공약으로 제시했습니다.\n",
      "→ 수도권 주거 환경 개선을 위한 정책으로 김문수 후보의 선거 공약서에 등장한 내용입니다.\n",
      "→ 이재명은 저출생·고령화 위기를 극복하고 아이부터 어르신까지 함께 돌보는 국가를 만들기 위해 다양한 정책을 실행할 계획이며, 김문수는 청년들의 주거 문제를 해결하기 위해 혁신적인 주거지원 정책을 추진하고 있다.\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQAWithSourcesChain, LLMChain\n",
    "from langchain.agents import initialize_agent, Tool, AgentType\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# ✅ 기본 설정\n",
    "llm = ChatOpenAI(temperature=0.3)\n",
    "candidates = [\"이재명\", \"김문수\"]\n",
    "\n",
    "# ✅ 사용자 프로필\n",
    "user_profile = \"\"\"\n",
    "나는 경기도에 거주 중인 30대 남자야. 최근 이직은 준비하면서 서울 은평구로 이사를 하고싶은데,\n",
    "나에게 가장 도움이 되는 구체적인 정책을 제시한 후보는 누구야?\n",
    "\"\"\"\n",
    "\n",
    "# ✅ 문서 로딩 및 전처리\n",
    "file_paths = {\n",
    "    \"이재명\": [\"20250603_대한민국_이재명_10대공약.pdf\", \"20250603_대한민국_이재명_선거공약서.pdf\"],\n",
    "    \"김문수\": [\"20250603_대한민국_김문수_10대공약.pdf\", \"20250603_대한민국_김문수_선거공약서.pdf\"],\n",
    "}\n",
    "all_documents = []\n",
    "for name, paths in file_paths.items():\n",
    "    for path in paths:\n",
    "        loader = PyMuPDFLoader(path)\n",
    "        data = loader.load()\n",
    "        for d in data:\n",
    "            d.metadata[\"candidate\"] = name\n",
    "            page = d.metadata.get(\"page\", \"?\")\n",
    "            d.metadata[\"source\"] = f\"{os.path.basename(path)}:p{page}\"\n",
    "        all_documents.extend(data)\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=1000, chunk_overlap=200, encoding_name='cl100k_base')\n",
    "documents = splitter.split_documents(all_documents)\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(model_name='jhgan/ko-sbert-nli', model_kwargs={'device': 'cpu'}, encode_kwargs={'normalize_embeddings': True})\n",
    "vectorstore = Chroma.from_documents(documents, embedding=embedding_model, persist_directory=\"chroma_db\")\n",
    "vectorstore.persist()\n",
    "\n",
    "# ✅ Retriever 및 QA 체인 구성\n",
    "retrievers = {c: vectorstore.as_retriever(search_kwargs={\"k\": 6, \"filter\": {\"candidate\": c}}) for c in candidates}\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"profile\", \"summaries\", \"question\"],\n",
    "    template=\"\"\"\n",
    "당신은 정책 분석가입니다. 다음은 사용자 프로필과 대통령 후보의 공약 문서입니다.\n",
    "사용자 프로필에 맞는 정책을 찾아서 설명해주십시오. 질문에 대해 다음 사항을 반드시 포함하여 답변하십시오.\n",
    "\n",
    "[포함 사항]\n",
    "- 정책의 목적\n",
    "- 구체적 수단 (시설, 제도, 법안 등)\n",
    "- 실행 대상 또는 지역\n",
    "- 문서상 등장한 구체적인 단어(용어)를 사용\n",
    "- 반드시 한국어로 답변할 것\n",
    "\n",
    "사용자 프로필\n",
    "{profile}\n",
    "\n",
    "문맥:\n",
    "{summaries}\n",
    "\n",
    "질문:\n",
    "{question}\n",
    "\n",
    "답변:\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "qa_chains = {\n",
    "    name: RetrievalQAWithSourcesChain.from_chain_type(\n",
    "        llm=llm,\n",
    "        retriever=retrievers[name],\n",
    "        chain_type=\"stuff\",\n",
    "        chain_type_kwargs={\"prompt\": policy_prompt},\n",
    "        return_source_documents=True\n",
    "    ) for name in candidates\n",
    "}\n",
    "\n",
    "# ✅ 후보명 추출, 키워드 추출, 요약\n",
    "candidate_detect_prompt = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"\"\"\n",
    "다음 질문에서 언급된 대통령 후보의 이름을 정확히 추출하시오. 두 명 이상일 경우 모두 출력하시오.\n",
    "\n",
    "질문: {question}\n",
    "후보 이름:\n",
    "\"\"\"\n",
    ")\n",
    "candidate_chain = LLMChain(llm=llm, prompt=candidate_detect_prompt)\n",
    "\n",
    "sentence_keyword_prompt = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"\"\"\n",
    "다음 질문을 보고, 이 질문에 답하기 위해 대통령 후보의 정책 문서에서 등장할 것으로 기대되는 핵심 문장형 키워드를 3~5개 생성하세요.\n",
    "각 문장은 해당 정책의 방향, 수단, 대상 등을 포함해야 하며, 실제 문서에서 나올 수 있는 표현이어야 합니다.\n",
    "\n",
    "[질문]\n",
    "{question}\n",
    "\n",
    "[기대 문장형 키워드]\n",
    "1.\n",
    "2.\n",
    "3.\n",
    "\"\"\"\n",
    ")\n",
    "sentence_keyword_chain = LLMChain(llm=llm, prompt=sentence_keyword_prompt)\n",
    "\n",
    "def extract_sentence_keywords(question: str):\n",
    "    result = sentence_keyword_chain.run({\"question\": question})\n",
    "    return [line.strip()[2:].strip() for line in result.split(\"\\n\") if line.strip().startswith(tuple(\"12345\"))]\n",
    "\n",
    "summary_prompt = PromptTemplate(\n",
    "    input_variables=[\"answer\"],\n",
    "    template=\"\"\"\n",
    "다음 응답 내용을 바탕으로 한 문장으로 요약해 주세요. ~습니다의 어투로 통일해 주세요.\n",
    "\n",
    "응답: {answer}\n",
    "\n",
    "한 줄 요약:\n",
    "\"\"\"\n",
    ")\n",
    "summary_chain = LLMChain(llm=llm, prompt=summary_prompt)\n",
    "\n",
    "# ✅ 번역 & 비교 프롬프트\n",
    "translation_prompt = PromptTemplate(\n",
    "    input_variables=[\"english_text\"],\n",
    "    template=\"\"\"\n",
    "다음 영어 텍스트를 자연스럽고 정확한 한국어로 번역하십시오:\n",
    "\n",
    "{english_text}\n",
    "\n",
    "번역:\n",
    "\"\"\"\n",
    ")\n",
    "translation_chain = LLMChain(llm=llm, prompt=translation_prompt)\n",
    "\n",
    "compare_prompt = PromptTemplate(\n",
    "    input_variables=[\"cand1\", \"cand2\", \"topic\", \"resp1\", \"resp2\"],\n",
    "    template=\"\"\"\n",
    "아래는 대통령 후보 {cand1}와 {cand2}의 \"{topic}\" 공약에 대한 요약입니다. 다음 형식에 따라 비교하십시오:\n",
    "\n",
    "1. 정책의 목적 비교:\n",
    "2. 구체적 수단 비교:\n",
    "3. 실행 대상 또는 지역 비교:\n",
    "4. 문서상 등장한 구체적 용어 비교:\n",
    "5. 종합 요약 (한국어로):\n",
    "\n",
    "[{cand1}의 공약]:\n",
    "{resp1}\n",
    "\n",
    "[{cand2}의 공약]:\n",
    "{resp2}\n",
    "\n",
    "위 내용을 기반으로 반드시 **한국어로 작성하십시오**.\n",
    "\"\"\"\n",
    ")\n",
    "compare_chain = LLMChain(llm=llm, prompt=compare_prompt)\n",
    "\n",
    "# ✅ Tool 정의\n",
    "\n",
    "def run_candidate_policy_qa(input):\n",
    "    result = candidate_chain.invoke({\"question\": input})[\"text\"]\n",
    "    target = next((c for c in candidates if c in result), None)\n",
    "    if not target:\n",
    "        return \"후보 이름을 인식할 수 없습니다.\"\n",
    "    answer = qa_chains[target].invoke({\"profile\": user_profile, \"question\": input})[\"answer\"]\n",
    "    translated = translation_chain.invoke({\"english_text\": answer})[\"text\"]\n",
    "    return f\"Final Answer: {translated}\"\n",
    "\n",
    "def run_policy_compare(input):\n",
    "    result = candidate_chain.invoke({\"question\": input})[\"text\"]\n",
    "    involved = [c for c in candidates if c in result]\n",
    "    if len(involved) != 2:\n",
    "        return \"비교하려는 두 후보를 명확히 질문에 포함해주세요.\"\n",
    "    cand1, cand2 = involved\n",
    "    answer1 = qa_chains[cand1].invoke({\"profile\": user_profile, \"question\": input})[\"answer\"]\n",
    "    answer2 = qa_chains[cand2].invoke({\"profile\": user_profile, \"question\": input})[\"answer\"]\n",
    "    comparison = compare_chain.invoke({\"cand1\": cand1, \"cand2\": cand2, \"topic\": input, \"resp1\": answer1, \"resp2\": answer2})[\"text\"]\n",
    "    translated = translation_chain.invoke({\"english_text\": comparison})[\"text\"]\n",
    "    return f\"Final Answer: {translated}\"\n",
    "\n",
    "# ✅ Agent 구성\n",
    "react_tools = [\n",
    "    Tool(name=\"CandidatePolicyQA\", func=run_candidate_policy_qa, description=\"질문에서 후보를 식별하고 해당 공약을 검색함.\"),\n",
    "    Tool(name=\"ComparePolicies\", func=run_policy_compare, description=\"질문에서 두 후보를 식별하고 해당 공약을 비교함.\")\n",
    "]\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools=react_tools,\n",
    "    llm=llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True,\n",
    "    agent_kwargs={\n",
    "        \"system_message\": (\n",
    "            \"당신은 반드시 한국어로 사고하고 응답하는 정책 분석 도우미입니다. \"\n",
    "            \"Thought, Action, Observation, Final Answer 형식을 사용, \"\n",
    "            \"Thought와 Final Answer도 반드시 한국어여야 합니다.\"\n",
    "        )\n",
    "    },\n",
    "    handle_parsing_errors=True)\n",
    "\n",
    "def extract_sentence_keywords(question: str):\n",
    "    result = sentence_keyword_chain.run({\"question\": question})\n",
    "    return [line.strip()[2:].strip() for line in result.split(\"\\n\") if line.strip().startswith(tuple(\"12345\"))]\n",
    "\n",
    "# ✅ 후보명 추출 체인\n",
    "candidate_prompt = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"다음 질문에서 언급된 대통령 후보의 이름을 정확히 추출하시오.\\n\\n질문: {question}\\n후보 이름:\"\n",
    ")\n",
    "candidate_chain = LLMChain(llm=ChatOpenAI(temperature=0.3), prompt=candidate_prompt)\n",
    "\n",
    "# ✅ 유사도 모델\n",
    "similarity_model = SentenceTransformer(\"jhgan/ko-sbert-nli\")\n",
    "\n",
    "# ✅ QA 체인 생성\n",
    "retrievers = {\n",
    "    name: vectorstore.as_retriever(search_kwargs={\"k\": 6, \"filter\": {\"candidate\": name}})\n",
    "    for name in file_paths\n",
    "}\n",
    "llm = ChatOpenAI(temperature=0.3)\n",
    "qa_chains = {\n",
    "    name: RetrievalQAWithSourcesChain.from_chain_type(\n",
    "        llm=llm,\n",
    "        retriever=retriever,\n",
    "        chain_type=\"stuff\",\n",
    "        chain_type_kwargs={\"prompt\": prompt_template},\n",
    "        return_source_documents=True\n",
    "    ) for name, retriever in retrievers.items()\n",
    "}\n",
    "\n",
    "# ✅ 실행 함수\n",
    "def run_prompt_chaining(question: str):\n",
    "    auto_keywords = extract_sentence_keywords(question)\n",
    "    detected_name = candidate_chain.invoke({\"question\": question})[\"text\"].strip()\n",
    "    candidate = next((name for name in qa_chains if name in detected_name), None)\n",
    "\n",
    "    if not candidate:\n",
    "        return {\n",
    "            \"질문\": question,\n",
    "            \"후보\": \"감지 실패\",\n",
    "            \"응답\": \"질문에서 후보 이름을 인식하지 못했습니다.\",\n",
    "            \"출처\": \"\",\n",
    "            \"정확성 점수(1~5)\": 1,\n",
    "            \"풍부성 점수(1~5)\": 1,\n",
    "            \"한 줄 요약\": \"한 줄 요약 불가\"\n",
    "        }\n",
    "\n",
    "    qa_result = qa_chains[candidate].invoke({\"profile\": user_profile, \"question\": question})\n",
    "    answer = qa_result[\"answer\"].replace(\"\\n\", \" \").strip()\n",
    "    sources = [doc.metadata.get(\"source\") for doc in qa_result.get(\"source_documents\", [])]\n",
    "\n",
    "    summary = summary_chain.run({\"answer\": answer})\n",
    "\n",
    "    answer_embedding = similarity_model.encode(answer, convert_to_tensor=True)\n",
    "    keyword_embeddings = similarity_model.encode(auto_keywords, convert_to_tensor=True)\n",
    "    similarities = util.cos_sim(answer_embedding, keyword_embeddings)[0].cpu().tolist()\n",
    "    high_score_count = sum(score > 0.4 for score in similarities)\n",
    "    accuracy_score = round((high_score_count / len(auto_keywords)) * 5)\n",
    "    richness = 5 if len(answer) > 400 and high_score_count >= 3 else 3 if high_score_count else 1\n",
    "\n",
    "    return {\n",
    "        \"질문\": question,\n",
    "        \"후보\": candidate,\n",
    "        \"응답\": answer,\n",
    "        \"출처\": \", \".join(sources),\n",
    "        \"정확성 점수(1~5)\": accuracy_score,\n",
    "        \"풍부성 점수(1~5)\": richness,\n",
    "        \"한 줄 요약\": summary\n",
    "    }\n",
    "\n",
    "# ✅ 테스트\n",
    "questions = [\n",
    "    \"청년 일자리 마련을 위해 이재명 후보는 어떤 정책을 제시했어?\",\n",
    "    \"수도권 주거 지원을 위해 김문수 후보가 제시한 정책은 뭐야?\",\n",
    "    \"이재명과 김문수의 청년 주거지원 정책을 비교해줘.\"\n",
    "]\n",
    "results = [run_prompt_chaining(q) for q in questions]\n",
    "df_final = pd.DataFrame([{k: v for k, v in row.items() if k != \"한 줄 요약\"} for row in results])\n",
    "display(df_final)\n",
    "\n",
    "print(\"\\n▶ 한 줄 요약:\")\n",
    "for row in results:\n",
    "    print(f\"→ {row['한 줄 요약']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## termperature 0.1로 수정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>질문</th>\n",
       "      <th>후보</th>\n",
       "      <th>응답</th>\n",
       "      <th>출처</th>\n",
       "      <th>정확성 점수(1~5)</th>\n",
       "      <th>풍부성 점수(1~5)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>청년 일자리 마련을 위해 이재명 후보는 어떤 정책을 제시했어?</td>\n",
       "      <td>이재명</td>\n",
       "      <td>- 정책의 목적: 청년 일자리 마련 - 구체적 수단: 청년·국민·어르신 패스 3종 도입으로 국민 교통비 절감, 대학생 등록금 부담 완화 및 청년주거 환경 개선 - 실행 대상 또는 지역: 청년 - 문서상 등장한 구체적인 단어(용어): 청년, 대학생, 교통비, 등록금, 주거 환경  이재명 후보는 청년 일자리 마련을 위해 국민 교통비 절감을 위한 패스 도입과 대학생 등록금 부담 완화, 청년주거 환경 개선 등의 정책을 제시했습니다.</td>\n",
       "      <td>20250603_대한민국_이재명_10대공약.pdf:p14, 20250603_대한민국_이재명_10대공약.pdf:p14, 20250603_대한민국_이재명_10대공약.pdf:p14, 20250603_대한민국_이재명_10대공약.pdf:p14, 20250603_대한민국_이재명_10대공약.pdf:p14, 20250603_대한민국_이재명_10대공약.pdf:p14</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>수도권 주거 지원을 위해 김문수 후보가 제시한 정책은 뭐야?</td>\n",
       "      <td>김문수</td>\n",
       "      <td>정책의 목적은 수도권 주거 지원을 위한 것입니다. 구체적 수단으로는 주거 안정을 위해 공급 확대와 임대료 인상 제한, 주거 안정을 위한 공공임대주택 공급 등이 포함됩니다. 실행 대상은 수도권 거주자들이며, 문서상에서는 \"수도권 주거 지원\"이라는 구체적인 용어가 사용되었습니다. 이에 따라 경기도에 거주 중인 30대 남성 사용자에게 도움이 될 수 있는 정책입니다.</td>\n",
       "      <td>20250603_대한민국_김문수_선거공약서.pdf:p25, 20250603_대한민국_김문수_선거공약서.pdf:p25, 20250603_대한민국_김문수_선거공약서.pdf:p25, 20250603_대한민국_김문수_선거공약서.pdf:p25, 20250603_대한민국_김문수_선거공약서.pdf:p25, 20250603_대한민국_김문수_선거공약서.pdf:p25</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>이재명과 김문수의 청년 주거지원 정책을 비교해줘.</td>\n",
       "      <td>이재명</td>\n",
       "      <td>이재명의 정책은 저출생·고령화 위기를 극복하고 아이부터 어르신까지 함께 돌보는 국가를 만드는 것을 목표로 하고 있습니다. 이를 위해 자녀양육 지원 확대, 공공임대주택 공급 확대, 난임부부 치료지원 강화 등을 실행 방법으로 제시하고 있습니다. 이는 경기도에 거주 중인 30대 남성이 이직을 준비하면서 서울 은평구로 이사를 하고 싶어하는 사용자에게 도움이 될 수 있는 정책입니다.  김문수의 청년 주거지원 정책은 현재 문서에는 언급되어 있지 않아 직접 비교가 어렵습니다. 그러나 김문수의 공약을 찾아보고 비교하면 사용자에게 더 나은 선택을 할 수 있을 것입니다. 이에 대해 추가 정보가 필요합니다.</td>\n",
       "      <td>20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   질문   후보  \\\n",
       "0  청년 일자리 마련을 위해 이재명 후보는 어떤 정책을 제시했어?  이재명   \n",
       "1   수도권 주거 지원을 위해 김문수 후보가 제시한 정책은 뭐야?  김문수   \n",
       "2         이재명과 김문수의 청년 주거지원 정책을 비교해줘.  이재명   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                             응답  \\\n",
       "0                                                                                               - 정책의 목적: 청년 일자리 마련 - 구체적 수단: 청년·국민·어르신 패스 3종 도입으로 국민 교통비 절감, 대학생 등록금 부담 완화 및 청년주거 환경 개선 - 실행 대상 또는 지역: 청년 - 문서상 등장한 구체적인 단어(용어): 청년, 대학생, 교통비, 등록금, 주거 환경  이재명 후보는 청년 일자리 마련을 위해 국민 교통비 절감을 위한 패스 도입과 대학생 등록금 부담 완화, 청년주거 환경 개선 등의 정책을 제시했습니다.   \n",
       "1                                                                                                                                    정책의 목적은 수도권 주거 지원을 위한 것입니다. 구체적 수단으로는 주거 안정을 위해 공급 확대와 임대료 인상 제한, 주거 안정을 위한 공공임대주택 공급 등이 포함됩니다. 실행 대상은 수도권 거주자들이며, 문서상에서는 \"수도권 주거 지원\"이라는 구체적인 용어가 사용되었습니다. 이에 따라 경기도에 거주 중인 30대 남성 사용자에게 도움이 될 수 있는 정책입니다.   \n",
       "2  이재명의 정책은 저출생·고령화 위기를 극복하고 아이부터 어르신까지 함께 돌보는 국가를 만드는 것을 목표로 하고 있습니다. 이를 위해 자녀양육 지원 확대, 공공임대주택 공급 확대, 난임부부 치료지원 강화 등을 실행 방법으로 제시하고 있습니다. 이는 경기도에 거주 중인 30대 남성이 이직을 준비하면서 서울 은평구로 이사를 하고 싶어하는 사용자에게 도움이 될 수 있는 정책입니다.  김문수의 청년 주거지원 정책은 현재 문서에는 언급되어 있지 않아 직접 비교가 어렵습니다. 그러나 김문수의 공약을 찾아보고 비교하면 사용자에게 더 나은 선택을 할 수 있을 것입니다. 이에 대해 추가 정보가 필요합니다.   \n",
       "\n",
       "                                                                                                                                                                                                     출처  \\\n",
       "0  20250603_대한민국_이재명_10대공약.pdf:p14, 20250603_대한민국_이재명_10대공약.pdf:p14, 20250603_대한민국_이재명_10대공약.pdf:p14, 20250603_대한민국_이재명_10대공약.pdf:p14, 20250603_대한민국_이재명_10대공약.pdf:p14, 20250603_대한민국_이재명_10대공약.pdf:p14   \n",
       "1  20250603_대한민국_김문수_선거공약서.pdf:p25, 20250603_대한민국_김문수_선거공약서.pdf:p25, 20250603_대한민국_김문수_선거공약서.pdf:p25, 20250603_대한민국_김문수_선거공약서.pdf:p25, 20250603_대한민국_김문수_선거공약서.pdf:p25, 20250603_대한민국_김문수_선거공약서.pdf:p25   \n",
       "2  20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16   \n",
       "\n",
       "   정확성 점수(1~5)  풍부성 점수(1~5)  \n",
       "0            4            3  \n",
       "1            5            3  \n",
       "2            5            3  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "▶ 한 줄 요약:\n",
      "→ 이재명 후보는 청년을 위한 국민 교통비 절감, 대학생 등록금 부담 완화, 청년주거 환경 개선을 통해 청년 일자리를 마련하겠다고 합니다.\n",
      "→ 수도권 주거 안정을 위해 공급 확대와 임대료 인상 제한, 공공임대주택 공급 등을 포함한 정책이 수도권 거주자들을 대상으로 실행됩니다.\n",
      "→ 이재명의 정책은 저출생·고령화 위기를 극복하고 아이부터 어르신까지 함께 돌보는 국가를 만드는 것을 목표로 하고 있습니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQAWithSourcesChain, LLMChain\n",
    "from langchain.agents import initialize_agent, Tool, AgentType\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# ✅ 기본 설정\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "candidates = [\"이재명\", \"김문수\"]\n",
    "\n",
    "# ✅ 사용자 프로필\n",
    "user_profile = \"\"\"\n",
    "나는 경기도에 거주 중인 30대 남자야. 최근 이직은 준비하면서 서울 은평구로 이사를 하고싶은데,\n",
    "나에게 가장 도움이 되는 구체적인 정책을 제시한 후보는 누구야?\n",
    "\"\"\"\n",
    "\n",
    "# ✅ 문서 로딩 및 전처리\n",
    "file_paths = {\n",
    "    \"이재명\": [\"20250603_대한민국_이재명_10대공약.pdf\", \"20250603_대한민국_이재명_선거공약서.pdf\"],\n",
    "    \"김문수\": [\"20250603_대한민국_김문수_10대공약.pdf\", \"20250603_대한민국_김문수_선거공약서.pdf\"],\n",
    "}\n",
    "all_documents = []\n",
    "for name, paths in file_paths.items():\n",
    "    for path in paths:\n",
    "        loader = PyMuPDFLoader(path)\n",
    "        data = loader.load()\n",
    "        for d in data:\n",
    "            d.metadata[\"candidate\"] = name\n",
    "            page = d.metadata.get(\"page\", \"?\")\n",
    "            d.metadata[\"source\"] = f\"{os.path.basename(path)}:p{page}\"\n",
    "        all_documents.extend(data)\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=1000, chunk_overlap=200, encoding_name='cl100k_base')\n",
    "documents = splitter.split_documents(all_documents)\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(model_name='jhgan/ko-sbert-nli', model_kwargs={'device': 'cpu'}, encode_kwargs={'normalize_embeddings': True})\n",
    "vectorstore = Chroma.from_documents(documents, embedding=embedding_model, persist_directory=\"chroma_db\")\n",
    "vectorstore.persist()\n",
    "\n",
    "# ✅ Retriever 및 QA 체인 구성\n",
    "retrievers = {c: vectorstore.as_retriever(search_kwargs={\"k\": 6, \"filter\": {\"candidate\": c}}) for c in candidates}\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"profile\", \"summaries\", \"question\"],\n",
    "    template=\"\"\"\n",
    "당신은 정책 분석가입니다. 다음은 사용자 프로필과 대통령 후보의 공약 문서입니다.\n",
    "사용자 프로필에 맞는 정책을 찾아서 설명해주십시오. 질문에 대해 다음 사항을 반드시 포함하여 답변하십시오.\n",
    "\n",
    "[포함 사항]\n",
    "- 정책의 목적\n",
    "- 구체적 수단 (시설, 제도, 법안 등)\n",
    "- 실행 대상 또는 지역\n",
    "- 문서상 등장한 구체적인 단어(용어)를 사용\n",
    "- 반드시 한국어로 답변할 것\n",
    "\n",
    "사용자 프로필\n",
    "{profile}\n",
    "\n",
    "문맥:\n",
    "{summaries}\n",
    "\n",
    "질문:\n",
    "{question}\n",
    "\n",
    "답변:\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "qa_chains = {\n",
    "    name: RetrievalQAWithSourcesChain.from_chain_type(\n",
    "        llm=llm,\n",
    "        retriever=retrievers[name],\n",
    "        chain_type=\"stuff\",\n",
    "        chain_type_kwargs={\"prompt\": policy_prompt},\n",
    "        return_source_documents=True\n",
    "    ) for name in candidates\n",
    "}\n",
    "\n",
    "# ✅ 후보명 추출, 키워드 추출, 요약\n",
    "candidate_detect_prompt = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"\"\"\n",
    "다음 질문에서 언급된 대통령 후보의 이름을 정확히 추출하시오. 두 명 이상일 경우 모두 출력하시오.\n",
    "\n",
    "질문: {question}\n",
    "후보 이름:\n",
    "\"\"\"\n",
    ")\n",
    "candidate_chain = LLMChain(llm=llm, prompt=candidate_detect_prompt)\n",
    "\n",
    "sentence_keyword_prompt = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"\"\"\n",
    "다음 질문을 보고, 이 질문에 답하기 위해 대통령 후보의 정책 문서에서 등장할 것으로 기대되는 핵심 문장형 키워드를 3~5개 생성하세요.\n",
    "각 문장은 해당 정책의 방향, 수단, 대상 등을 포함해야 하며, 실제 문서에서 나올 수 있는 표현이어야 합니다.\n",
    "\n",
    "[질문]\n",
    "{question}\n",
    "\n",
    "[기대 문장형 키워드]\n",
    "1.\n",
    "2.\n",
    "3.\n",
    "\"\"\"\n",
    ")\n",
    "sentence_keyword_chain = LLMChain(llm=llm, prompt=sentence_keyword_prompt)\n",
    "\n",
    "def extract_sentence_keywords(question: str):\n",
    "    result = sentence_keyword_chain.run({\"question\": question})\n",
    "    return [line.strip()[2:].strip() for line in result.split(\"\\n\") if line.strip().startswith(tuple(\"12345\"))]\n",
    "\n",
    "summary_prompt = PromptTemplate(\n",
    "    input_variables=[\"answer\"],\n",
    "    template=\"\"\"\n",
    "다음 응답 내용을 바탕으로 한 문장으로 요약해 주세요. ~습니다의 어투로 통일해 주세요.\n",
    "\n",
    "응답: {answer}\n",
    "\n",
    "한 줄 요약:\n",
    "\"\"\"\n",
    ")\n",
    "summary_chain = LLMChain(llm=llm, prompt=summary_prompt)\n",
    "\n",
    "# ✅ 번역 & 비교 프롬프트\n",
    "translation_prompt = PromptTemplate(\n",
    "    input_variables=[\"english_text\"],\n",
    "    template=\"\"\"\n",
    "다음 영어 텍스트를 자연스럽고 정확한 한국어로 번역하십시오:\n",
    "\n",
    "{english_text}\n",
    "\n",
    "번역:\n",
    "\"\"\"\n",
    ")\n",
    "translation_chain = LLMChain(llm=llm, prompt=translation_prompt)\n",
    "\n",
    "compare_prompt = PromptTemplate(\n",
    "    input_variables=[\"cand1\", \"cand2\", \"topic\", \"resp1\", \"resp2\"],\n",
    "    template=\"\"\"\n",
    "아래는 대통령 후보 {cand1}와 {cand2}의 \"{topic}\" 공약에 대한 요약입니다. 다음 형식에 따라 비교하십시오:\n",
    "\n",
    "1. 정책의 목적 비교:\n",
    "2. 구체적 수단 비교:\n",
    "3. 실행 대상 또는 지역 비교:\n",
    "4. 문서상 등장한 구체적 용어 비교:\n",
    "5. 종합 요약 (한국어로):\n",
    "\n",
    "[{cand1}의 공약]:\n",
    "{resp1}\n",
    "\n",
    "[{cand2}의 공약]:\n",
    "{resp2}\n",
    "\n",
    "위 내용을 기반으로 반드시 **한국어로 작성하십시오**.\n",
    "\"\"\"\n",
    ")\n",
    "compare_chain = LLMChain(llm=llm, prompt=compare_prompt)\n",
    "\n",
    "# ✅ Tool 정의\n",
    "\n",
    "def run_candidate_policy_qa(input):\n",
    "    result = candidate_chain.invoke({\"question\": input})[\"text\"]\n",
    "    target = next((c for c in candidates if c in result), None)\n",
    "    if not target:\n",
    "        return \"후보 이름을 인식할 수 없습니다.\"\n",
    "    answer = qa_chains[target].invoke({\"profile\": user_profile, \"question\": input})[\"answer\"]\n",
    "    translated = translation_chain.invoke({\"english_text\": answer})[\"text\"]\n",
    "    return f\"Final Answer: {translated}\"\n",
    "\n",
    "def run_policy_compare(input):\n",
    "    result = candidate_chain.invoke({\"question\": input})[\"text\"]\n",
    "    involved = [c for c in candidates if c in result]\n",
    "    if len(involved) != 2:\n",
    "        return \"비교하려는 두 후보를 명확히 질문에 포함해주세요.\"\n",
    "    cand1, cand2 = involved\n",
    "    answer1 = qa_chains[cand1].invoke({\"profile\": user_profile, \"question\": input})[\"answer\"]\n",
    "    answer2 = qa_chains[cand2].invoke({\"profile\": user_profile, \"question\": input})[\"answer\"]\n",
    "    comparison = compare_chain.invoke({\"cand1\": cand1, \"cand2\": cand2, \"topic\": input, \"resp1\": answer1, \"resp2\": answer2})[\"text\"]\n",
    "    translated = translation_chain.invoke({\"english_text\": comparison})[\"text\"]\n",
    "    return f\"Final Answer: {translated}\"\n",
    "\n",
    "# ✅ Agent 구성\n",
    "react_tools = [\n",
    "    Tool(name=\"CandidatePolicyQA\", func=run_candidate_policy_qa, description=\"질문에서 후보를 식별하고 해당 공약을 검색함.\"),\n",
    "    Tool(name=\"ComparePolicies\", func=run_policy_compare, description=\"질문에서 두 후보를 식별하고 해당 공약을 비교함.\")\n",
    "]\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools=react_tools,\n",
    "    llm=llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True,\n",
    "    agent_kwargs={\n",
    "        \"system_message\": (\n",
    "            \"당신은 반드시 한국어로 사고하고 응답하는 정책 분석 도우미입니다. \"\n",
    "            \"Thought, Action, Observation, Final Answer 형식을 사용, \"\n",
    "            \"Thought와 Final Answer도 반드시 한국어여야 합니다.\"\n",
    "        )\n",
    "    },\n",
    "    handle_parsing_errors=True)\n",
    "\n",
    "def extract_sentence_keywords(question: str):\n",
    "    result = sentence_keyword_chain.run({\"question\": question})\n",
    "    return [line.strip()[2:].strip() for line in result.split(\"\\n\") if line.strip().startswith(tuple(\"12345\"))]\n",
    "\n",
    "# ✅ 후보명 추출 체인\n",
    "candidate_prompt = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"다음 질문에서 언급된 대통령 후보의 이름을 정확히 추출하시오.\\n\\n질문: {question}\\n후보 이름:\"\n",
    ")\n",
    "candidate_chain = LLMChain(llm=ChatOpenAI(temperature=0.2), prompt=candidate_prompt)\n",
    "\n",
    "# ✅ 유사도 모델\n",
    "similarity_model = SentenceTransformer(\"jhgan/ko-sbert-nli\")\n",
    "\n",
    "# ✅ QA 체인 생성\n",
    "retrievers = {\n",
    "    name: vectorstore.as_retriever(search_kwargs={\"k\": 6, \"filter\": {\"candidate\": name}})\n",
    "    for name in file_paths\n",
    "}\n",
    "llm = ChatOpenAI(temperature=0.3)\n",
    "qa_chains = {\n",
    "    name: RetrievalQAWithSourcesChain.from_chain_type(\n",
    "        llm=llm,\n",
    "        retriever=retriever,\n",
    "        chain_type=\"stuff\",\n",
    "        chain_type_kwargs={\"prompt\": prompt_template},\n",
    "        return_source_documents=True\n",
    "    ) for name, retriever in retrievers.items()\n",
    "}\n",
    "\n",
    "# ✅ 실행 함수\n",
    "def run_prompt_chaining(question: str):\n",
    "    auto_keywords = extract_sentence_keywords(question)\n",
    "    detected_name = candidate_chain.invoke({\"question\": question})[\"text\"].strip()\n",
    "    candidate = next((name for name in qa_chains if name in detected_name), None)\n",
    "\n",
    "    if not candidate:\n",
    "        return {\n",
    "            \"질문\": question,\n",
    "            \"후보\": \"감지 실패\",\n",
    "            \"응답\": \"질문에서 후보 이름을 인식하지 못했습니다.\",\n",
    "            \"출처\": \"\",\n",
    "            \"정확성 점수(1~5)\": 1,\n",
    "            \"풍부성 점수(1~5)\": 1,\n",
    "            \"한 줄 요약\": \"한 줄 요약 불가\"\n",
    "        }\n",
    "\n",
    "    qa_result = qa_chains[candidate].invoke({\"profile\": user_profile, \"question\": question})\n",
    "    answer = qa_result[\"answer\"].replace(\"\\n\", \" \").strip()\n",
    "    sources = [doc.metadata.get(\"source\") for doc in qa_result.get(\"source_documents\", [])]\n",
    "\n",
    "    summary = summary_chain.run({\"answer\": answer})\n",
    "\n",
    "    answer_embedding = similarity_model.encode(answer, convert_to_tensor=True)\n",
    "    keyword_embeddings = similarity_model.encode(auto_keywords, convert_to_tensor=True)\n",
    "    similarities = util.cos_sim(answer_embedding, keyword_embeddings)[0].cpu().tolist()\n",
    "    high_score_count = sum(score > 0.4 for score in similarities)\n",
    "    accuracy_score = round((high_score_count / len(auto_keywords)) * 5)\n",
    "    richness = 5 if len(answer) > 400 and high_score_count >= 3 else 3 if high_score_count else 1\n",
    "\n",
    "    return {\n",
    "        \"질문\": question,\n",
    "        \"후보\": candidate,\n",
    "        \"응답\": answer,\n",
    "        \"출처\": \", \".join(sources),\n",
    "        \"정확성 점수(1~5)\": accuracy_score,\n",
    "        \"풍부성 점수(1~5)\": richness,\n",
    "        \"한 줄 요약\": summary\n",
    "    }\n",
    "\n",
    "# ✅ 테스트\n",
    "questions = [\n",
    "    \"청년 일자리 마련을 위해 이재명 후보는 어떤 정책을 제시했어?\",\n",
    "    \"수도권 주거 지원을 위해 김문수 후보가 제시한 정책은 뭐야?\",\n",
    "    \"이재명과 김문수의 청년 주거지원 정책을 비교해줘.\"\n",
    "]\n",
    "results = [run_prompt_chaining(q) for q in questions]\n",
    "df_final = pd.DataFrame([{k: v for k, v in row.items() if k != \"한 줄 요약\"} for row in results])\n",
    "display(df_final)\n",
    "\n",
    "print(\"\\n▶ 한 줄 요약:\")\n",
    "for row in results:\n",
    "    print(f\"→ {row['한 줄 요약']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>질문</th>\n",
       "      <th>후보</th>\n",
       "      <th>응답</th>\n",
       "      <th>출처</th>\n",
       "      <th>정확성 점수(1~5)</th>\n",
       "      <th>풍부성 점수(1~5)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>청년 일자리 마련을 위해 이재명 후보는 어떤 정책을 제시했어?</td>\n",
       "      <td>이재명</td>\n",
       "      <td>- 정책의 목적: 청년 일자리 마련 - 구체적 수단: 국민 교통비 절감을 위한 청년·국민·어르신 패스 3종 도입 - 실행 대상 또는 지역: 국민 전체, 특히 청년층 - 문서상 등장한 구체적인 단어(용어): 청년·국민·어르신 패스 3종  이재명 후보는 청년 일자리 마련을 위해 국민 교통비를 절감하기 위해 청년·국민·어르신 패스 3종을 도입하는 정책을 제시했습니다. 이를 통해 청년층의 교통비 부담을 줄이고 경제적 안정을 도모할 수 있을 것으로 기대됩니다.</td>\n",
       "      <td>20250603_대한민국_이재명_10대공약.pdf:p14, 20250603_대한민국_이재명_10대공약.pdf:p14, 20250603_대한민국_이재명_10대공약.pdf:p14, 20250603_대한민국_이재명_10대공약.pdf:p14, 20250603_대한민국_이재명_10대공약.pdf:p14, 20250603_대한민국_이재명_10대공약.pdf:p14</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>수도권 주거 지원을 위해 김문수 후보가 제시한 정책은 뭐야?</td>\n",
       "      <td>김문수</td>\n",
       "      <td>정책의 목적: 수도권 주거 지원 구체적 수단: 주거 안정 정책 실행 대상 또는 지역: 수도권 문서상 등장한 구체적인 단어(용어): 주거 안정 정책  김문수 후보는 수도권 주거 지원을 위해 주거 안정 정책을 제시하였습니다. 해당 정책은 수도권 지역의 주거 안정을 위해 구체적인 시설 및 제도적 지원을 통해 주거 환경을 개선하고자 하는 것으로 해석됩니다. 이 정책은 경기도에 거주 중인 30대 남성 사용자에게 도움이 될 수 있을 것으로 예상됩니다.</td>\n",
       "      <td>20250603_대한민국_김문수_선거공약서.pdf:p25, 20250603_대한민국_김문수_선거공약서.pdf:p25, 20250603_대한민국_김문수_선거공약서.pdf:p25, 20250603_대한민국_김문수_선거공약서.pdf:p25, 20250603_대한민국_김문수_선거공약서.pdf:p25, 20250603_대한민국_김문수_선거공약서.pdf:p25</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>이재명과 김문수의 청년 주거지원 정책을 비교해줘.</td>\n",
       "      <td>이재명</td>\n",
       "      <td>이재명의 정책은 저출생·고령화 위기를 극복하고 아이부터 어르신까지 함께 돌보는 국가를 만드는 것을 목표로 하고 있습니다. 구체적으로는 자녀양육 지원 확대, 공공임대주택 공급 확대, 난임부부 치료지원 강화 등을 실행 방법으로 제시하고 있습니다. 이 정책은 경기도에 거주 중인 30대 남성에게도 도움이 될 수 있습니다.  김문수의 청년 주거지원 정책은 문서에서 확인할 수 없기 때문에 비교할 수 있는 정보가 없습니다. 따라서 이재명의 정책을 기준으로 설명해 드릴 수밖에 없습니다. 만약 김문수의 청년 주거지원 정책에 대한 정보를 제공해주신다면 두 후보의 정책을 비교하여 보다 구체적인 설명을 제공해 드릴 수 있을 것입니다.</td>\n",
       "      <td>20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   질문   후보  \\\n",
       "0  청년 일자리 마련을 위해 이재명 후보는 어떤 정책을 제시했어?  이재명   \n",
       "1   수도권 주거 지원을 위해 김문수 후보가 제시한 정책은 뭐야?  김문수   \n",
       "2         이재명과 김문수의 청년 주거지원 정책을 비교해줘.  이재명   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                           응답  \\\n",
       "0                                                                                              - 정책의 목적: 청년 일자리 마련 - 구체적 수단: 국민 교통비 절감을 위한 청년·국민·어르신 패스 3종 도입 - 실행 대상 또는 지역: 국민 전체, 특히 청년층 - 문서상 등장한 구체적인 단어(용어): 청년·국민·어르신 패스 3종  이재명 후보는 청년 일자리 마련을 위해 국민 교통비를 절감하기 위해 청년·국민·어르신 패스 3종을 도입하는 정책을 제시했습니다. 이를 통해 청년층의 교통비 부담을 줄이고 경제적 안정을 도모할 수 있을 것으로 기대됩니다.   \n",
       "1                                                                                                    정책의 목적: 수도권 주거 지원 구체적 수단: 주거 안정 정책 실행 대상 또는 지역: 수도권 문서상 등장한 구체적인 단어(용어): 주거 안정 정책  김문수 후보는 수도권 주거 지원을 위해 주거 안정 정책을 제시하였습니다. 해당 정책은 수도권 지역의 주거 안정을 위해 구체적인 시설 및 제도적 지원을 통해 주거 환경을 개선하고자 하는 것으로 해석됩니다. 이 정책은 경기도에 거주 중인 30대 남성 사용자에게 도움이 될 수 있을 것으로 예상됩니다.   \n",
       "2  이재명의 정책은 저출생·고령화 위기를 극복하고 아이부터 어르신까지 함께 돌보는 국가를 만드는 것을 목표로 하고 있습니다. 구체적으로는 자녀양육 지원 확대, 공공임대주택 공급 확대, 난임부부 치료지원 강화 등을 실행 방법으로 제시하고 있습니다. 이 정책은 경기도에 거주 중인 30대 남성에게도 도움이 될 수 있습니다.  김문수의 청년 주거지원 정책은 문서에서 확인할 수 없기 때문에 비교할 수 있는 정보가 없습니다. 따라서 이재명의 정책을 기준으로 설명해 드릴 수밖에 없습니다. 만약 김문수의 청년 주거지원 정책에 대한 정보를 제공해주신다면 두 후보의 정책을 비교하여 보다 구체적인 설명을 제공해 드릴 수 있을 것입니다.   \n",
       "\n",
       "                                                                                                                                                                                                     출처  \\\n",
       "0  20250603_대한민국_이재명_10대공약.pdf:p14, 20250603_대한민국_이재명_10대공약.pdf:p14, 20250603_대한민국_이재명_10대공약.pdf:p14, 20250603_대한민국_이재명_10대공약.pdf:p14, 20250603_대한민국_이재명_10대공약.pdf:p14, 20250603_대한민국_이재명_10대공약.pdf:p14   \n",
       "1  20250603_대한민국_김문수_선거공약서.pdf:p25, 20250603_대한민국_김문수_선거공약서.pdf:p25, 20250603_대한민국_김문수_선거공약서.pdf:p25, 20250603_대한민국_김문수_선거공약서.pdf:p25, 20250603_대한민국_김문수_선거공약서.pdf:p25, 20250603_대한민국_김문수_선거공약서.pdf:p25   \n",
       "2  20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16, 20250603_대한민국_이재명_10대공약.pdf:p16   \n",
       "\n",
       "   정확성 점수(1~5)  풍부성 점수(1~5)  \n",
       "0            4            3  \n",
       "1            5            3  \n",
       "2            4            3  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "▶ 한 줄 요약:\n",
      "→ 이재명 후보는 청년 일자리를 위해 국민 교통비를 절감하기 위해 청년·국민·어르신 패스 3종을 도입하는 정책을 제시했습니다.\n",
      "→ 김문수 후보는 수도권 주거 안정 정책을 통해 주거 환경을 개선하고자 합니다.\n",
      "→ 이재명의 정책은 저출생·고령화 위기를 극복하고 아이부터 어르신까지 함께 돌보는 국가를 만드는 것을 목표로 하고 있습니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQAWithSourcesChain, LLMChain\n",
    "from langchain.agents import initialize_agent, Tool, AgentType\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# ✅ 기본 설정\n",
    "llm = ChatOpenAI(temperature=0.3)\n",
    "candidates = [\"이재명\", \"김문수\"]\n",
    "\n",
    "# ✅ 사용자 프로필\n",
    "user_profile = \"\"\"\n",
    "나는 경기도에 거주 중인 30대 남자야. 최근 이직은 준비하면서 서울 은평구로 이사를 하고싶은데,\n",
    "나에게 가장 도움이 되는 구체적인 정책을 제시한 후보는 누구야?\n",
    "\"\"\"\n",
    "\n",
    "# ✅ 문서 로딩 및 전처리\n",
    "file_paths = {\n",
    "    \"이재명\": [\"20250603_대한민국_이재명_10대공약.pdf\", \"20250603_대한민국_이재명_선거공약서.pdf\"],\n",
    "    \"김문수\": [\"20250603_대한민국_김문수_10대공약.pdf\", \"20250603_대한민국_김문수_선거공약서.pdf\"],\n",
    "}\n",
    "all_documents = []\n",
    "for name, paths in file_paths.items():\n",
    "    for path in paths:\n",
    "        loader = PyMuPDFLoader(path)\n",
    "        data = loader.load()\n",
    "        for d in data:\n",
    "            d.metadata[\"candidate\"] = name\n",
    "            page = d.metadata.get(\"page\", \"?\")\n",
    "            d.metadata[\"source\"] = f\"{os.path.basename(path)}:p{page}\"\n",
    "        all_documents.extend(data)\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=1000, chunk_overlap=200, encoding_name='cl100k_base')\n",
    "documents = splitter.split_documents(all_documents)\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(model_name='jhgan/ko-sbert-nli', model_kwargs={'device': 'cpu'}, encode_kwargs={'normalize_embeddings': True})\n",
    "vectorstore = Chroma.from_documents(documents, embedding=embedding_model, persist_directory=\"chroma_db\")\n",
    "vectorstore.persist()\n",
    "\n",
    "# ✅ Retriever 및 QA 체인 구성\n",
    "retrievers = {c: vectorstore.as_retriever(search_kwargs={\"k\": 6, \"filter\": {\"candidate\": c}}) for c in candidates}\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"profile\", \"summaries\", \"question\"],\n",
    "    template=\"\"\"\n",
    "당신은 정책 분석가입니다. 다음은 사용자 프로필과 대통령 후보의 공약 문서입니다.\n",
    "사용자 프로필에 맞는 정책을 찾아서 설명해주십시오. 질문에 대해 다음 사항을 반드시 포함하여 답변하십시오.\n",
    "\n",
    "[포함 사항]\n",
    "- 정책의 목적\n",
    "- 구체적 수단 (시설, 제도, 법안 등)\n",
    "- 실행 대상 또는 지역\n",
    "- 문서상 등장한 구체적인 단어(용어)를 사용\n",
    "- 반드시 한국어로 답변할 것\n",
    "\n",
    "사용자 프로필\n",
    "{profile}\n",
    "\n",
    "문맥:\n",
    "{summaries}\n",
    "\n",
    "질문:\n",
    "{question}\n",
    "\n",
    "답변:\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "qa_chains = {\n",
    "    name: RetrievalQAWithSourcesChain.from_chain_type(\n",
    "        llm=llm,\n",
    "        retriever=retrievers[name],\n",
    "        chain_type=\"stuff\",\n",
    "        chain_type_kwargs={\"prompt\": policy_prompt},\n",
    "        return_source_documents=True\n",
    "    ) for name in candidates\n",
    "}\n",
    "\n",
    "# ✅ 후보명 추출, 키워드 추출, 요약\n",
    "candidate_detect_prompt = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"\"\"\n",
    "다음 질문에서 언급된 대통령 후보의 이름을 정확히 추출하시오. 두 명 이상일 경우 모두 출력하시오.\n",
    "\n",
    "질문: {question}\n",
    "후보 이름:\n",
    "\"\"\"\n",
    ")\n",
    "candidate_chain = LLMChain(llm=llm, prompt=candidate_detect_prompt)\n",
    "\n",
    "sentence_keyword_prompt = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"\"\"\n",
    "다음 질문을 보고, 이 질문에 답하기 위해 대통령 후보의 정책 문서에서 등장할 것으로 기대되는 핵심 문장형 키워드를 3~5개 생성하세요.\n",
    "각 문장은 해당 정책의 방향, 수단, 대상 등을 포함해야 하며, 실제 문서에서 나올 수 있는 표현이어야 합니다.\n",
    "\n",
    "[질문]\n",
    "{question}\n",
    "\n",
    "[기대 문장형 키워드]\n",
    "1.\n",
    "2.\n",
    "3.\n",
    "\"\"\"\n",
    ")\n",
    "sentence_keyword_chain = LLMChain(llm=llm, prompt=sentence_keyword_prompt)\n",
    "\n",
    "def extract_sentence_keywords(question: str):\n",
    "    result = sentence_keyword_chain.run({\"question\": question})\n",
    "    return [line.strip()[2:].strip() for line in result.split(\"\\n\") if line.strip().startswith(tuple(\"12345\"))]\n",
    "\n",
    "summary_prompt = PromptTemplate(\n",
    "    input_variables=[\"answer\"],\n",
    "    template=\"\"\"\n",
    "다음 응답 내용을 바탕으로 한 문장으로 요약해 주세요. ~습니다의 어투로 통일해 주세요.\n",
    "\n",
    "응답: {answer}\n",
    "\n",
    "한 줄 요약:\n",
    "\"\"\"\n",
    ")\n",
    "summary_chain = LLMChain(llm=llm, prompt=summary_prompt)\n",
    "\n",
    "# ✅ 번역 & 비교 프롬프트\n",
    "translation_prompt = PromptTemplate(\n",
    "    input_variables=[\"english_text\"],\n",
    "    template=\"\"\"\n",
    "다음 영어 텍스트를 자연스럽고 정확한 한국어로 번역하십시오:\n",
    "\n",
    "{english_text}\n",
    "\n",
    "번역:\n",
    "\"\"\"\n",
    ")\n",
    "translation_chain = LLMChain(llm=llm, prompt=translation_prompt)\n",
    "\n",
    "compare_prompt = PromptTemplate(\n",
    "    input_variables=[\"cand1\", \"cand2\", \"topic\", \"resp1\", \"resp2\"],\n",
    "    template=\"\"\"\n",
    "아래는 대통령 후보 {cand1}와 {cand2}의 \"{topic}\" 공약에 대한 요약입니다. 다음 형식에 따라 비교하십시오:\n",
    "\n",
    "1. 정책의 목적 비교:\n",
    "2. 구체적 수단 비교:\n",
    "3. 실행 대상 또는 지역 비교:\n",
    "4. 문서상 등장한 구체적 용어 비교:\n",
    "5. 종합 요약 (한국어로):\n",
    "\n",
    "[{cand1}의 공약]:\n",
    "{resp1}\n",
    "\n",
    "[{cand2}의 공약]:\n",
    "{resp2}\n",
    "\n",
    "위 내용을 기반으로 반드시 **한국어로 작성하십시오**.\n",
    "\"\"\"\n",
    ")\n",
    "compare_chain = LLMChain(llm=llm, prompt=compare_prompt)\n",
    "\n",
    "# ✅ Tool 정의\n",
    "\n",
    "def run_candidate_policy_qa(input):\n",
    "    result = candidate_chain.invoke({\"question\": input})[\"text\"]\n",
    "    target = next((c for c in candidates if c in result), None)\n",
    "    if not target:\n",
    "        return \"후보 이름을 인식할 수 없습니다.\"\n",
    "    answer = qa_chains[target].invoke({\"profile\": user_profile, \"question\": input})[\"answer\"]\n",
    "    translated = translation_chain.invoke({\"english_text\": answer})[\"text\"]\n",
    "    return f\"Final Answer: {translated}\"\n",
    "\n",
    "def run_policy_compare(input):\n",
    "    result = candidate_chain.invoke({\"question\": input})[\"text\"]\n",
    "    involved = [c for c in candidates if c in result]\n",
    "    if len(involved) != 2:\n",
    "        return \"비교하려는 두 후보를 명확히 질문에 포함해주세요.\"\n",
    "    cand1, cand2 = involved\n",
    "    answer1 = qa_chains[cand1].invoke({\"profile\": user_profile, \"question\": input})[\"answer\"]\n",
    "    answer2 = qa_chains[cand2].invoke({\"profile\": user_profile, \"question\": input})[\"answer\"]\n",
    "    comparison = compare_chain.invoke({\"cand1\": cand1, \"cand2\": cand2, \"topic\": input, \"resp1\": answer1, \"resp2\": answer2})[\"text\"]\n",
    "    translated = translation_chain.invoke({\"english_text\": comparison})[\"text\"]\n",
    "    return f\"Final Answer: {translated}\"\n",
    "\n",
    "# ✅ Agent 구성\n",
    "react_tools = [\n",
    "    Tool(name=\"CandidatePolicyQA\", func=run_candidate_policy_qa, description=\"질문에서 후보를 식별하고 해당 공약을 검색함.\"),\n",
    "    Tool(name=\"ComparePolicies\", func=run_policy_compare, description=\"질문에서 두 후보를 식별하고 해당 공약을 비교함.\")\n",
    "]\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools=react_tools,\n",
    "    llm=llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True,\n",
    "    agent_kwargs={\n",
    "        \"system_message\": (\n",
    "            \"당신은 반드시 한국어로 사고하고 응답하는 정책 분석 도우미입니다. \"\n",
    "            \"Thought, Action, Observation, Final Answer 형식을 사용, \"\n",
    "            \"Thought와 Final Answer도 반드시 한국어여야 합니다.\"\n",
    "        )\n",
    "    },\n",
    "    handle_parsing_errors=True)\n",
    "\n",
    "def extract_sentence_keywords(question: str):\n",
    "    result = sentence_keyword_chain.run({\"question\": question})\n",
    "    return [line.strip()[2:].strip() for line in result.split(\"\\n\") if line.strip().startswith(tuple(\"12345\"))]\n",
    "\n",
    "# ✅ 후보명 추출 체인\n",
    "candidate_prompt = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"다음 질문에서 언급된 대통령 후보의 이름을 정확히 추출하시오.\\n\\n질문: {question}\\n후보 이름:\"\n",
    ")\n",
    "candidate_chain = LLMChain(llm=ChatOpenAI(temperature=0.1), prompt=candidate_prompt)\n",
    "\n",
    "# ✅ 유사도 모델\n",
    "similarity_model = SentenceTransformer(\"jhgan/ko-sbert-nli\")\n",
    "\n",
    "# ✅ QA 체인 생성\n",
    "retrievers = {\n",
    "    name: vectorstore.as_retriever(search_kwargs={\"k\": 6, \"filter\": {\"candidate\": name}})\n",
    "    for name in file_paths\n",
    "}\n",
    "llm = ChatOpenAI(temperature=0.3)\n",
    "qa_chains = {\n",
    "    name: RetrievalQAWithSourcesChain.from_chain_type(\n",
    "        llm=llm,\n",
    "        retriever=retriever,\n",
    "        chain_type=\"stuff\",\n",
    "        chain_type_kwargs={\"prompt\": prompt_template},\n",
    "        return_source_documents=True\n",
    "    ) for name, retriever in retrievers.items()\n",
    "}\n",
    "\n",
    "# ✅ 실행 함수\n",
    "def run_prompt_chaining(question: str):\n",
    "    auto_keywords = extract_sentence_keywords(question)\n",
    "    detected_name = candidate_chain.invoke({\"question\": question})[\"text\"].strip()\n",
    "    candidate = next((name for name in qa_chains if name in detected_name), None)\n",
    "\n",
    "    if not candidate:\n",
    "        return {\n",
    "            \"질문\": question,\n",
    "            \"후보\": \"감지 실패\",\n",
    "            \"응답\": \"질문에서 후보 이름을 인식하지 못했습니다.\",\n",
    "            \"출처\": \"\",\n",
    "            \"정확성 점수(1~5)\": 1,\n",
    "            \"풍부성 점수(1~5)\": 1,\n",
    "            \"한 줄 요약\": \"한 줄 요약 불가\"\n",
    "        }\n",
    "\n",
    "    qa_result = qa_chains[candidate].invoke({\"profile\": user_profile, \"question\": question})\n",
    "    answer = qa_result[\"answer\"].replace(\"\\n\", \" \").strip()\n",
    "    sources = [doc.metadata.get(\"source\") for doc in qa_result.get(\"source_documents\", [])]\n",
    "\n",
    "    summary = summary_chain.run({\"answer\": answer})\n",
    "\n",
    "    answer_embedding = similarity_model.encode(answer, convert_to_tensor=True)\n",
    "    keyword_embeddings = similarity_model.encode(auto_keywords, convert_to_tensor=True)\n",
    "    similarities = util.cos_sim(answer_embedding, keyword_embeddings)[0].cpu().tolist()\n",
    "    high_score_count = sum(score > 0.4 for score in similarities)\n",
    "    accuracy_score = round((high_score_count / len(auto_keywords)) * 5)\n",
    "    richness = 5 if len(answer) > 400 and high_score_count >= 3 else 3 if high_score_count else 1\n",
    "\n",
    "    return {\n",
    "        \"질문\": question,\n",
    "        \"후보\": candidate,\n",
    "        \"응답\": answer,\n",
    "        \"출처\": \", \".join(sources),\n",
    "        \"정확성 점수(1~5)\": accuracy_score,\n",
    "        \"풍부성 점수(1~5)\": richness,\n",
    "        \"한 줄 요약\": summary\n",
    "    }\n",
    "\n",
    "# ✅ 테스트\n",
    "questions = [\n",
    "    \"청년 일자리 마련을 위해 이재명 후보는 어떤 정책을 제시했어?\",\n",
    "    \"수도권 주거 지원을 위해 김문수 후보가 제시한 정책은 뭐야?\",\n",
    "    \"이재명과 김문수의 청년 주거지원 정책을 비교해줘.\"\n",
    "]\n",
    "results = [run_prompt_chaining(q) for q in questions]\n",
    "df_final = pd.DataFrame([{k: v for k, v in row.items() if k != \"한 줄 요약\"} for row in results])\n",
    "display(df_final)\n",
    "\n",
    "print(\"\\n▶ 한 줄 요약:\")\n",
    "for row in results:\n",
    "    print(f\"→ {row['한 줄 요약']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "Y3cyyTIDfrwX",
    "tRAH0aoYc2jy"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
