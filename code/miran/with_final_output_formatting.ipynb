{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "collapsed_sections": [
        "41uDRgtYSq-B",
        "KCz1b6QZSq-B"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain langchain-community langchain-openai\n",
        "!pip install pymupdf\n",
        "!pip install sentence-transformers\n",
        "!pip install openai\n",
        "!pip install chromadb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2HrETm_x8i70",
        "outputId": "aa4f1c1a-a293-4e5a-8483-10a90713569e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.25)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.25-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.3.22-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.58 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.63)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.44)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.5)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.41)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Collecting langchain-core<1.0.0,>=0.3.58 (from langchain)\n",
            "  Downloading langchain_core-0.3.65-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.1.2)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.68.2 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (1.84.0)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (0.9.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting langsmith<0.4,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.3.45-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (4.14.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.4.26)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain) (3.0.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading langchain_community-0.3.25-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-0.3.22-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.3/65.3 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading langchain_core-0.3.65-py3-none-any.whl (438 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.1/438.1 kB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langsmith-0.3.45-py3-none-any.whl (363 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.0/363.0 kB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, langsmith, dataclasses-json, langchain-core, langchain-openai, langchain-community\n",
            "  Attempting uninstall: langsmith\n",
            "    Found existing installation: langsmith 0.3.44\n",
            "    Uninstalling langsmith-0.3.44:\n",
            "      Successfully uninstalled langsmith-0.3.44\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.63\n",
            "    Uninstalling langchain-core-0.3.63:\n",
            "      Successfully uninstalled langchain-core-0.3.63\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-community-0.3.25 langchain-core-0.3.65 langchain-openai-0.3.22 langsmith-0.3.45 marshmallow-3.26.1 mypy-extensions-1.1.0 pydantic-settings-2.9.1 python-dotenv-1.1.0 typing-inspect-0.9.0\n",
            "Collecting pymupdf\n",
            "  Downloading pymupdf-1.26.1-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
            "Downloading pymupdf-1.26.1-cp39-abi3-manylinux_2_28_x86_64.whl (24.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m78.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pymupdf\n",
            "Successfully installed pymupdf-1.26.1\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.52.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.32.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.2.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.4.26)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m106.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m79.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m62.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m98.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.84.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.5)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.14.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
            "Collecting chromadb\n",
            "  Downloading chromadb-1.0.12-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.2.2.post1)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (2.11.5)\n",
            "Collecting fastapi==0.115.9 (from chromadb)\n",
            "  Downloading fastapi-0.115.9-py3-none-any.whl.metadata (27 kB)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.34.3)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.11/dist-packages (from chromadb) (2.0.2)\n",
            "Collecting posthog>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-4.7.0-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.14.0)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_api-1.34.1-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.34.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.55b1-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_sdk-1.34.1-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.21.1)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.67.1)\n",
            "Collecting overrides>=7.3.1 (from chromadb)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.72.1)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.16.0)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Downloading kubernetes-33.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (9.1.2)\n",
            "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.0.2)\n",
            "Collecting mmh3>=4.0.1 (from chromadb)\n",
            "  Downloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.10.18)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.24.0)\n",
            "Collecting starlette<0.46.0,>=0.40.0 (from fastapi==0.115.9->chromadb)\n",
            "  Downloading starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (24.2)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.25.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.38.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.32.3)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.4.0)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.70.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.34.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.34.1-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting opentelemetry-proto==1.34.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_proto-1.34.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-instrumentation-asgi==0.55b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.55b1-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting opentelemetry-instrumentation==0.55b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation-0.55b1-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.55b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_semantic_conventions-0.55b1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting opentelemetry-util-http==0.55b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_util_http-0.55b1-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation==0.55b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.2)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.55b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (1.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (0.4.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (2.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.13.2->chromadb) (0.32.4)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.0)\n",
            "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-1.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.3.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (1.1.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.22.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
            "Downloading chromadb-1.0.12-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.3/19.3 MB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.115.9-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl (284 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kubernetes-33.1.0-py2.py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.34.1-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.34.1-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.34.1-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.34.1-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.7/55.7 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_instrumentation_fastapi-0.55b1-py3-none-any.whl (12 kB)\n",
            "Downloading opentelemetry_instrumentation-0.55b1-py3-none-any.whl (31 kB)\n",
            "Downloading opentelemetry_instrumentation_asgi-0.55b1-py3-none-any.whl (16 kB)\n",
            "Downloading opentelemetry_semantic_conventions-0.55b1-py3-none-any.whl (196 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.2/196.2 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_util_http-0.55b1-py3-none-any.whl (7.3 kB)\n",
            "Downloading opentelemetry_sdk-1.34.1-py3-none-any.whl (118 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.5/118.5 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading posthog-4.7.0-py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.0/102.0 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
            "Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading starlette-0.45.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (454 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.8/454.8 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53803 sha256=569fe91a749bdda7ce597db5d3f011ce685406e36a6547b9d238c4d49f182cf7\n",
            "  Stored in directory: /root/.cache/pip/wheels/a3/01/bd/4c40ceb9d5354160cb186dcc153360f4ab7eb23e2b24daf96d\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, durationpy, uvloop, overrides, opentelemetry-util-http, opentelemetry-proto, mmh3, humanfriendly, httptools, bcrypt, backoff, asgiref, watchfiles, starlette, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, coloredlogs, opentelemetry-semantic-conventions, onnxruntime, kubernetes, fastapi, opentelemetry-sdk, opentelemetry-instrumentation, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-instrumentation-fastapi, chromadb\n",
            "  Attempting uninstall: starlette\n",
            "    Found existing installation: starlette 0.46.2\n",
            "    Uninstalling starlette-0.46.2:\n",
            "      Successfully uninstalled starlette-0.46.2\n",
            "  Attempting uninstall: fastapi\n",
            "    Found existing installation: fastapi 0.115.12\n",
            "    Uninstalling fastapi-0.115.12:\n",
            "      Successfully uninstalled fastapi-0.115.12\n",
            "Successfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.3.0 chromadb-1.0.12 coloredlogs-15.0.1 durationpy-0.10 fastapi-0.115.9 httptools-0.6.4 humanfriendly-10.0 kubernetes-33.1.0 mmh3-5.1.0 onnxruntime-1.22.0 opentelemetry-api-1.34.1 opentelemetry-exporter-otlp-proto-common-1.34.1 opentelemetry-exporter-otlp-proto-grpc-1.34.1 opentelemetry-instrumentation-0.55b1 opentelemetry-instrumentation-asgi-0.55b1 opentelemetry-instrumentation-fastapi-0.55b1 opentelemetry-proto-1.34.1 opentelemetry-sdk-1.34.1 opentelemetry-semantic-conventions-0.55b1 opentelemetry-util-http-0.55b1 overrides-7.7.0 posthog-4.7.0 pypika-0.48.9 starlette-0.45.3 uvloop-0.21.0 watchfiles-1.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['OPENAI_API_KEY'] = input(\"Enter your OpenAI API key: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBTi-HkLW47d",
        "outputId": "5ed0a6cc-457d-489e-bb82-f2d415ee5814"
      },
      "execution_count": 3,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your OpenAI API key: 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\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 최종 출력 포맷 조정"
      ],
      "metadata": {
        "id": "OeQ_uKn5Sq-A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NaverAPI"
      ],
      "metadata": {
        "id": "41uDRgtYSq-B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "naver news api\n",
        "\"\"\"\n",
        "\n",
        "import urllib.request\n",
        "import urllib.parse\n",
        "import json\n",
        "# from dotenv import load_dotenv\n",
        "import os\n",
        "import time\n",
        "import openai\n",
        "import ast\n",
        "\n",
        "class NaverNewsAPI:\n",
        "    def __init__(self):\n",
        "        # load_dotenv()\n",
        "        # self.client_id = os.getenv(\"NAVER_API_CLIENT_ID\")\n",
        "        # self.client_secret = os.getenv(\"NAVER_API_CLIENT_SECRET\")\n",
        "        self.client_id = \"EPCR5d1whNbimUA9ICpK\"\n",
        "        self.client_secret = \"oAjgY5t6Pi\"\n",
        "        self.base_url = \"https://openapi.naver.com/v1/search/news.json\"\n",
        "\n",
        "    def search(self, keyword: str, display: int = 50,sort='date') -> dict:\n",
        "        enc_text = urllib.parse.quote(keyword)\n",
        "        url = f\"{self.base_url}?query={enc_text}&display={display}\"\n",
        "\n",
        "        request = urllib.request.Request(url)\n",
        "        request.add_header(\"X-Naver-Client-Id\", self.client_id)\n",
        "        request.add_header(\"X-Naver-Client-Secret\", self.client_secret)\n",
        "\n",
        "        try:\n",
        "            with urllib.request.urlopen(request) as response:\n",
        "                if response.getcode() == 200:\n",
        "                    response_body = response.read().decode('utf-8')\n",
        "                    print(\"\\n✅ request Success\")\n",
        "                    return json.loads(response_body)\n",
        "                else:\n",
        "                    print(f\"❌ Error Code: {response.getcode()}\")\n",
        "                    return {}\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Request failed: {e}\")\n",
        "            return {}\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "iaaCRl_YSq-B"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NaverAPI 호출함수"
      ],
      "metadata": {
        "id": "KCz1b6QZSq-B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "b-Md55O8Sq-B"
      },
      "outputs": [],
      "source": [
        "# gpt 로 돌리는 경우\n",
        "\n",
        "\"\"\"\n",
        "news search\n",
        "\"\"\"\n",
        "\n",
        "# ✅ API 키 설정\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "news = NaverNewsAPI()\n",
        "\n",
        "def gpt_prompt_action(prompt: str, max_tokens: int):\n",
        "  response = openai.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=0.7,\n",
        "        max_tokens=max_tokens\n",
        "  )\n",
        "\n",
        "  return response.choices[0].message.content.strip()\n",
        "\n",
        "\n",
        "def summary(text: str, keyword: str):\n",
        "  prompt = f\"\"\"\n",
        "너는 뉴스 분석 전문가야. 다음은 뉴스 기사 전문이야.\n",
        "\n",
        "[뉴스 기사 전문]\n",
        "{text}\n",
        "\n",
        "이 기사에서 \"{keyword}\"와 관련된 내용이 있다면, 관련된 내용을 요약해서 알려줘.\n",
        "만약 관련 내용이 없다면 부가 설명 없이 \"관련 없음\" 이란 단어만 말해줘.\n",
        "\"\"\"\n",
        "\n",
        "  return gpt_prompt_action(prompt,300)\n",
        "\n",
        "\n",
        "def news_filter(news_list: list, search_word: str) :\n",
        "  filter_ls = [x.replace('\"', '') for x in news_list if '관련 없음' not in x]\n",
        "  count = len(filter_ls)\n",
        "  concat_text = '\\n'.join(filter_ls)\n",
        "  prompt = f\"\"\"\n",
        "아래 문장들을 보고 {search_word} 주제 기준으로 긍정적인지 부정적인지 알려줘.\n",
        "\n",
        "{concat_text}\n",
        "\n",
        "답변은 부가 설명없이 아래 list안에 json 형식을 담아서 답변해줘.\n",
        "요소인 json 형식은 아래와 같아. 총 {count}개 문장이니 리스트에 요소 확실히 개수 맞춰서 대답해줘.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "  add_prompt = \"\"\"\n",
        "{\n",
        "    'num' : '위에 나오는 문장의 순서',\n",
        "    'sentiment' : '긍정 or 부정'\n",
        "}\n",
        "\n",
        "답변은 꼭 리스트로 해줘\n",
        "  \"\"\"\n",
        "\n",
        "  return gpt_prompt_action(prompt+add_prompt, 4000)\n",
        "\n",
        "\n",
        "def news_final_summary(candidate: str, search_word: str):\n",
        "    try:\n",
        "        result = news.search(keyword=candidate + \" \" + search_word)\n",
        "    except Exception as e:\n",
        "        return f\"뉴스 검색 중 오류 발생: {e}\"\n",
        "\n",
        "    check_ls = []\n",
        "    for item in result.get(\"items\", []):\n",
        "        try:\n",
        "            result = summary(item['title'] + item['description'], search_word)\n",
        "            check_ls.append(result)\n",
        "        except Exception as e:\n",
        "            check_ls.append(f\"요약 실패: {e}\")\n",
        "\n",
        "    filter_ls = [x.replace('\"', '') for x in check_ls if '관련 없음' not in x]\n",
        "    concat_text = '\\n'.join(filter_ls)\n",
        "    prompt = f\"\"\"\n",
        "    너는 정책 분석 전문가야.\n",
        "\n",
        "    아래 문장들은 다양한 뉴스 기사에서 추출된 내용이야.\n",
        "    이 문장들을 보고 {candidate} 후보의 \"{search_word}\" 주제와 직접적으로 관련된 정책이 있는지 판단해.\n",
        "\n",
        "    만약 {candidate} 후보의 정책이 명확하게 드러난다면, **구체적인 정책 내용을 요약해서 한 문단으로 작성해줘.**\n",
        "\n",
        "    하지만 다음 중 하나라도 해당된다면, 부가 설명 없이 반드시 \"관련 없음\" 이라고만 말해:\n",
        "    - 뉴스 내용이 {candidate} 후보의 정책이 아닌 경우\n",
        "    - {search_word} 주제와 직접 관련이 없는 경우\n",
        "    - 정책의 내용이 불분명하거나 판단이 애매한 경우\n",
        "\n",
        "    문장 목록:\n",
        "    {concat_text}\n",
        "\n",
        "    답변 형식:\n",
        "    - 관련 있을 경우: {candidate} 후보의 정책 요약 한 문단\n",
        "    - 관련 없을 경우: 관련 없음\n",
        "    \"\"\"\n",
        "\n",
        "    return gpt_prompt_action(prompt, 4000)\n",
        "\n",
        "def news_sentiment_action(search_word: str) :\n",
        "    # main.py\n",
        "    result = news.search(keyword = search_word)\n",
        "\n",
        "    # print(f\"result - {result}\")\n",
        "\n",
        "    # 예시 출력\n",
        "    check_ls = []\n",
        "    for item in result.get(\"items\", []):\n",
        "        result = summary(item['title'] + item['description'], search_word)\n",
        "        check_ls.append(result)\n",
        "        # 여기서 요약 태워서 김문수 후보의 청년 주거 정책에 관련된 뉴스가 맞는지? 맞으면 그 내용은 요약해서 무엇인지 내놓게 하기\n",
        "        # 그다음 해당 내용들을 기준으로 감성 분석 진행 -> 100개 기준 몇개가 긍정적인지 부정적일지로 해서\n",
        "\n",
        "    final_result = news_filter(check_ls, search_word)\n",
        "\n",
        "    # 문자열 → 리스트로 안전하게 변환\n",
        "\n",
        "    retries = 0\n",
        "    max_retries = 3\n",
        "    while retries < max_retries:\n",
        "        try:\n",
        "            data = ast.literal_eval(final_result)\n",
        "            if isinstance(data, list):  # 리스트인지 확인\n",
        "                # return data\n",
        "                # 긍정/부정 개수 세기\n",
        "                total = len(data)\n",
        "                positive = sum(1 for item in data if item['sentiment'] == '긍정')\n",
        "                negative = sum(1 for item in data if item['sentiment'] == '부정')\n",
        "\n",
        "                # 비율 계산\n",
        "                positive_ratio = round(positive / total * 100, 2)\n",
        "                negative_ratio = round(negative / total * 100, 2)\n",
        "\n",
        "                print(f\"총 개수: {total}\")\n",
        "                print(f\"긍정: {positive}개 ({positive_ratio}%)\")\n",
        "                print(f\"부정: {negative}개 ({negative_ratio}%)\")\n",
        "\n",
        "                final_result = f\"{search_word} - 긍정({positive_ratio}) / 부정({negative_ratio})\"\n",
        "\n",
        "                return final_result\n",
        "            else:\n",
        "                print(\"⚠️ 변환 성공했으나 리스트 타입이 아닙니다.\")\n",
        "                return None\n",
        "        except (ValueError, SyntaxError) as e:\n",
        "            print(f\"❌ ast.literal_eval 실패 (시도 {retries + 1}/{max_retries}): {e}\")\n",
        "            retries += 1\n",
        "            time.sleep(1)\n",
        "\n",
        "    return None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PDF 로드 및 벡터DB 생성"
      ],
      "metadata": {
        "id": "udpwMSvSSq-B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "from difflib import SequenceMatcher\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.agents import Tool, initialize_agent\n",
        "from langchain.agents.agent_types import AgentType\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain, RetrievalQAWithSourcesChain\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.document_loaders import PyMuPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "# ✅ 후보자 정보\n",
        "candidates = [\"이재명\", \"김문수\", \"이준석\", \"권영국\", \"송진호\"]\n",
        "PDF_FOLDER = \"/content/\"\n",
        "\n",
        "file_paths = {\n",
        "    name: [f\"{PDF_FOLDER}20250604_대한민국_{name}_선거공약서.pdf\"] * 2\n",
        "    for name in candidates\n",
        "}\n",
        "\n",
        "# ✅ 문서 로딩\n",
        "all_documents = []\n",
        "for name, paths in file_paths.items():\n",
        "    for path in paths:\n",
        "        loader = PyMuPDFLoader(path)\n",
        "        data = loader.load()\n",
        "        for d in data:\n",
        "            d.metadata[\"candidate\"] = name\n",
        "            page = d.metadata.get(\"page\", \"?\")\n",
        "            d.metadata[\"source\"] = f\"{os.path.basename(path)}:p{page}\"\n",
        "        all_documents.extend(data)\n",
        "\n",
        "# ✅ 문서 분할\n",
        "splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
        "    chunk_size=1000, chunk_overlap=200, encoding_name='cl100k_base'\n",
        ")\n",
        "documents = splitter.split_documents(all_documents)\n",
        "\n",
        "# ✅ 임베딩 및 벡터스토어 생성\n",
        "embedding_model = HuggingFaceEmbeddings(\n",
        "    model_name='jhgan/ko-sbert-nli',\n",
        "    model_kwargs={'device': 'cpu'},\n",
        "    encode_kwargs={'normalize_embeddings': True}\n",
        ")\n",
        "vectorstore = Chroma.from_documents(documents, embedding=embedding_model, persist_directory=\"chroma_db\")\n",
        "vectorstore.persist()\n",
        "\n",
        "# ✅ 후보별 Retriever\n",
        "retrievers = {\n",
        "    c: vectorstore.as_retriever(search_kwargs={\"k\": 6, \"filter\": {\"candidate\": c}})\n",
        "    for c in candidates\n",
        "}\n",
        "\n",
        "# ✅ 모델 초기화\n",
        "llm = ChatOpenAI(temperature=0.2)\n"
      ],
      "metadata": {
        "id": "YiRbqA4MSq-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ 유틸 함수\n",
        "def is_empty_or_irrelevant(answer: str) -> bool:\n",
        "    patterns = [\"관련.*없\", \"언급되지 않았습니다\", \"포함되어 있지 않습니다\", \"등장하지 않습니다\", \"찾을 수 없습니다\", \"문서에.*없\"]\n",
        "    return not answer.strip() or any(re.search(p, answer) for p in patterns)\n",
        "\n",
        "def is_english(text: str, threshold: float = 0.6) -> bool:\n",
        "    english_chars = re.findall(r'[a-zA-Z]', text)\n",
        "    total_chars = re.findall(r'\\S', text)\n",
        "    return bool(total_chars) and len(english_chars) / len(total_chars) >= threshold\n",
        "\n",
        "def translate_if_needed(text: str) -> str:\n",
        "    if is_english(text):\n",
        "        result = translation_chain.invoke({\"english_text\": text})\n",
        "        return result[\"text\"] if isinstance(result, dict) else result\n",
        "    return text\n",
        "\n",
        "def format_candidate_policy(candidate: str, answer: str) -> str:\n",
        "    return f\"[{candidate} 후보]\\n📄 PDF 기반 공약: \\n{answer.strip()}\"\n",
        "\n",
        "\n",
        "#질의와 Agent응답 결과간의 관련성 체크\n",
        "def is_llm_irrelevant(question: str, answer: str) -> bool:\n",
        "\n",
        "    try:\n",
        "        # print(f\"[관련성 판단 호출] Q: {question} / A: {answer}\")\n",
        "        result = relevance_chain.invoke({\"question\": question, \"answer\": answer})\n",
        "        result_text = result[\"text\"].strip() if isinstance(result, dict) else result.strip()\n",
        "        print(f\"관련성 판단 결과: {result_text}\")\n",
        "        return \"관련 없음\" in result_text\n",
        "    except Exception as e:\n",
        "        print(f\"❌ 관련성 판단 실패: {e}\")\n",
        "        return False\n",
        "\n",
        "\n",
        "# ✅ 후보별 요약 수집 및 비교표 정보 생성\n",
        "def summarize_all_candidates(keywords: list[str], question: str) -> tuple[str, list[dict]]:\n",
        "    summaries = []\n",
        "    comparison_rows = []\n",
        "    for cand in candidates:\n",
        "        try:\n",
        "            full_summary = []\n",
        "            for kw in keywords:\n",
        "                result = qa_chains[cand].invoke({\"question\": kw})[\"answer\"].strip()\n",
        "                full_summary.append(f\"- {kw}: {result}\")\n",
        "\n",
        "            joined_summary = \"\\n\".join(full_summary)\n",
        "            summaries.append(f\"[{cand} 후보]\\n{joined_summary}\")\n",
        "\n",
        "            # 상세 분해 추출\n",
        "            extract = detailed_policy_chain.invoke({\"question\": question, \"summary\": joined_summary})[\"text\"]\n",
        "            extract_lines = extract.split(\"\\n\")\n",
        "            row = {\n",
        "                \"후보\": cand,\n",
        "                \"핵심 공약\": extract_lines[0].replace(\"핵심 공약:\", \"\").strip() if len(extract_lines) > 0 else \"\",\n",
        "                \"실현 방식\": extract_lines[1].replace(\"실현 방식:\", \"\").strip() if len(extract_lines) > 1 else \"\",\n",
        "                \"강점\": extract_lines[2].replace(\"강점:\", \"\").strip() if len(extract_lines) > 2 else \"\"\n",
        "            }\n",
        "            comparison_rows.append(row)\n",
        "\n",
        "        except Exception as e:\n",
        "            summaries.append(f\"[{cand} 후보] 요약 실패: {e}\")\n",
        "            comparison_rows.append({\"후보\": cand, \"핵심 공약\": \"요약 실패\", \"실현 방식\": \"\", \"강점\": \"\"})\n",
        "\n",
        "    return \"\\n\\n\".join(summaries), comparison_rows\n",
        "\n",
        "\n",
        "\n",
        "# ✅ 불릿 형식 비교 요약 생성\n",
        "def build_bullet_summary(rows: list[dict]) -> str:\n",
        "    lines = [\"[후보별 공약 요약]\"]\n",
        "    for row in rows:\n",
        "        lines.append(f\"- {row['후보']} 후보:\")\n",
        "        lines.append(f\"  • 핵심 공약: {row['핵심 공약']}\")\n",
        "        lines.append(f\"  • 실현 방식: {row['실현 방식']}\")\n",
        "        lines.append(f\"  • 강점: {row['강점']}\")\n",
        "    return \"\\n\".join(lines)\n",
        "\n",
        "\n",
        "# ✅ 출력 포맷 조립\n",
        "def format_recommendation_output(question: str, comparison_rows: list[dict], recommendation_text: str) -> str:\n",
        "    bullets = build_bullet_summary(comparison_rows)\n",
        "    return f\"\"\"[질문]\n",
        "{question}\n",
        "\n",
        "{bullets}\n",
        "\n",
        "[추천 요약]\n",
        "{recommendation_text}\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def format_final_comparison(topic: str, comparisons: list[str]) -> str:\n",
        "    return f\"\"\"✅ '{topic}'에 대한 후보별 공약 비교 분석 결과\\n\\n{chr(10).join(comparisons)}\"\"\"\n",
        "\n",
        "# ✅ 단일 후보 공약 질의 실행 함수\n",
        "def run_candidate_policy_qa(input: str) -> str:\n",
        "    print(\"#### 단일 후보 공약 질의 Tool 활성화....\")\n",
        "    print(\"#### 후보자 이름 추출 중....\")\n",
        "    result = candidate_chain.invoke({\"question\": input})[\"text\"]\n",
        "    target = next((c for c in candidates if c in result), None)\n",
        "    if not target:\n",
        "        return \"Final Answer: 후보 이름을 인식할 수 없습니다.\"\n",
        "\n",
        "    print(f\"#### {target} 후보자 공약집 검색 중....\")\n",
        "    result_dict = qa_chains[target].invoke({\"question\": input})\n",
        "    answer = result_dict[\"answer\"].strip()\n",
        "    sources = result_dict.get(\"source_documents\", [])\n",
        "\n",
        "    print(\"#### 관련성 체크 중....\")\n",
        "    if is_empty_or_irrelevant(answer) or is_llm_irrelevant(input, answer) or len(sources) <= 1:\n",
        "        return f\"Final Answer: 공약 없음\"\n",
        "    else:\n",
        "        print(\"#### 단일 후보 공약 RAG 실행 완료 ####\")\n",
        "\n",
        "        print(\"#### 사후 포맷팅 진행 ####\")\n",
        "        print(\"#\"*50)\n",
        "        answer = translate_if_needed(answer)\n",
        "        final_text = single_candidate_formatter_chain.invoke({\n",
        "                \"question\": input,\n",
        "                \"summaries\": answer,\n",
        "                \"sources\": sources,\n",
        "            })[\"text\"]\n",
        "\n",
        "\n",
        "        #✅ 전역 또는 외부에서 접근 가능하도록 저장 (예: 전역 dict)\n",
        "        global last_observation_output\n",
        "        last_observation_output = final_text  # ✅ 이 변수에 저장됨\n",
        "\n",
        "        return f\"Final Answer:\\n{final_text}\"\n",
        "\n",
        "\n",
        "\n",
        "# ✅ 다자 공약 비교 실행 함수\n",
        "def run_policy_compare_all(input):\n",
        "    print(\"\\n#### 후보별 공약 비교 Tool 활성화....\")\n",
        "    print(\"##### 후보자 이름 추출 중....\")\n",
        "    if \",\" in input:\n",
        "        split = [c.strip() for c in input.split(\",\")]\n",
        "        involved = [c for c in split if c in candidates]\n",
        "        keyword = next((k for k in split if k not in candidates), input)\n",
        "    else:\n",
        "        involved = candidates\n",
        "        keyword = input.strip()\n",
        "\n",
        "    print(f\"#### 후보자 이름 : {involved}\")\n",
        "    #RAG 실행\n",
        "    comparisons = []\n",
        "    for cand in involved:\n",
        "        print(f\"#### {cand} 후보자 공약집 검색 중....\")\n",
        "        result_dict = qa_chains[cand].invoke({\"question\": keyword})\n",
        "        answer = result_dict[\"answer\"]\n",
        "        sources = result_dict.get(\"source_documents\", [])\n",
        "\n",
        "        if is_empty_or_irrelevant(answer) or is_llm_irrelevant(input, answer) or len(sources) <= 1:\n",
        "            answer = \"공약 없음\"\n",
        "\n",
        "        answer = translate_if_needed(answer)\n",
        "        answer = format_candidate_policy(cand, answer)\n",
        "\n",
        "        comparisons.append(answer)\n",
        "\n",
        "    print(f\"#### 공약 비교 중....\")\n",
        "    result = compare_chain.invoke({\n",
        "        \"topic\": keyword,\n",
        "        \"comparisons\": \"\\n\\n\".join(comparisons)\n",
        "    })[\"text\"]\n",
        "    result = translate_if_needed(result)\n",
        "\n",
        "    print(\"#### 후보별 공약 비교 완료 ####\")\n",
        "    print(\"#\"*50)\n",
        "\n",
        "    # ✅ 최종 텍스트 구성\n",
        "    final_text = f\"{format_final_comparison(keyword, comparisons)}\\n\\n✅ 최종 비교 분석\\n{result}\"\n",
        "\n",
        "\n",
        "    #✅ 전역 또는 외부에서 접근 가능하도록 저장 (예: 전역 dict)\n",
        "    global last_observation_output\n",
        "    last_observation_output = final_text  # ✅ 이 변수에 저장됨\n",
        "\n",
        "    return f\"Final Answer:\\n{final_text}\"\n",
        "\n",
        "\n",
        "# ✅ 사용자 맞춤 추천 실행 함수\n",
        "def run_user_profile_recommendation(question: str) -> str:\n",
        "\n",
        "    print(\"\\n#### 사용자 컨텍스트 별 질의 응답 Tool 활성화....\")\n",
        "    print(\"##### 사용자 프로파일 추출 중....\")\n",
        "\n",
        "    # 1. 사용자 프로파일 추출\n",
        "    profile_result = extract_user_profile_chain.invoke({\"question\": question})[\"text\"]\n",
        "\n",
        "\n",
        "    # 2. 관심 키워드 추출\n",
        "    keywords = re.findall(r'관심정책 키워드\\s*\\(.*?\\):\\s*(.*)', profile_result)\n",
        "    keyword_list = keywords[0].split(\",\") if keywords else []\n",
        "\n",
        "    print(\"##### 후보별 공약 요약 중....\")\n",
        "\n",
        "    # 3. 후보별 공약 요약\n",
        "    summaries, comparison_rows = summarize_all_candidates([kw.strip() for kw in keyword_list], question)\n",
        "\n",
        "    # 4. 추천 수행\n",
        "    recommendation = recommend_chain.invoke({\n",
        "        \"question\": question,\n",
        "        \"profile\": profile_result,\n",
        "        \"summaries\": summaries\n",
        "    })[\"text\"]\n",
        "\n",
        "    question = translate_if_needed(question)\n",
        "\n",
        "    # ✅ 최종 텍스트 구성\n",
        "    final_text = format_recommendation_output(question, comparison_rows, recommendation)\n",
        "\n",
        "    print(\"#### 사용자 컨텍스트 별 질의 응답 완료 ####\")\n",
        "    print(\"#\"*50)\n",
        "\n",
        "    #✅ 전역 또는 외부에서 접근 가능하도록 저장 (예: 전역 dict)\n",
        "    global last_observation_output\n",
        "    last_observation_output = final_text  # ✅ 이 변수에 저장됨\n",
        "\n",
        "    return \"Final Answer:\\n\" + final_text\n",
        "\n",
        "\n",
        "\n",
        "# ✅ 실시간 뉴스 검색\n",
        "def run_policy_news_issue(input: str) -> str:\n",
        "    print(\"\\n#### 실시간 여론 반응 분석 Tool 활성화....\")\n",
        "    print(\"#### 후보자 이름 추출 중....\")\n",
        "    result = candidate_chain.invoke({\"question\": input})[\"text\"]\n",
        "    candidate = next((c for c in candidates if c in result), None)\n",
        "    if not candidate:\n",
        "        return \"Final Answer: 후보 이름을 인식할 수 없습니다.\"\n",
        "\n",
        "\n",
        "    # 정책 키워드 추출 (후보명 제외 나머지)\n",
        "    keyword = input.replace(candidate, \"\").strip(\" ,\")\n",
        "    if not keyword:\n",
        "        return \"Final Answer: 정책 주제(키워드)를 포함해 질문해 주세요.\"\n",
        "\n",
        "    print(f'#### {candidate} 후보의 {keyword} 관련 정책 뉴스 검색 중...')\n",
        "    try:\n",
        "        news_summary = news_final_summary(candidate, keyword)\n",
        "\n",
        "        # ✅ 최종 텍스트 구성\n",
        "        final_text = news_issue_summary_chain.invoke({\n",
        "                    \"candidate\": candidate,\n",
        "                    \"keyword\": keyword,\n",
        "                    \"news_summary\": news_summary\n",
        "                })[\"text\"]\n",
        "\n",
        "\n",
        "        print(\"#### 실시간 여론 반응 분석 완료 ####\")\n",
        "        print(\"#\"*50)\n",
        "\n",
        "        global last_observation_output\n",
        "        last_observation_output = final_text  # ✅ 이 변수에 저장됨\n",
        "\n",
        "        return final_text or f\"{candidate} 후보의 '{keyword}' 관련 정책 정보를 외부에서 찾을 수 없습니다.\"\n",
        "    except Exception as e:\n",
        "        return f\"{candidate} 후보의 '{keyword}' 관련 외부 뉴스 요약 중 오류가 발생했습니다: {e}\"\n",
        "\n",
        "\n",
        "# ✅ 툴 & 에이전트 설정\n",
        "tool_qa = Tool(name=\"CandidatePolicyQA\", func=run_candidate_policy_qa, description=\"후보 이름과 주제를 기반으로 공약을 PDF에서 찾고, 공약 없음이면 바로 종료한다.\")\n",
        "tool_compare = Tool(name=\"ComparePolicies\", func=run_policy_compare_all, description=\"복수 후보 간 특정 주제에 대한 공약을 비교합니다.\")\n",
        "tool_recommend = Tool(name=\"RecommendCandidateNatural\", func=run_user_profile_recommendation, description=\"사용자 질문에서 상황을 추출하고 적합한 후보를 추천합니다.\")\n",
        "tool_news = Tool(name=\"PolicyNewsIssueCheck\",func=run_policy_news_issue,description=\"후보와 정책 키워드에 대해 최근 뉴스나 논란, 실제 이행 상황 등 사회적 이슈를 요약합니다.\"\n",
        ")\n",
        "\n",
        "react_tools = [tool_qa, tool_compare, tool_recommend,tool_news]\n",
        "\n",
        "\n",
        "agent = initialize_agent(\n",
        "    tools=react_tools,\n",
        "    llm=llm,\n",
        "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=False,  # verbose=True면 Thought/Action 로그 출력됨\n",
        "    agent_kwargs={\n",
        "        \"system_message\": (\n",
        "            \"당신은 반드시 한국어로 사고하고 응답하는 정책 분석 도우미입니다. \"\n",
        "            \"Thought, Action, Observation, Final Answer 형식을 사용하며, \"\n",
        "            \"**Final Answer로 시작하는 응답이 나오면 체인을 반드시 종료하십시오.**\"\n",
        "        )\n",
        "    },\n",
        "    handle_parsing_errors=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "sInXJmhdSq-C"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 프롬프트"
      ],
      "metadata": {
        "id": "XfHBJAERSq-B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ 단일 후보 공약 질의용 프롬프트\n",
        "fomatting_single_candidate_prompt = PromptTemplate(\n",
        "    input_variables=[\"summaries\", \"question\",\"sources\"],\n",
        "    template=\"\"\"\n",
        "아래는 대통령 후보의 공약 문서에서 발췌한 내용입니다. 주어진 문맥을 기반으로 사용자의 질문에 응답하되, 주의사항을 고려해서 다음과 같은 형식으로 작성하십시오.\n",
        "주의사항:반드시 문서의 내용에 기반하여 답하라. 문서에 없는 내용은 추측하지 마라.후보이름과 질문 주제로 문장을 만들지 마라 한국어로 답변할 것\n",
        "\n",
        "\n",
        "1. 정책 개요\n",
        "정책의 목적과 방향성을 간결히 기술하십시오.\n",
        "\n",
        "2. 주요 추진 전략\n",
        "구체적인 수단이나 실행 계획을 2~4개 항목으로 불릿(bullet) 형식으로 정리하십시오.\n",
        "\n",
        "3. 기대 효과 및 정책 방향\n",
        "정책이 지향하는 기대 효과 및 장기적 비전을 서술하십시오.\n",
        "\n",
        "4. 문서 출처 요약\n",
        "해당 내용을 발췌한 공약 문서의 파일명 및 페이지 번호(예: 2025공약서.pdf:p12, p13)를 명시하십시오.\n",
        "\n",
        "\n",
        "출력 예시는 다음과 같습니다:\n",
        "1. 정책 개요:\n",
        "친환경 수산업 전환을 목표로 함. (후보자 이름 및 정책명 언급 금지)\n",
        "\n",
        "2: 주요 추진 전략:\n",
        "- 전략1\n",
        "- 전략2\n",
        "- 전략3\n",
        "\n",
        "기대 효과 및 정책 방향\n",
        "어촌과 수산경제의 지속가능한 발전 실현. (후보자 이름 및 정책명 언급 금지)\n",
        "\n",
        "문서 출처 요약\n",
        "20250604_대한민국_이재명_선거공약서.pdf: p1, p7, p8\n",
        "\n",
        "\n",
        "문맥:\n",
        "{summaries}\n",
        "\n",
        "질문:\n",
        "{question}\n",
        "\n",
        "sources:\n",
        "{sources}\n",
        "\n",
        "출력 형식에 맞게 한국어로 답하십시오.\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "single_candidate_policy_prompt = PromptTemplate(\n",
        "    input_variables=[\"summaries\", \"question\"],\n",
        "    template=\"\"\"\n",
        "아래 문서는 대통령 후보의 공약이다.\n",
        "질문에 대해 주의사항을 고려하고, 다음 요소를 포함하여 답변하라:\n",
        "\n",
        "주의사항:반드시 문서의 내용에 기반하여 답하라. 문서에 없는 내용은 추측하지 말고 답하지 마라.반드시 한국어로 답변할 것\n",
        "\n",
        "- 정책의 목적\n",
        "- 구체적 수단 (시설, 제도, 법안 등)\n",
        "- 실행 대상 또는 지역\n",
        "- 문서상 등장한 구체적인 단어(용어)를 사용\n",
        "\n",
        "\n",
        "문맥:\n",
        "{summaries}\n",
        "\n",
        "질문:\n",
        "{question}\n",
        "\n",
        "답변:\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# ✅ 후보간 공약 비교 프롬프트\n",
        "multi_candidate_comparison_prompt = PromptTemplate(\n",
        "    input_variables=[\"topic\", \"comparisons\"],\n",
        "    template=\"\"\"\n",
        "다음은 '{topic}'에 대한 대통령 후보 공약 요약이다. 다음 기준에 따라 자세히 비교하라:\n",
        "\n",
        "1. 정책의 목적 비교\n",
        "2. 구체적 수단 비교\n",
        "3. 실행 대상 또는 지역 비교\n",
        "4. 문서상 등장한 구체적 용어 비교\n",
        "\n",
        "아래 형식을 유지하고 문장을 요약하지 마시오. 반드시 문단 단위로 상세히 작성하고, 후보별 차이점을 구체적으로 명시하시오.\n",
        "\n",
        "후보별 공약:\n",
        "{comparisons}\n",
        "\n",
        "반드시 한국어로 작성하시오.\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "# ✅ 사용자 프로파일 추출\n",
        "user_profile_extraction_prompt = PromptTemplate(\n",
        "    input_variables=[\"question\"],\n",
        "    template=\"\"\"\n",
        "다음 질문에서 사용자 프로파일을 추론하시오:\n",
        "{question}\n",
        "\n",
        "- 연령:\n",
        "- 직업/소득:\n",
        "- 주거 상태:\n",
        "- 관심 정책 키워드:\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "\n",
        "# ✅ 추천용 프롬프트\n",
        "candidate_recommendation_prompt = PromptTemplate(\n",
        "    input_variables=[\"question\", \"profile\", \"summaries\"],\n",
        "    template=\"\"\"\n",
        "[질문]\n",
        "{question}\n",
        "\n",
        "[프로파일]\n",
        "{profile}\n",
        "\n",
        "[후보별 공약 요약]\n",
        "{summaries}\n",
        "\n",
        "이 정보를 바탕으로 가장 적합한 후보를 한 명 추천하라. 한 문단으로 이유 포함.\n",
        "- 추천 후보:\n",
        "- 추천 이유:\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "\n",
        "# ✅ 비교용 상세 분해 프롬프트\n",
        "policy_element_extraction_prompt = PromptTemplate(\n",
        "    input_variables=[\"question\", \"summary\"],\n",
        "    template=\"\"\"\n",
        "다음은 어떤 대통령 후보의 공약 요약 내용입니다:\n",
        "\n",
        "[질문]\n",
        "{question}\n",
        "\n",
        "[공약 요약]\n",
        "{summary}\n",
        "\n",
        "아래 항목들을 해당 공약 요약에서 가능한 한 구체적으로 추출하십시오:\n",
        "- 핵심 공약: 핵심 아이디어 한 줄 요약\n",
        "- 실현 방식: 구체적인 실행 수단, 제도, 구조\n",
        "- 강점: 타 후보 대비 돋보이는 차별점이나 이점\n",
        "\n",
        "출력 예시는 다음과 같습니다:\n",
        "핵심 공약: 청년에게 생애 첫 집 공급 확대\n",
        "실현 방식: 공공임대 및 분양 확대, 저리 대출 제공\n",
        "강점: 청년 세대에 직접적이고 독립적인 주거 안정 방안 제시\n",
        "\n",
        "위와 같은 형식으로 3줄로 정리하십시오.\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "# ✅ 관련성 판단 프롬프트\n",
        "relevance_prompt = PromptTemplate(\n",
        "    input_variables=[\"question\", \"answer\"],\n",
        "    template=\"\"\"\n",
        "다음은 사용자의 질문과 PDF에서 추출된 응답입니다.\n",
        "\n",
        "[질문]\n",
        "{question}\n",
        "\n",
        "[응답]\n",
        "{answer}\n",
        "\n",
        "아래 기준에 따라 이 응답이 질문의 정책 주제에 '직접적으로 정책적 답변'을 제공하는지 판단하시오.\n",
        "\n",
        "판단 기준(엄격 적용):\n",
        "- 응답에서 후보 이름, 정책 이름, 형식적 표현은 모두 배제하고 '내용만'으로 판단할 것\n",
        "- 질문에 명시된 정책(분야/주제/대상/문제)이 응답에서 '정책 목적과 구체적 실행방안(수단/시행계획 등)'으로 직접 다루어지는 경우에만 → \"관련 있음\"\n",
        "- 질문의 정책 주제가 응답에서 '명확한 정책 내용이나 수단'으로 논의되지 않으면 → \"관련 없음\"\n",
        "- 단순히 단어의 일치, 지역·경제·활성화 등 포괄적 표현, 간접적 연관성, 추상적 서술만 있을 경우 → \"관련 없음\"\n",
        "- 실제 정책의 제목, 세부 실행계획, 지원대상, 예산, 실현 방식 등 구체적 정책 정보가 반드시 명시되어야 함\n",
        "\n",
        "결론은 반드시 \"관련 있음\" 또는 \"관련 없음\" 중 하나로만 간결하게 작성하시오.\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "\n",
        "#✅ 뉴스/논란 + 한줄요약용 PromptTemplate 예시\n",
        "news_issue_summary_prompt = PromptTemplate(\n",
        "    input_variables=[\"candidate\", \"keyword\", \"news_summary\"],\n",
        "    template=\"\"\"\n",
        "아래는 {candidate} 후보의 {keyword} 정책에 대한 최근 뉴스/이슈 요약과 주요 뉴스 인용문이다.\n",
        "\n",
        "[뉴스 기사 요약]\n",
        "{news_summary}\n",
        "\n",
        "\n",
        "이 자료를 바탕으로 다음 포맷에 맞춰 정책 이행 현황과 논란을 분석하라.\n",
        "\n",
        "[뉴스/이행 및 논란 요약]\n",
        "• 최근 이행 상황: (뉴스 기반 정책 실행 및 실제 사례)\n",
        "• 논란 및 이슈: (뉴스 기반 정책 비판, 논란, 부정적 평가 등)\n",
        "• 주요 뉴스 인용: (대표 기사 1~2개 문장 요약)\n",
        "\n",
        "[최종 한줄 요약]\n",
        "- 해당 정책의 실제 이행/논란/사회적 평판을 종합적으로 한 문장으로 요약\n",
        "\n",
        "반드시 한국어로 답변하라.\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "translation_prompt = PromptTemplate(\n",
        "    input_variables=[\"english_text\"],\n",
        "    template=\"다음 영어 텍스트를 자연스럽고 정확한 한국어로 번역하십시오:\\n\\n{english_text}\\n\\n번역:\"\n",
        ")\n",
        "\n",
        "#후보자 이름 추출\n",
        "candidate_detect_prompt = PromptTemplate(\n",
        "    input_variables=[\"question\"],\n",
        "    template=\"다음 질문에서 언급된 대통령 후보의 이름을 정확히 추출하시오. 두 명 이상일 경우 모두 출력하시오.\\n\\n질문: {question}\\n후보 이름:\"\n",
        ")\n",
        "\n",
        "\n",
        "# ✅ 후보별 QA 체인 초기화\n",
        "qa_chains = {\n",
        "    name: RetrievalQAWithSourcesChain.from_chain_type(\n",
        "        llm=llm,\n",
        "        retriever=retrievers[name],\n",
        "        chain_type=\"stuff\",\n",
        "        chain_type_kwargs={\"prompt\": single_candidate_policy_prompt},\n",
        "        return_source_documents=True\n",
        "    )\n",
        "    for name in candidates\n",
        "}\n",
        "\n",
        "candidate_chain = LLMChain(llm=llm, prompt=candidate_detect_prompt) #후보자 이름 추출\n",
        "compare_chain = LLMChain(llm=llm, prompt=multi_candidate_comparison_prompt)# 공약 비교 체인\n",
        "extract_user_profile_chain = LLMChain(llm=llm, prompt=user_profile_extraction_prompt) #사용자 프로필 추출\n",
        "recommend_chain = LLMChain(llm=llm, prompt=candidate_recommendation_prompt) #후보자 추천\n",
        "relevance_chain = LLMChain(llm=llm, prompt=relevance_prompt) # 질의와 응답간 관련성 체크\n",
        "translation_chain = LLMChain(llm=llm, prompt=translation_prompt)# 한국어로 번역\n",
        "detailed_policy_chain = LLMChain(llm=llm, prompt=policy_element_extraction_prompt)\n",
        "news_issue_summary_chain = LLMChain(llm=llm, prompt=news_issue_summary_prompt) #뉴스/논란\n",
        "single_candidate_formatter_chain = LLMChain(llm=llm, prompt=fomatting_single_candidate_prompt) #후보자 공약 출력 포맷팅\n",
        "\n"
      ],
      "metadata": {
        "id": "5KG4vKUqSq-B"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 실험"
      ],
      "metadata": {
        "id": "ud0GxJaLSq-C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def action_query(query) :\n",
        "\n",
        "  response = agent.invoke({\"input\": query})[\"output\"]\n",
        "\n",
        "  if is_english(response):\n",
        "      translated = translation_chain.invoke({\"english_text\": response})\n",
        "      if isinstance(translated, dict):\n",
        "          return translated[\"text\"].strip()\n",
        "      else:\n",
        "          return translated\n",
        "  else:\n",
        "      return response"
      ],
      "metadata": {
        "id": "LgJIROEESq-C"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. 단일 후보자 정책 질의 응답"
      ],
      "metadata": {
        "id": "AhuurgpfnEKn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"이재명 후보의 조선해양 정책에 대해 알려줘.\"\n",
        "result = action_query(query)\n",
        "print(f'Final Answer:\\n{result}')\n",
        "print(f'\\n{last_observation_output}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CP4yOkEq3gQP",
        "outputId": "c2f6f4db-9c68-405b-9e2d-78e463fee911"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#### 단일 후보 공약 질의 Tool 활성화....\n",
            "#### 후보자 이름 추출 중....\n",
            "#### 이재명 후보자 공약집 검색 중....\n",
            "#### 관련성 체크 중....\n",
            "관련성 판단 결과: \"관련 있음\"\n",
            "#### 단일 후보 공약 RAG 실행 완료 ####\n",
            "#### 사후 포맷팅 진행 ####\n",
            "##################################################\n",
            "Final Answer:\n",
            "이재명의 해양 정책은 기후 변화에 대응하고 산업 구조를 탄소 중립화로 전환하는 것을 목표로 합니다. 주요 전략은 온실가스 감축 목표 설정, 석탄화력발전소 폐쇄, 재생에너지 전환 가속화, 그리고 탄소 중립 산업 전환을 촉진하는 것입니다. 이 정책은 태양광, 풍력, 전기 자동차, 그리고 배터리와 같은 탄소 중립 산업의 국내 생산 및 수출 경쟁력을 촉진하고, 건물 및 난방 분야의 에너지 효율을 지원하는 데 초점을 맞추고 있습니다. 이 정보는 2025년 6월 4일자 선거 공약 문서 34페이지에서 인용되었습니다.\n",
            "\n",
            "1. 정책 개요:\n",
            "기후위기 대응과 산업구조의 탈탄소 전환을 목표로 하는 조선해양 정책입니다.\n",
            "\n",
            "2. 주요 추진 전략:\n",
            "- 온실가스 감축 목표 수립\n",
            "- 석탄화력발전 폐쇄\n",
            "- 재생에너지 중심의 에너지전환 가속화\n",
            "- 탄소중립 산업전환\n",
            "\n",
            "3. 기대 효과 및 정책 방향:\n",
            "태양광, 풍력, 전기차, 배터리 등 탄소중립산업의 국산화 및 수출경쟁력 제고를 통해 경제와 환경의 조화로운 발전을 도모하며, 건축물 및 열 부문의 탈탄소화를 통해 노후건물의 에너지효율화를 지원합니다.\n",
            "\n",
            "4. 문서 출처 요약:\n",
            "20250604_대한민국_이재명_선거공약서.pdf: p34\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"이준석 후보의 수산물 의견에 대해 알려줘.\"\n",
        "result = action_query(query)\n",
        "print(f'Final Answer:\\n{result}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "069412e7-578c-4c52-eb6b-76d71504fe40",
        "id": "rw8z6kOdSq-C"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#### 단일 후보 공약 질의 Tool 활성화....\n",
            "#### 후보자 이름 추출 중....\n",
            "#### 단일 후보 공약 질의 Tool 활성화....\n",
            "#### 후보자 이름 추출 중....\n",
            "#### 이준석 후보자 공약집 검색 중....\n",
            "#### 관련성 체크 중....\n",
            "Final Answer:\n",
            "이재명 후보에 대한 해산물 정책은 없습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"이재명 후보의 노인 복지 정책 알려줘.\"\n",
        "action_query(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "outputId": "d73ae9a3-3e08-4ead-b4a9-0ff01ed6bf87",
        "id": "XnzgCgoBrj14"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#### 단일 후보 공약 질의 Tool 활성화....\n",
            "#### 후보자 이름 추출 중....\n",
            "#### 이재명 후보자 공약집 검색 중....\n",
            "#### 관련성 체크 중....\n",
            "관련성 판단 결과: \"관련 있음\"\n",
            "#### 단일 후보 공약 RAG 실행 완료 ####\n",
            "#### 사후 포맷팅 진행 ####\n",
            "##################################################\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'이재명 후보의 노인 복지 정책은 고령사회 대응을 위한 통합적 지원체계를 구축하고, 어르신 주거 문제를 해결하며 노후 소득 보장 체계를 구축하여 노인들의 삶의 질을 향상시키는 것이 목표입니다.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. 복수 후보자 정책 비교"
      ],
      "metadata": {
        "id": "95bbiPmondlw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"후보별 노인 관련 정책 비교해줘.\"\n",
        "result = action_query(query)\n",
        "print(f'Final Answer:\\n{result}')\n",
        "print(f'\\n{last_observation_output}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e000c256-b9ba-4762-cc5e-e7cdbe36dd1d",
        "id": "JnvdHqJ5Sq-C"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "#### 후보별 공약 비교 Tool 활성화....\n",
            "##### 후보자 이름 추출 중....\n",
            "#### 후보자 이름 : ['이재명', '김문수', '이준석', '권영국', '송진호']\n",
            "#### 이재명 후보자 공약집 검색 중....\n",
            "관련성 판단 결과: \"관련 있음\"\n",
            "#### 김문수 후보자 공약집 검색 중....\n",
            "관련성 판단 결과: \"관련 있음\"\n",
            "#### 이준석 후보자 공약집 검색 중....\n",
            "관련성 판단 결과: \"관련 있음\"\n",
            "#### 권영국 후보자 공약집 검색 중....\n",
            "관련성 판단 결과: \"관련 있음\"\n",
            "#### 송진호 후보자 공약집 검색 중....\n",
            "#### 공약 비교 중....\n",
            "#### 후보별 공약 비교 완료 ####\n",
            "##################################################\n",
            "Final Answer:\n",
            "각 후보의 노인 관련 문제에 대한 정책이 비교되었습니다.\n",
            "\n",
            "✅ '노인'에 대한 후보별 공약 비교 분석 결과\n",
            "\n",
            "[이재명 후보]\n",
            "📄 PDF 기반 공약: \n",
            "- 정책의 목적: 고령사회 대응을 위한 통합적 지원체계를 마련하여 노인들의 삶의 질을 향상시키고 노후 소득 보장을 강화하는 것\n",
            "- 구체적 수단: 공공신탁제도 도입, 고령자 친화 주택·은퇴자 도시 조성, 간호·간병 통합서비스 확대, 요양병원 간병비 건강보험 적용, 지역사회 통합 돌봄체계 구축 등\n",
            "- 실행 대상 또는 지역: 노인 및 고령자\n",
            "- 문서상 등장한 구체적인 단어(용어): 고령사회 대응, 공공신탁제도, 고령자 친화 주택, 간호·간병 통합서비스, 요양병원 간병비, 노후 소득 보장 체계\n",
            "[김문수 후보]\n",
            "📄 PDF 기반 공약: \n",
            "정책의 목적은 어르신의 건강과 복지를 강화하고 돌봄과 자립의 균형을 제공하는 것입니다. 구체적 수단으로는 어르신을 위한 방문 접종 및 의료서비스 확대, 사회 서비스형 어르신 복지 일자리 확충, 어르신 데이케어센터 이용시간 확대, 요양병원 간병비 건강보험 적용 등이 있습니다. 실행 대상은 어르신으로, 구체적인 단어로는 고령자, 폐렴구균, 대상포진, HPV, RSV, 치매 등이 사용되었습니다.\n",
            "[이준석 후보]\n",
            "📄 PDF 기반 공약: \n",
            "이준석 대통령 후보의 공약 중 하나는 '국가과학영웅 우대제도' 도입이다. 이 정책의 목적은 우수한 과학기술인을 국가 차원에서 예우하여 연구자 자부심을 회복하고 인재 유출을 방지하는 것이다. 구체적인 수단으로는 '과학기술 성과연금'과 '과학자 패스트트랙' 제도를 도입한다. 이를 통해 과학기술 연구자에게 매월 연금을 지급하고, 성과에 따라 포상금을 제공하며, 국제 활동을 지원하는 등의 혜택을 제공할 것이다. 이 정책은 과학기술 연구자를 대상으로 하며, 연금제도 기준 및 평가체계 설계부터 법령 정비 및 첫 수급자 선정까지 취임 후 2년 이내에 시행될 예정이다.\n",
            "[권영국 후보]\n",
            "📄 PDF 기반 공약: \n",
            "- 정책의 목적: 노인을 위한 존중 사회 조성 및 노인빈곤 완화\n",
            "- 구체적 수단: 기초연금 70만원으로 인상, 노인최저소득 도입, 어르신 맞춤형 일자리 확대, 공공부문 및 은퇴자협동조합을 통한 고령자 고용 지원, 국공립 장기요양 확대, 요양보호사 고용안정 및 처우개선, 공공병원 운영 및 장례서비스 표준비용 발표\n",
            "- 실행 대상 또는 지역: 노인 및 어르신\n",
            "- 문서상 등장한 구체적인 단어(용어): 기초연금, 노인빈곤, 공공실버아파트, 노후원룸, 장기요양, 요양보호사, 공공병원, 장례식장, 국립대병원, 의료격차 해소, 의사 수 확대, 공중보건간호사제, 감염병전문병원, 재난의료 지휘체계, 금융투자소득세, 가상자산세, 부유세, 사회상속제\n",
            "[송진호 후보]\n",
            "📄 PDF 기반 공약: \n",
            "공약 없음\n",
            "\n",
            "✅ 최종 비교 분석\n",
            "이재명 후보는 고령사회 대응을 위한 통합적 지원체계를 구축하여 노인들의 삶의 질을 향상시키고 노후 소득 보장을 강화하는 것을 목적으로 하고, 공공신탁제도 도입, 고령자 친화 주택·은퇴자 도시 조성, 간호·간병 통합서비스 확대 등을 구체적 수단으로 제시하며, 노인 및 고령자를 실행 대상으로 삼고 있습니다. 김문수 후보는 어르신의 건강과 복지를 강화하고 돌봄과 자립의 균형을 제공하는 것을 목적으로 하며, 어르신을 위한 방문 접종 및 의료서비스 확대, 어르신 데이케어센터 이용시간 확대 등을 구체적 수단으로 제시하고 어르신을 실행 대상으로 삼고 있습니다. 이준석 후보는 '국가과학영웅 우대제도' 도입을 통해 과학기술 연구자를 대상으로 우수한 과학기술인을 예우하고 인재 유출을 방지하는 것을 목적으로 하며, '과학기술 성과연금'과 '과학자 패스트트랙' 제도를 도입하여 혜택을 제공할 예정입니다. 권영국 후보는 노인을 위한 존중 사회 조성과 노인빈곤 완화를 목적으로 하며, 기초연금 인상, 어르신 맞춤형 일자리 확대, 국공립 장기요양 확대 등을 구체적 수단으로 제시하고 노인 및 어르신을 실행 대상으로 삼고 있습니다. 송진호 후보는 공약이 없습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"이준석,김문수 후보의 반도체 산업 정책 비교해줘.\"\n",
        "result = action_query(query)\n",
        "print(f'Final Answer:\\n{result}')\n",
        "print(f'\\n{last_observation_output}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26530989-3085-42e7-cae0-893a41a80816",
        "id": "BZwCGCZ1oLAG"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "#### 후보별 공약 비교 Tool 활성화....\n",
            "##### 후보자 이름 추출 중....\n",
            "#### 후보자 이름 : ['이준석', '김문수']\n",
            "#### 이준석 후보자 공약집 검색 중....\n",
            "#### 김문수 후보자 공약집 검색 중....\n",
            "관련성 판단 결과: \"관련 있음\"\n",
            "#### 공약 비교 중....\n",
            "#### 후보별 공약 비교 완료 ####\n",
            "##################################################\n",
            "Final Answer:\n",
            "김문수의 정책에는 메가 자유무역구 도입, 기업 유치를 위한 규제 완화, 중앙 정부 권한 및 자원을 지방 정부로 이양하여 반도체 산업을 국가 경제의 중요한 부분으로 육성하고 발전시키는 구체적인 조치가 포함되어 있습니다. 반면에 이준석은 반도체 산업에 대한 구체적인 정책을 가지고 있지 않습니다.\n",
            "\n",
            "✅ '반도체 산업 정책'에 대한 후보별 공약 비교 분석 결과\n",
            "\n",
            "[이준석 후보]\n",
            "📄 PDF 기반 공약: \n",
            "공약 없음\n",
            "[김문수 후보]\n",
            "📄 PDF 기반 공약: \n",
            "- 정책의 목적: 반도체 산업을 육성하고 발전시켜 국가 경제의 중요한 부분으로 만들기 위함\n",
            "- 구체적 수단: 메가프리존 도입을 통한 미래첨단산업기반 마련, 기업 유치를 위한 규제 완화, 중앙정부의 권한과 자원 지방 이양 확대\n",
            "- 실행 대상 또는 지역: 지자체 기획에 기반한 메가프리존, 광역시·도, 특별자치도, 특례시, 50만 대도시, 시·군의 자치 역량과 의지에 따라 지역별 맞춤형 권한 이양 조정\n",
            "- 문서상 등장한 구체적인 단어(용어)를 사용: 메가프리존, 규제 완화, 중앙정부 권한 지방이양, 반도체 산업 발전을 위한 정책 등\n",
            "\n",
            "✅ 최종 비교 분석\n",
            "이준석 후보는 반도체 산업 정책에 대한 공약이 없는 반면, 김문수 후보는 반도체 산업을 육성하고 발전시켜 국가 경제의 중요한 부분으로 만들기 위한 목적을 가지고 있다. 김문수 후보는 메가프리존 도입, 기업 유치를 위한 규제 완화, 중앙정부의 권한과 자원 지방 이양 확대 등의 구체적인 수단을 제시하고 있으며, 실행 대상은 지자체 기획에 기반한 메가프리존, 지역별 맞춤형 권한 이양 조정이다. 김문수 후보의 공약에는 메가프리존, 규제 완화, 중앙정부 권한 지방이양, 반도체 산업 발전을 위한 정책 등의 구체적인 용어가 등장한다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. 사용자 컨텍스트 별 질의 응답"
      ],
      "metadata": {
        "id": "q0pW-Ah9o6Pk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"부산에 살고 있는 비정규직 청년인데 어떤 후보가 일자리 정책이 좋을까요?\"\n",
        "result = action_query(query)\n",
        "print(f'Final Answer:\\n{result}')\n",
        "print(f'\\n{last_observation_output}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe054649-6661-4d48-9971-a1aefd7af9ef",
        "id": "kEMI1DeESq-C"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "#### 사용자 컨텍스트 별 질의 응답 Tool 활성화....\n",
            "##### 사용자 프로파일 추출 중....\n",
            "##### 후보별 공약 요약 중....\n",
            "#### 사용자 컨텍스트 별 질의 응답 완료 ####\n",
            "##################################################\n",
            "Final Answer:\n",
            "부산의 비정규직에 대한 일자리 창출 정책을 고려할 때, 이재명 후보를 추천합니다.\n",
            "\n",
            "[질문]\n",
            "부산에 살고 있는 비정규직 청년인데 어떤 후보가 일자리 정책이 좋을까요?\n",
            "\n",
            "[후보별 공약 요약]\n",
            "- 이재명 후보:\n",
            "  • 핵심 공약: 비정규직 청년 일자리 확대\n",
            "  • 실현 방식: 비정규직 전환 지원, 산업 분야별 일자리 창출\n",
            "  • 강점: 비정규직 청년의 고용 안정성 강화, 다양한 일자리 창출을 통한 경제 활성화\n",
            "- 김문수 후보:\n",
            "  • 핵심 공약: 비정규직 청년 일자리 안정화\n",
            "  • 실현 방식: 비정규직 고용 확대, 근로자 보호법 개정\n",
            "  • 강점: 비정규직 청년들에게 직접적인 일자리 보장 및 안정성 제공\n",
            "- 이준석 후보:\n",
            "  • 핵심 공약: 비정규직 청년 일자리 보장\n",
            "  • 실현 방식: 비정규직 전환 지원, 산업 분야별 맞춤형 일자리 창출\n",
            "  • 강점: 비정규직 청년의 고용 안정성 강화 및 경제 활성화에 직접적인 영향력 제공\n",
            "- 권영국 후보:\n",
            "  • 핵심 공약: 비정규직 청년 일자리 보장\n",
            "  • 실현 방식: 공공일자리 창출, 비정규직 보호법 제정\n",
            "  • 강점: 비정규직 청년들에게 안정적인 일자리 창출 및 보호를 위한 종합적인 정책 제시\n",
            "- 송진호 후보:\n",
            "  • 핵심 공약: 비정규직 청년 일자리 확대\n",
            "  • 실현 방식: 비정규직 고용 확대, 교육 및 기술 지원 강화\n",
            "  • 강점: 비정규직 청년의 고용 안정성 향상을 위한 구체적인 정책 제시\n",
            "\n",
            "[추천 요약]\n",
            "- 추천 후보: 이재명 후보\n",
            "- 추천 이유: 이재명 후보는 일자리 창출을 중요하게 생각하고 있으며, 비정규직 청년들을 보호하고 지원하는 정책을 내놓고 있습니다. 또한 부산에 살고 있는 비정규직 청년들을 위한 지역 일자리 창출을 강조하고 있어, 부산에서 일하고 사는 당신에게 적합한 후보로 추천할 수 있습니다.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"30대 취준생에게 실질적인 도움을 주는 공약이 누구 후보에게 많은지 요약해줘\"\n",
        "result = action_query(query)\n",
        "print(f'Final Answer:\\n{result}')\n",
        "print(f'\\n{last_observation_output}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bf01eda-7ac6-4e2d-8fef-fd00ca8c0c85",
        "id": "8LuqINmLpGNL"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#### 단일 후보 공약 질의 Tool 활성화....\n",
            "#### 후보자 이름 추출 중....\n",
            "#### 단일 후보 공약 질의 Tool 활성화....\n",
            "#### 후보자 이름 추출 중....\n",
            "#### 단일 후보 공약 질의 Tool 활성화....\n",
            "#### 후보자 이름 추출 중....\n",
            "#### 단일 후보 공약 질의 Tool 활성화....\n",
            "#### 후보자 이름 추출 중....\n",
            "\n",
            "#### 사용자 컨텍스트 별 질의 응답 Tool 활성화....\n",
            "##### 사용자 프로파일 추출 중....\n",
            "##### 후보별 공약 요약 중....\n",
            "#### 사용자 컨텍스트 별 질의 응답 완료 ####\n",
            "##################################################\n",
            "Final Answer:\n",
            "이재명 후보는 30대 구직자들에게 가장 도움이 되는 정책을 가지고 있습니다.\n",
            "\n",
            "[질문]\n",
            "30대 취준생에게 실질적인 도움을 주는 공약이 필요한 상황\n",
            "\n",
            "[후보별 공약 요약]\n",
            "- 이재명 후보:\n",
            "  • 핵심 공약: 30대 취준생을 위한 실질적인 취업 지원 강화\n",
            "  • 실현 방식: 전문 교육 및 취업 멘토링 프로그램 확대, 기업과의 협력을 통한 실무 경험 제공\n",
            "  • 강점: 다양한 분야의 전문가들과의 네트워킹 기회 제공으로 취업률 향상에 도움을 줄 수 있음.\n",
            "- 김문수 후보:\n",
            "  • 핵심 공약: 30대 취준생을 위한 취업 지원 프로그램 강화\n",
            "  • 실현 방식: 취업 멘토링 제공, 기업과의 연계 강화, 취업 보증서 도입\n",
            "  • 강점: 다양한 분야의 전문가들과의 네트워킹 기회 제공하여 취업률 향상에 기여함.\n",
            "- 이준석 후보:\n",
            "  • 핵심 공약: 30대 취준생을 위한 취업 지원 프로그램 신설\n",
            "  • 실현 방식: 취업 멘토링, 이력서 작성 및 면접 대비 교육 제공\n",
            "  • 강점: 다른 후보들과 달리 청년들의 실질적인 취업 도움을 제공하여 실질적인 변화를 이끌어냄.\n",
            "- 권영국 후보:\n",
            "  • 핵심 공약: 30대 취준생을 위한 실질적인 취업 지원 강화\n",
            "  • 실현 방식: 취업 특화 교육과 멘토링 프로그램 확대, 기업과의 맞춤형 취업 연계\n",
            "  • 강점: 다양한 직무 분야에 맞는 맞춤형 취업 지원으로 취준생들의 취업률 향상에 기여함.\n",
            "- 송진호 후보:\n",
            "  • 핵심 공약: 30대 취준생을 위한 취업 지원 프로그램 확대\n",
            "  • 실현 방식: 취업 멘토링 제공, 기업과의 연계 강화, 취업 보조금 지원\n",
            "  • 강점: 실질적인 취업 도움 제공으로 청년층의 경제적 안정 증진 가능성 제시\n",
            "\n",
            "[추천 요약]\n",
            "- 추천 후보: 이재명 후보\n",
            "- 추천 이유: 이재명 후보는 고용, 교육, 주거, 경제 등 다양한 분야에서 취준생들에게 실질적인 도움을 줄 수 있는 공약을 내놓고 있습니다. 그 중에서도 취업 지원 프로그램 강화, 청년 주거 안정을 위한 정책 등이 취준생들에게 큰 도움이 될 것으로 예상됩니다. 또한 그의 경제 지원 정책이 취준생들이 경제적으로 어려움을 겪는 상황에서도 도움이 될 것으로 기대됩니다. 따라서 취준생들에게 실질적인 도움을 줄 수 있는 후보로 이재명 후보를 추천합니다.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. 여론 반응 분석"
      ],
      "metadata": {
        "id": "2MJl5HZlnOLe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"이재명 후보의 조선해양 정책 요즘 이행되고 있는거야? 논란은 없어?.\"\n",
        "action_query(query)\n",
        "print(last_observation_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27198abb-6e83-4a30-9946-f167d175b3e3",
        "id": "qH4Ch2fuSq-C"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "#### 실시간 여론 반응 분석 Tool 활성화....\n",
            "#### 후보자 이름 추출 중....\n",
            "#### 이재명 후보의 후보의 조선해양 정책 관련 정책 뉴스 검색 중...\n",
            "\n",
            "✅ request Success\n",
            "#### 실시간 여론 반응 분석 완료 ####\n",
            "##################################################\n",
            "[뉴스/이행 및 논란 요약]\n",
            "• 최근 이행 상황: 이재명 후보의 조선해양 정책은 동남투자은행 설립을 통해 해양 관련 산업 활성화를 모색하고 있으며, 부산을 해양수도로 만들기 위한 노력이 진행 중이다.\n",
            "• 논란 및 이슈: 일부 산업계에서는 이 정책이 실현 가능성에 대한 의문을 제기하고 있으며, 자금 조달 등의 어려움이 예상된다는 우려가 있다.\n",
            "• 주요 뉴스 인용: \"이재명 후보의 해양수도 정책은 현실적으로 실행 가능한지 의문이 드는 부분이 있다.\" (출처: 뉴스 기사 제목)\n",
            "  \n",
            "[최종 한줄 요약]\n",
            "- 이재명 후보의 조선해양 정책은 실행 가능성에 대한 의문이 제기되고 있으며, 자금 조달 등의 어려움이 예상되는 상황이다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"김문수 후보의 국정 교과서 관련 정책이 요즘 무슨 문제야? .\"\n",
        "action_query(query)\n",
        "print(last_observation_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d7b69a5-13e7-4f7d-af08-e1e3d642d358",
        "id": "_FgYPA8z1aFU"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "#### 실시간 여론 반응 분석 Tool 활성화....\n",
            "#### 후보자 이름 추출 중....\n",
            "#### 김문수 후보의 국정 교과서 관련 정책 뉴스 검색 중...\n",
            "\n",
            "✅ request Success\n",
            "#### 실시간 여론 반응 분석 완료 ####\n",
            "##################################################\n",
            "[뉴스/이행 및 논란 요약]\n",
            "• 최근 이행 상황: 김문수 후보의 국정 교과서 정책에 대한 최근 뉴스나 이슈가 없어 정책 이행 상황에 대한 정보가 부족하다.\n",
            "• 논란 및 이슈: 국정 교과서 정책에 대한 논란이나 비판에 대한 정보가 없어 부정적 평가나 논란에 대한 분석이 어렵다.\n",
            "• 주요 뉴스 인용: 관련 없음\n",
            "\n",
            "[최종 한줄 요약]\n",
            "- 현재까지 김문수 후보의 국정 교과서 정책에 대한 이행 상황이나 논란에 대한 정보가 부족하여 정책의 사회적 평판을 평가하기 어렵다.\n"
          ]
        }
      ]
    }
  ]
}